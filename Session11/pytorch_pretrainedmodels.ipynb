{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fNlogJJUn5TW"
   },
   "source": [
    "# Foundations Of AIML\n",
    "## Session 11\n",
    "### Experiment 2.1: Fine-tuning pre-trained CNN - Inception v3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mTRPBKC-n5Ta"
   },
   "source": [
    "We have seen using the pre-trained model as a black box for feature extraction. This gave us a decent accuracy. However, if we have sufficent data we can *tweak* the learned model to extract features specific to our new dataset. Note that, we have 5000 training images which is not sufficient to train a deep model from scratch. But, 5000 might be enough to *tweak* the pre-trained model to be specific to our dataset. We will see what happens when we tweak only a small specific part of the pre-trained model. We will also see how to tweak the entire model. How many layers to tweak depends on amount of available data. Finetuning to specific data, when done properly, is almost always beneficial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "sWdriso3qVzs"
   },
   "outputs": [],
   "source": [
    "## NOTE: Read the comments to understand the refining of Inception v3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "6Lg3bLHHn5Td"
   },
   "outputs": [],
   "source": [
    "# Importing pytorch packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.autograd import Variable\n",
    "# Importing config.py file\n",
    "import config as cf\n",
    "from utils import *\n",
    "from light_cnn import network_9layers   ## Light CNN model with less weights\n",
    "from data_loader import *\n",
    "## Importing python packages\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models   ## Used for Pretrained PyTorch models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 827,
     "status": "error",
     "timestamp": 1523080317729,
     "user": {
      "displayName": "Priyanka Gaddam",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102560758347233399972"
     },
     "user_tz": -330
    },
    "id": "PxXu8Rrrn5Tj",
    "outputId": "5cae7c5e-638a-4404-ded2-66982eeeaf97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/IIC/ data/IIC_train.txt\n",
      "1003 50\n"
     ]
    }
   ],
   "source": [
    "cf.data_dir = 'data/'\n",
    "\n",
    "## IMFDB data is with 16 classes, Loading atleast 32 images per Batch of Train loader is exhauting memory\n",
    "## So Test with IIC data which is only 5 classes and use 10 images per batch for training\n",
    "\n",
    "#img_root = cf.data_dir+'IMFDB_final/'\n",
    "#train_list_file = cf.data_dir+'IMFDB_train.txt'   #### 5000 images for training\n",
    "#val_list_file = cf.data_dir+'IMFDB_test.txt'      #### 1095 images for validation\n",
    "\n",
    "# img_root = \"data/IMFDB_final/\"\n",
    "# train_list_file = \"data/IMFDB_train.txt\"        #### 5000 images for training\n",
    "# val_list_file = \"data/IMFDB_test.txt\"           #### 1095 images for validation\n",
    "\n",
    "img_root = \"data/IIC/\"\n",
    "train_list_file = \"data/IIC_train.txt\"\n",
    "val_list_file = \"data/IIC_test.txt\"\n",
    "print(img_root,train_list_file)\n",
    "\n",
    "train_image_list = [line.rstrip('\\n') for line in open(train_list_file)]\n",
    "val_image_list = [line.rstrip('\\n') for line in open(val_list_file)]\n",
    "\n",
    "print (len(train_image_list), len(val_image_list))\n",
    "\n",
    "## Define classes for IIC dataset\n",
    "#classes = ['AamairKhan', 'Rimisen', 'Kajol', 'KareenaKapoor','RishiKapoor', 'AmrishPuri', 'AnilKapoor', 'AnupamKher', 'BomanIrani', 'HrithikRoshan', 'KajalAgarwal', 'KatrinaKaif', 'Madhavan', 'MadhuriDixit', 'Umashri', 'Trisha']\n",
    "classes = ['baba_ramdev', 'biswa',  'dhinchak_pooja',  'khali',  'priya_prakash']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/IIC_Inception/train\n"
     ]
    }
   ],
   "source": [
    "traindir = \"data/IIC_Inception/train\"\n",
    "valdir = \"data/IIC_Inception/val\"\n",
    "\n",
    "## For PyTorch Pretrained models Input size is expected as [224,224] except for inception v3 which is [229,229]\n",
    "## Standard Normalization expetced for Pretrained Pytorch models\n",
    "## https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html#sphx-glr-beginner-transfer-learning-tutorial-py\n",
    "## https://discuss.pytorch.org/t/imagenet-example-with-inception-v3/1691\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "print(traindir)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "        datasets.ImageFolder(traindir, transforms.Compose([\n",
    "            #transforms.RandomSizedCrop(224),\n",
    "            #transforms.RandomHorizontalFlip(),\n",
    "            transforms.Resize([299,299]),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])),\n",
    "        batch_size=10, shuffle=True,\n",
    "        num_workers=0, pin_memory=False)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "        datasets.ImageFolder(valdir, transforms.Compose([\n",
    "            transforms.Resize([299,299]),\n",
    "            #transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])),\n",
    "        batch_size=5, shuffle=False,\n",
    "        num_workers=0, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "4j_lWRmen5Tr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Checking for GPU instance\n",
    "use_cuda = torch.cuda.is_available()\n",
    "#Intilizaing the accuracy value as zero\n",
    "best_acc = 0\n",
    "num_classes = 5   ## For IIC data\n",
    "#num_classes = 16  ## For IMFDB data\n",
    "\n",
    "print(use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s92V85SWn5Tv"
   },
   "source": [
    "### Net surgery\n",
    "the original pre-trained model has the last layer (fc2) for 79077 classes but we want to have last layer for only 16 classes.\n",
    "We chop-off the fc2 with 79077 classes and *implant* a new classifier (the MLP model we used in the previous experiment) which predicts 16 classes. Note that we could also implant a single FC layer with 16 classes (instead of a 3 layer MLP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception3(\n",
      "  (Conv2d_1a_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Conv2d_2a_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Conv2d_2b_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Conv2d_3b_1x1): BasicConv2d(\n",
      "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Conv2d_4a_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Mixed_5b): InceptionA(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_1): BasicConv2d(\n",
      "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_2): BasicConv2d(\n",
      "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_5c): InceptionA(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_1): BasicConv2d(\n",
      "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_2): BasicConv2d(\n",
      "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_5d): InceptionA(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_2): BasicConv2d(\n",
      "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6a): InceptionB(\n",
      "    (branch3x3): BasicConv2d(\n",
      "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6b): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6c): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6d): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6e): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (AuxLogits): InceptionAux(\n",
      "    (conv0): BasicConv2d(\n",
      "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv1): BasicConv2d(\n",
      "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
      "  )\n",
      "  (Mixed_7a): InceptionD(\n",
      "    (branch3x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_3): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_4): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_7b): InceptionE(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_7c): InceptionE(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "inception = models.inception_v3(pretrained=True,transform_input=True)\n",
    "print(inception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## starting the surgery - Remove FC layer for the full model (not Aux model) and define own classifier\n",
    "## This is not very efficient for Inception v3 model. Check below for training by removing all the FC layers (both full model and Aux model)\n",
    "\n",
    "layers_to_remove = ['fc']\n",
    "for layers_ in layers_to_remove:        \n",
    "    del(inception._modules[layers_])\n",
    "    \n",
    "#### old fc removed.\n",
    "\n",
    "classifier = nn.Sequential(nn.Linear(2048, 512), nn.BatchNorm1d(512), nn.ReLU(),\n",
    "                           nn.Linear(512, 32), nn.BatchNorm1d(32), nn.ReLU(),\n",
    "                           nn.Linear(32, num_classes))\n",
    "\n",
    "### implanting a new fc2\n",
    "inception.fc = classifier\n",
    "if use_cuda:\n",
    "    inception.cuda()\n",
    "\n",
    "## Define the layers for which to update the gradients by optimizer\n",
    "## Check the other method where we also set requires_grad=True to only such parameters where we want to even calulate the gradient\n",
    "## layers_to_finetune and settting optimizer to this will gaurantee that only these layers are updated with gradients, however gradients are calculated for all parameters which consumes more memory and time\n",
    "layers_to_finetune = [{'params': inception.fc.parameters()}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Vv5fANFNn5Tx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception3(\n",
      "  (Conv2d_1a_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Conv2d_2a_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Conv2d_2b_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Conv2d_3b_1x1): BasicConv2d(\n",
      "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Conv2d_4a_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Mixed_5b): InceptionA(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_1): BasicConv2d(\n",
      "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_2): BasicConv2d(\n",
      "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_5c): InceptionA(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_1): BasicConv2d(\n",
      "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_2): BasicConv2d(\n",
      "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_5d): InceptionA(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_2): BasicConv2d(\n",
      "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6a): InceptionB(\n",
      "    (branch3x3): BasicConv2d(\n",
      "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6b): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6c): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6d): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6e): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (AuxLogits): InceptionAux(\n",
      "    (conv0): BasicConv2d(\n",
      "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv1): BasicConv2d(\n",
      "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
      "  )\n",
      "  (Mixed_7a): InceptionD(\n",
      "    (branch3x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_3): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_4): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_7b): InceptionE(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_7c): InceptionE(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=512, out_features=32, bias=True)\n",
      "    (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=32, out_features=5, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "## Check if the new FC layers are updated in the model\n",
    "print(inception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "TfN-M_cWn5T0"
   },
   "outputs": [],
   "source": [
    "### Intiliazing the loss\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Ws3OTgnYn5T2"
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    inception.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        #print(len(inputs), targets)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = Variable(inputs), Variable(targets)\n",
    "        outputs = inception(inputs)      ### notice that the pre-trained network has an implant classifier which directly outputs the 16 class prediction scores\n",
    "        \n",
    "        ## some issue with outputs...what does inception return?\n",
    "        ## Inception V3 returns two outputs when set to \"Training\"- One for actual model and other for Auxillary model\n",
    "        ## Loss need to be computed for both models and Total loss need to be BP'ed\n",
    "        ## https://discuss.pytorch.org/t/imagenet-example-with-inception-v3/1691/3\n",
    "        \n",
    "        #print(outputs)\n",
    "        #size_ = outputs.size()\n",
    "        #print(len(outputs))\n",
    "        #outputs_ = outputs.view(size_[0], num_classes)\n",
    "        outputs_0 = outputs[0]\n",
    "        outputs_1 = outputs[1]\n",
    "        #print(outputs_0)\n",
    "        #print(outputs_1)\n",
    "        loss_0 = criterion(outputs_0, targets)\n",
    "        loss_1 = criterion(outputs_1, targets)\n",
    "        #print(loss_0, loss_1)\n",
    "        loss = loss_0 + loss_1\n",
    "        #print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.data[0]\n",
    "        _, predicted = torch.max(outputs_0.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets.data).cpu().sum()\n",
    "        \n",
    "        if batch_idx%10 == 0 or batch_idx == len(trainloader)-1:\n",
    "            progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                         % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "        \n",
    "    train_loss_file.write('%d %.3f %.3f\\n' %(epoch, train_loss/len(trainloader), 100.*correct/total))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "B8R1FLLun5T6"
   },
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    global best_acc\n",
    "    inception.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = Variable(inputs, volatile=True), Variable(targets)\n",
    "        \n",
    "        ## Inception V3 returns only one outputs when set to \"eval\"- so outputs is treated differently for testing/evaluation\n",
    "        outputs = inception(inputs)\n",
    "        #print(outputs)\n",
    "        #outputs_0 = outputs[0]\n",
    "        size_ = outputs.size()\n",
    "        outputs_ = outputs.view(size_[0], num_classes)\n",
    "        loss = criterion(outputs_, targets)\n",
    "\n",
    "        test_loss += loss.data[0]\n",
    "        _, predicted = torch.max(outputs_.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets.data).cpu().sum()\n",
    "        \n",
    "        if batch_idx%5 == 0 or batch_idx == len(testloader)-1:\n",
    "            progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                         % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "        \n",
    "    print ('val_loss: ',  test_loss/len(testloader), 'accuracy: ', 100.0*correct/total)\n",
    "    val_loss_file.write('%d %.3f %.3f\\n' %(epoch,  test_loss/len(testloader), 100.*correct/total))\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': classifier,\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir(cf.data_dir+'checkpoint'):\n",
    "            os.mkdir(cf.data_dir+'checkpoint')\n",
    "        torch.save(state, cf.data_dir+'checkpoint/checkpoint_inception_all_ckpt.t7')\n",
    "        best_acc = acc\n",
    "    \n",
    "    return test_loss/len(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "6Azf488-n5T-"
   },
   "outputs": [],
   "source": [
    "experiment = 'inception_finetune_fc_IIC/'\n",
    "#train_loss_file = open(cf.data_dir+experiment+\"/train_loss.txt\", \"w\", 0)\n",
    "#val_loss_file = open(cf.data_dir+experiment+\"/val_loss.txt\", \"w\", 0)\n",
    "train_loss_file = open(\"data/inception_finetune_fc_IIC/train_loss.txt\", \"w+\")\n",
    "val_loss_file = open(\"data/inception_finetune_fc_IIC/val_loss.txt\", \"w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "gZDZUrQ1n5UF",
    "outputId": "164205aa-94ee-4843-dd5e-fd170a00a916"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      " [>..................................] | Loss: 9.153 | Acc: 90.000% (9/10)      1/101 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vgopired\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [==================================>] | Loss: 9.278 | Acc: 63.000% (635/1003)  101/101 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vgopired\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.3281, -0.8079, -0.4068, -0.0705, -0.7599],\n",
      "        [ 1.9623, -1.0684, -0.9724,  0.1779, -1.1739],\n",
      "        [ 2.4755, -1.3137, -1.0497, -0.0565, -1.4196],\n",
      "        [ 1.3999, -0.5170, -0.5496,  0.0820, -0.7635],\n",
      "        [ 1.7188, -0.7831, -0.5793, -0.1362, -0.8382]])\n",
      " [>..................................] | Loss: 0.357 | Acc: 100.000% (5/5)      \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 1/10 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vgopired\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.4347, -0.4537, -0.8952,  0.3561, -1.0565],\n",
      "        [ 1.7532, -0.8908, -0.6896, -0.0019, -1.0352],\n",
      "        [ 0.2905, -0.5779,  0.2071, -0.2968, -0.3032],\n",
      "        [ 1.9243, -0.8738, -0.6672, -0.1363, -1.0702],\n",
      "        [ 1.9047, -0.9666, -0.7373, -0.0723, -1.0723]])\n",
      "tensor([[-0.0645,  0.8602, -0.6497,  0.3188, -0.5023],\n",
      "        [-0.7104,  0.0978, -0.3252,  0.6691, -0.3279],\n",
      "        [ 0.1875,  0.2973, -0.1487, -0.0491, -0.2422],\n",
      "        [-0.6691,  0.6734, -0.8781,  1.1787, -0.8602],\n",
      "        [-1.1909,  0.9887, -0.7875,  1.3192, -0.8296]])\n",
      "tensor([[-0.7468,  1.3098, -0.5443,  0.4047, -0.4702],\n",
      "        [-1.2978,  1.7331, -0.6545,  0.6491, -0.7830],\n",
      "        [-0.3781,  1.4632, -0.5734,  0.0146, -0.5533],\n",
      "        [-0.8426,  1.0804,  0.0290, -0.2068, -0.2327],\n",
      "        [-1.3699,  1.9825, -0.9987,  0.6019, -0.5505]])\n",
      "tensor([[-1.3569, -0.5721,  1.5778, -0.6979,  0.0989],\n",
      "        [-1.5405, -0.6032,  1.7402, -0.7312,  0.1706],\n",
      "        [-0.3664, -0.2120,  0.9629, -0.3202, -0.1993],\n",
      "        [-1.6872, -0.6656,  1.6022, -0.8358,  0.3803],\n",
      "        [-1.7029, -0.7348,  2.2347, -0.9908,  0.1109]])\n",
      "tensor([[-1.2825, -0.2799,  1.9792, -0.7944, -0.2198],\n",
      "        [-1.2308, -0.4105,  1.8261, -0.6753, -0.0489],\n",
      "        [-1.1510, -0.2722,  1.0072, -0.6210,  0.1900],\n",
      "        [-2.2835, -0.8319,  1.1626, -1.0296,  0.9329],\n",
      "        [-1.4114, -0.5119,  1.5765, -0.6265,  0.2226]])\n",
      "tensor([[-0.9500,  1.0604, -0.5533,  0.8276, -0.6444], Acc: 90.000% (27/30)     6/10 \n",
      "        [-0.3578, -0.0762, -0.4529,  0.9193, -0.6464],\n",
      "        [-0.5126,  0.6047, -0.6180,  1.1221, -0.8325],\n",
      "        [ 0.0942, -0.2438, -0.9510,  1.3035, -1.0583],\n",
      "        [-0.7474,  0.2014, -1.1291,  1.4788, -0.8996]])\n",
      "tensor([[-0.6925,  0.0843, -1.1981,  2.0996, -1.5596],\n",
      "        [-0.6371,  0.0164, -1.0312,  1.7976, -1.2863],\n",
      "        [-0.8095,  0.9183, -1.0672,  1.4142, -1.0201],\n",
      "        [-1.0869,  0.8541, -0.9509,  1.9390, -1.4583],\n",
      "        [-1.0306,  0.2558, -0.4955,  0.8320, -0.2325]])\n",
      "tensor([[-2.2693, -0.6229,  0.4126, -1.0425,  1.2969],\n",
      "        [-1.2405, -0.5093,  0.3492,  0.1157,  0.1687],\n",
      "        [-1.1271,  0.7339,  0.1194, -0.1400, -0.0394],\n",
      "        [-1.3710, -0.6343,  0.5170, -0.5822,  0.6884],\n",
      "        [-0.7700, -0.1674,  0.1359, -0.3594,  0.4348]])\n",
      "tensor([[-1.7997, -1.0356,  0.3337, -1.0945,  1.1207],\n",
      "        [-1.8606, -0.9026,  0.2746, -0.7952,  1.0694],\n",
      "        [-0.6461, -0.5756,  0.4903, -0.5741,  0.2819],\n",
      "        [ 0.0221, -0.1705, -0.0846, -0.2342,  0.0126],\n",
      "        [-1.2362,  0.6207, -0.3716, -0.5312,  0.5697]])\n",
      " [===============================>...] | Loss: 0.685 | Acc: 82.000% (41/50)     10/10 \n",
      "val_loss:  tensor(0.6847) accuracy:  tensor(82)\n",
      "Saving..\n",
      "\n",
      "Epoch: 1\n",
      " [==================================>] | Loss: 9.152 | Acc: 67.000% (681/1003)  101/101 \n",
      "tensor([[ 1.8166, -1.0480, -0.7563, -0.0777, -1.0861],\n",
      "        [ 2.3075, -1.1283, -1.1415,  0.0119, -1.3880],\n",
      "        [ 3.1884, -1.5288, -1.5444, -0.1109, -1.8905],\n",
      "        [ 2.5212, -0.9719, -1.2838,  0.0472, -1.5616],\n",
      "        [ 2.1434, -0.8959, -0.9670, -0.0872, -1.1906]])\n",
      "tensor([[ 1.6944, -0.4691, -1.0376,  0.2710, -1.2746], Acc: 100.000% (5/5)      1/10 \n",
      "        [ 2.1574, -1.0358, -0.8018, -0.2255, -1.2412],\n",
      "        [ 0.7643, -0.7668, -0.0511, -0.2904, -0.5564],\n",
      "        [ 2.2024, -0.7653, -0.9407, -0.1867, -1.2866],\n",
      "        [ 2.5386, -1.2614, -1.1219, -0.1585, -1.5147]])\n",
      "tensor([[-0.0147,  1.0275, -0.7649,  0.4102, -1.0384],\n",
      "        [-1.2963,  0.2095, -0.3781,  0.5518, -0.1294],\n",
      "        [-0.0284,  0.0291, -0.0098, -0.2658, -0.0589],\n",
      "        [-0.5145,  0.5614, -0.7170,  0.7965, -0.8986],\n",
      "        [-1.2772,  1.2782, -0.8444,  1.1865, -1.1577]])\n",
      "tensor([[-0.9288,  1.5412, -0.4625,  0.3397, -0.8091],\n",
      "        [-1.5339,  2.1265, -0.6865,  0.5396, -1.2677],\n",
      "        [-0.7678,  2.1056, -0.8219,  0.2015, -1.0579],\n",
      "        [-0.9040,  1.4302, -0.1423, -0.2275, -0.5006],\n",
      "        [-1.6632,  2.2161, -1.1002,  0.5137, -0.9145]])\n",
      "tensor([[-1.9415, -1.2141,  2.0144, -1.2907,  0.3938],\n",
      "        [-1.7780, -0.7674,  2.3936, -1.0815, -0.0954],\n",
      "        [-0.2390, -0.5651,  1.1945, -0.6815, -0.4275],\n",
      "        [-1.8188, -0.9177,  1.9167, -0.9866,  0.2558],\n",
      "        [-1.3449, -0.9610,  2.2074, -1.1629, -0.1188]])\n",
      "tensor([[-1.6125, -0.6916,  2.3157, -1.1271, -0.1999],\n",
      "        [-1.8117, -0.8141,  2.6724, -1.1983, -0.2387],\n",
      "        [-1.3533, -0.4111,  1.5279, -0.9023,  0.0253],\n",
      "        [-2.8363, -0.9717,  1.5140, -1.4588,  1.1391],\n",
      "        [-1.5164, -0.5967,  2.1281, -0.7542, -0.1086]])\n",
      "tensor([[-1.6287,  1.5342, -0.6411,  0.9726, -1.1469], Acc: 93.000% (28/30)     6/10 \n",
      "        [ 0.3595, -0.3145, -0.8084,  0.9587, -1.0705],\n",
      "        [-0.4394,  0.7359, -0.8677,  1.1159, -1.0844],\n",
      "        [-0.3912, -0.0157, -1.0011,  1.5136, -1.3389],\n",
      "        [-0.7418, -0.1042, -1.4569,  1.9365, -1.4868]])\n",
      "tensor([[-0.8563, -0.0707, -1.3149,  2.1964, -1.8131],\n",
      "        [-0.5859, -0.2953, -1.3166,  1.9150, -1.6375],\n",
      "        [-0.7019,  0.8123, -1.2485,  1.7134, -1.5882],\n",
      "        [-1.2040,  0.6098, -0.8471,  2.0329, -1.8595],\n",
      "        [-1.9035, -0.2322, -0.8882,  1.2229, -0.3542]])\n",
      "tensor([[-2.8512, -0.8432,  0.3227, -1.2913,  1.7756],\n",
      "        [-1.9286, -1.0403,  1.0074, -0.8192,  0.7126],\n",
      "        [-2.1816,  0.6341,  0.0416, -0.5959,  0.4314],\n",
      "        [-2.1655, -0.6441,  0.1451, -0.9656,  1.4021],\n",
      "        [-0.4482, -0.2849, -0.0209, -0.4210,  0.3601]])\n",
      "tensor([[-1.8019, -1.2586, -0.1275, -1.1765,  1.4705],\n",
      "        [-3.3110, -1.3603,  0.2507, -1.4035,  2.1034],\n",
      "        [-0.9927, -0.9377,  0.5889, -0.8252,  0.5618],\n",
      "        [ 0.0625, -0.0151, -0.2673, -0.2291, -0.0771],\n",
      "        [-1.8801,  0.2966, -0.4635, -0.7537,  0.9644]])\n",
      " [===============================>...] | Loss: 0.516 | Acc: 86.000% (43/50)     10/10 \n",
      "val_loss:  tensor(0.5159) accuracy:  tensor(86)\n",
      "Saving..\n",
      "\n",
      "Epoch: 2\n",
      " [==================================>] | Loss: 9.171 | Acc: 67.000% (673/1003)  101/101 \n",
      "tensor([[ 2.0564, -1.4834, -0.8767, -0.1331, -1.2375],\n",
      "        [ 3.2253, -2.0882, -1.6725, -0.0408, -1.9282],\n",
      "        [ 4.1732, -2.4415, -2.0307, -0.3042, -2.3907],\n",
      "        [ 2.9083, -1.6911, -1.6030,  0.1092, -1.9150],\n",
      "        [ 2.6585, -1.5113, -1.1670, -0.2876, -1.3998]])\n",
      "tensor([[ 1.8878, -0.8282, -1.3062,  0.3892, -1.4298], Acc: 100.000% (5/5)      1/10 \n",
      "        [ 2.7519, -1.5685, -1.1851, -0.2965, -1.6006],\n",
      "        [ 0.8093, -1.3634,  0.1091, -0.5534, -0.6597],\n",
      "        [ 3.1152, -1.3653, -1.3642, -0.4045, -1.6598],\n",
      "        [ 2.9507, -1.9095, -1.2860, -0.2962, -1.6964]])\n",
      "tensor([[ 0.0447,  1.2684, -1.1016,  0.6482, -1.3779],\n",
      "        [-2.0537,  0.4826, -0.1724,  1.0364, -0.6554],\n",
      "        [-0.2253,  0.2281,  0.1410, -0.1049, -0.3322],\n",
      "        [-1.0100,  0.4760, -1.2087,  1.4570, -1.2565],\n",
      "        [-1.9129,  1.0032, -0.7715,  1.5078, -1.2490]])\n",
      "tensor([[-1.1452,  1.7682, -0.3240,  0.0483, -0.9027],\n",
      "        [-1.1773,  1.4210, -0.3424,  0.3728, -0.9365],\n",
      "        [-0.6344,  2.2801, -1.0291, -0.2083, -0.9595],\n",
      "        [-0.8709,  1.2975, -0.0353, -0.4941, -0.4470],\n",
      "        [-1.7632,  1.8559, -0.7412,  0.2918, -0.7707]])\n",
      "tensor([[-1.7582, -1.4753,  1.8704, -1.1270,  0.2279],\n",
      "        [-2.1154, -1.0289,  2.1862, -1.1006,  0.2327],\n",
      "        [-0.6408, -0.6150,  1.5031, -0.7059, -0.4980],\n",
      "        [-2.3212, -0.9361,  2.0393, -1.1067,  0.3951],\n",
      "        [-1.8264, -1.2796,  2.5021, -1.2386, -0.0566]])\n",
      "tensor([[-2.2711, -0.9799,  3.0291, -1.3431, -0.3391],\n",
      "        [-2.1367, -1.0292,  2.6818, -1.1205, -0.1190],\n",
      "        [-2.0258, -0.4359,  1.9367, -0.9338,  0.0013],\n",
      "        [-2.9988, -0.8717,  0.9354, -1.6640,  1.6663],\n",
      "        [-1.9723, -0.7703,  2.0519, -0.7860,  0.0777]])\n",
      "tensor([[-2.0454,  1.4749, -0.4745,  0.5982, -0.8663], Acc: 86.000% (26/30)     6/10 \n",
      "        [-0.3902, -0.1991, -0.7820,  1.1868, -1.0669],\n",
      "        [-0.5054,  0.8155, -0.9057,  1.1267, -1.2517],\n",
      "        [-0.4510, -0.1605, -1.4115,  1.8706, -1.6565],\n",
      "        [-0.6775, -0.2312, -1.3914,  1.4881, -1.0518]])\n",
      "tensor([[-1.4547,  0.2151, -1.4735,  2.5307, -2.0896],\n",
      "        [-1.0865, -0.0337, -1.4390,  2.1323, -1.7468],\n",
      "        [-0.7041,  0.4892, -0.8835,  1.4016, -1.3355],\n",
      "        [-1.4095,  0.6088, -0.3993,  1.6967, -1.7955],\n",
      "        [-1.8786, -0.0908, -0.6522,  1.0756, -0.3139]])\n",
      "tensor([[-1.9275, -0.9975,  0.5833, -1.2290,  1.2286],\n",
      "        [-1.6211, -0.9562,  0.7556, -0.8977,  0.8001],\n",
      "        [-2.0265,  0.8279,  0.2283, -0.6802,  0.3334],\n",
      "        [-2.0483, -0.7799,  0.2155, -1.1121,  1.4330],\n",
      "        [-0.6569, -0.4627,  0.0991, -0.3606,  0.4124]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.2978, -1.5760, -0.0160, -1.3042,  1.3003],\n",
      "        [-2.1385, -1.0937,  0.3777, -1.2407,  1.3980],\n",
      "        [-0.9242, -1.3910,  0.8600, -1.0298,  0.5422],\n",
      "        [ 0.6240, -0.4552, -0.2269, -0.2553, -0.3669],\n",
      "        [-1.0218,  1.5136, -0.4960, -0.4468, -0.1656]])\n",
      " [===============================>...] | Loss: 0.563 | Acc: 82.000% (41/50)     10/10 \n",
      "val_loss:  tensor(0.5630) accuracy:  tensor(82)\n",
      "\n",
      "Epoch: 3\n",
      " [==================================>] | Loss: 9.075 | Acc: 68.000% (685/1003)  101/101 \n",
      "tensor([[ 1.7159, -1.3996, -0.7231, -0.2007, -1.0605],\n",
      "        [ 2.7520, -1.5924, -1.4785, -0.0891, -1.7131],\n",
      "        [ 3.6821, -1.9548, -1.8899, -0.3244, -2.1601],\n",
      "        [ 2.1044, -0.9390, -1.3904,  0.2766, -1.6494],\n",
      "        [ 2.4447, -1.2883, -1.0230, -0.4385, -1.3021]])\n",
      "tensor([[ 0.9411, -0.5421, -1.5438,  0.9984, -1.6250], Acc: 100.000% (5/5)      1/10 \n",
      "        [ 2.3403, -1.1721, -1.0233, -0.3098, -1.5789],\n",
      "        [ 0.7557, -1.4014,  0.1144, -0.6985, -0.5122],\n",
      "        [ 2.2203, -0.8763, -0.9518, -0.3563, -1.3354],\n",
      "        [ 2.6304, -1.5328, -1.2125, -0.2928, -1.6278]])\n",
      "tensor([[ 0.1129,  1.1493, -1.1121,  0.6341, -1.5953],\n",
      "        [-2.1151,  0.7523, -0.5132,  1.4469, -1.0784],\n",
      "        [-1.0671, -0.0706,  0.3909,  0.1826, -0.4404],\n",
      "        [-1.9165,  1.4032, -1.1559,  1.5727, -1.4126],\n",
      "        [-2.5116,  1.4004, -0.9666,  1.6165, -1.3787]])\n",
      "tensor([[-1.3884,  1.7475, -0.4385,  0.4143, -1.1357],\n",
      "        [-1.7082,  1.8756, -0.4999,  0.5892, -1.3119],\n",
      "        [-0.8592,  2.1570, -1.0516,  0.4580, -1.3741],\n",
      "        [-1.0060,  0.9956,  0.4282, -0.5483, -0.6018],\n",
      "        [-2.1202,  1.7597, -0.9997,  1.2670, -1.3032]])\n",
      "tensor([[-1.9557, -1.3705,  2.1684, -1.3313,  0.0678],\n",
      "        [-1.9085, -0.6844,  2.1441, -1.0480, -0.0920],\n",
      "        [-1.2022, -0.4611,  1.7647, -0.6159, -0.6238],\n",
      "        [-2.6743, -0.9550,  2.1625, -1.3279,  0.4777],\n",
      "        [-2.0221, -0.8177,  2.2963, -0.8782, -0.0966]])\n",
      "tensor([[-2.2819, -0.5750,  2.7511, -1.2488, -0.4483],\n",
      "        [-2.4830, -0.8427,  2.9382, -1.0914, -0.3647],\n",
      "        [-2.0668, -0.3070,  2.0107, -0.8911, -0.2015],\n",
      "        [-2.6369, -0.5901,  1.0878, -1.5177,  1.2494],\n",
      "        [-2.1475, -0.4887,  2.2319, -0.8679, -0.1006]])\n",
      "tensor([[-2.2978,  1.3687, -0.5021,  1.6280, -1.6279], Acc: 80.000% (24/30)     6/10 \n",
      "        [-1.2292, -0.1533, -0.7474,  1.6712, -1.3832],\n",
      "        [-1.0988,  1.2341, -1.3268,  1.8096, -1.7584],\n",
      "        [-1.4430,  0.3254, -1.6233,  2.6477, -2.2516],\n",
      "        [-1.6823,  0.3248, -1.6818,  2.1325, -1.3494]])\n",
      "tensor([[-2.4962,  0.3292, -1.6504,  3.2332, -2.5732],\n",
      "        [-1.8979,  0.2129, -1.6793,  2.5947, -1.8649],\n",
      "        [-1.4375,  0.6039, -1.2021,  2.3009, -2.0936],\n",
      "        [-2.7677,  0.7985, -0.4976,  2.7935, -2.9053],\n",
      "        [-2.4345,  0.1467, -0.6369,  1.6237, -0.7510]])\n",
      "tensor([[-2.1093, -0.5914,  0.5362, -1.1985,  1.1943],\n",
      "        [-2.2960, -0.8458,  0.5281, -0.4318,  0.6799],\n",
      "        [-2.0436,  0.9587, -0.1584, -0.0417,  0.0074],\n",
      "        [-2.0921, -0.7280,  0.0364, -0.9672,  1.3854],\n",
      "        [-0.6652, -0.1751,  0.0039, -0.4407,  0.5464]])\n",
      "tensor([[-1.7290, -1.4107, -0.1216, -1.3158,  1.5066],\n",
      "        [-2.7616, -1.0582, -0.0684, -1.3873,  1.9006],\n",
      "        [-1.1592, -0.9475,  0.6768, -0.8239,  0.6423],\n",
      "        [ 0.0882, -0.0347, -0.0228, -0.3630, -0.2119],\n",
      "        [-1.5404,  1.5591, -0.4176, -0.3520, -0.1591]])\n",
      " [===============================>...] | Loss: 0.517 | Acc: 80.000% (40/50)     10/10 \n",
      "val_loss:  tensor(0.5173) accuracy:  tensor(80)\n",
      "\n",
      "Epoch: 4\n",
      " [==================================>] | Loss: 8.987 | Acc: 70.000% (706/1003)  101/101 \n",
      "tensor([[ 2.1458, -1.5724, -1.0488, -0.1643, -1.2300],\n",
      "        [ 2.4356, -1.5216, -1.3302, -0.1524, -1.4006],\n",
      "        [ 3.7944, -2.0151, -1.9341, -0.5339, -1.9800],\n",
      "        [ 1.2277, -0.6821, -1.3440,  0.7086, -1.5337],\n",
      "        [ 2.3287, -1.3627, -0.8923, -0.5524, -1.0848]])\n",
      "tensor([[ 1.3659, -0.5932, -1.7266,  0.8883, -1.7427], Acc: 100.000% (5/5)      1/10 \n",
      "        [ 2.3103, -1.1756, -0.9835, -0.3793, -1.4703],\n",
      "        [ 1.3845, -1.2061, -0.0942, -0.6403, -0.7539],\n",
      "        [ 2.5776, -1.1228, -1.0196, -0.6339, -1.3837],\n",
      "        [ 2.6895, -1.4987, -1.2428, -0.4069, -1.5423]])\n",
      "tensor([[-0.4537,  2.0619, -1.4081,  0.2229, -1.5302],\n",
      "        [-2.2982,  0.9401, -0.8445,  1.3359, -0.9572],\n",
      "        [-0.9107,  0.0194,  0.2898, -0.2812, -0.2160],\n",
      "        [-2.1297,  1.8242, -1.8300,  1.5042, -1.3867],\n",
      "        [-2.8061,  1.4781, -1.1749,  1.4816, -1.2692]])\n",
      "tensor([[-1.7924,  2.4729, -0.8077,  0.0449, -1.1417],\n",
      "        [-2.1959,  2.7253, -0.8041,  0.1313, -1.3177],\n",
      "        [-0.6858,  2.1278, -1.0574, -0.1159, -1.3343],\n",
      "        [-1.5240,  1.6362,  0.1251, -0.6834, -0.5850],\n",
      "        [-2.3352,  2.1517, -1.1098,  0.4398, -0.8335]])\n",
      "tensor([[-1.8829, -1.5598,  2.3247, -1.4476, -0.1302],\n",
      "        [-1.9587, -0.8877,  2.2893, -0.9661, -0.2071],\n",
      "        [-1.1898, -0.5785,  1.7206, -0.5177, -0.6609],\n",
      "        [-2.7558, -1.1878,  2.3529, -1.2034,  0.3366],\n",
      "        [-2.4861, -1.3408,  2.5959, -1.0981,  0.0171]])\n",
      "tensor([[-2.5625, -0.9919,  3.0965, -1.4103, -0.5351],\n",
      "        [-2.2161, -1.0571,  2.5867, -0.8451, -0.5920],\n",
      "        [-1.7262, -0.5471,  2.0049, -0.7690, -0.2526],\n",
      "        [-2.8145, -1.2422,  1.7432, -1.7387,  1.0544],\n",
      "        [-2.0038, -0.9540,  2.4255, -0.9112, -0.2463]])\n",
      "tensor([[-2.7966,  1.5892, -1.1454,  1.3004, -1.0480], Acc: 90.000% (27/30)     6/10 \n",
      "        [-1.6871,  0.2803, -0.6221,  1.6567, -1.3047],\n",
      "        [-1.7617,  1.5576, -1.1759,  1.1458, -1.2483],\n",
      "        [-2.1682,  0.3283, -2.2781,  3.1525, -2.3346],\n",
      "        [-1.7351,  0.1453, -1.8988,  1.9206, -0.9840]])\n",
      "tensor([[-2.6155,  0.3234, -2.2305,  3.2740, -2.3978],\n",
      "        [-1.7955,  0.2330, -1.8901,  2.4434, -1.6666],\n",
      "        [-1.5071,  0.9121, -1.5774,  1.9153, -1.7242],\n",
      "        [-2.8363,  1.4322, -0.8264,  2.4742, -2.7967],\n",
      "        [-2.6696,  0.3811, -0.9825,  1.7883, -0.8068]])\n",
      "tensor([[-2.3888, -0.9830,  0.9173, -1.3533,  1.2656],\n",
      "        [-2.1455, -0.8388,  0.8293, -0.3615,  0.5044],\n",
      "        [-2.6987,  0.6788, -0.2101, -0.4168,  0.5799],\n",
      "        [-2.5267, -0.9905,  0.5710, -1.0713,  1.4057],\n",
      "        [-0.6595, -0.5126,  0.5125, -0.3876,  0.3479]])\n",
      "tensor([[-1.7121, -1.5239,  0.3348, -1.3099,  1.3631],\n",
      "        [-2.7093, -1.2964,  0.2642, -1.3869,  1.7883],\n",
      "        [-0.8616, -1.0701,  0.9062, -0.6611,  0.3249],\n",
      "        [ 0.1432, -0.0478,  0.0328, -0.5175, -0.0448],\n",
      "        [-2.3097,  1.9638, -0.7444, -0.5840, -0.0109]])\n",
      " [===============================>...] | Loss: 0.479 | Acc: 78.000% (39/50)     10/10 \n",
      "val_loss:  tensor(0.4790) accuracy:  tensor(78)\n",
      "\n",
      "Epoch: 5\n",
      " [==================================>] | Loss: 9.008 | Acc: 71.000% (720/1003)  101/101 \n",
      "tensor([[ 2.6088, -1.8086, -1.1592, -0.3453, -1.4784],\n",
      "        [ 2.9491, -1.8580, -1.4808, -0.3370, -1.6098],\n",
      "        [ 4.9573, -2.6394, -2.4094, -0.8561, -2.6616],\n",
      "        [ 2.6549, -1.3910, -1.5693, -0.0453, -1.7145],\n",
      "        [ 3.2138, -1.8537, -1.2195, -0.8151, -1.5636]])\n",
      "tensor([[ 1.7785, -1.0488, -1.6132,  0.6334, -1.7163], Acc: 100.000% (5/5)      1/10 \n",
      "        [ 2.2652, -1.1144, -1.0400, -0.2254, -1.6509],\n",
      "        [ 1.3307, -1.3879,  0.1366, -1.0057, -0.6496],\n",
      "        [ 3.1457, -1.3129, -1.3146, -0.7173, -1.7254],\n",
      "        [ 2.9149, -1.6203, -1.3159, -0.4683, -1.7557]])\n",
      "tensor([[-0.4195,  1.7626, -1.2190,  0.3790, -1.3875],\n",
      "        [-2.1145,  0.3529,  0.1051,  0.8341, -0.5615],\n",
      "        [-1.5599, -0.8073,  0.6845, -1.0502,  0.6649],\n",
      "        [-2.0146,  1.8323, -1.1806,  0.9380, -1.0943],\n",
      "        [-2.6392,  1.6477, -0.8435,  0.8694, -1.0017]])\n",
      "tensor([[-1.6084,  1.7175, -0.5834,  0.6347, -1.1990],\n",
      "        [-2.1103,  2.5508, -0.7855,  0.2649, -1.3641],\n",
      "        [-0.9969,  2.1468, -1.0083,  0.0292, -1.1295],\n",
      "        [-1.4257,  1.6806, -0.2646, -0.4785, -0.5676],\n",
      "        [-2.3550,  1.3749, -1.0959,  1.0168, -0.7706]])\n",
      "tensor([[-2.0864, -1.3820,  3.0331, -1.8880, -0.5876],\n",
      "        [-2.1075, -0.9455,  2.6141, -1.0965, -0.3950],\n",
      "        [-0.8802, -0.8926,  1.7693, -0.8298, -0.7009],\n",
      "        [-2.4297, -1.0668,  2.3630, -1.7196,  0.2406],\n",
      "        [-2.0126, -1.4925,  2.4198, -1.5837,  0.0509]])\n",
      "tensor([[-1.4700, -0.5105,  2.6497, -1.7345, -1.1391],\n",
      "        [-2.4566, -1.0618,  3.1317, -1.1306, -0.9164],\n",
      "        [-2.1236, -0.6243,  2.2794, -0.9742, -0.2224],\n",
      "        [-2.7189, -0.9523,  1.3300, -2.0256,  1.2416],\n",
      "        [-1.9536, -0.8707,  2.5382, -0.9188, -0.3761]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.1140,  0.8659, -0.5855,  1.0629, -0.7799], Acc: 93.000% (28/30)     6/10 \n",
      "        [-1.0647, -0.5279, -0.6128,  1.3391, -0.8831],\n",
      "        [-1.7257,  1.0302, -0.8804,  1.1631, -1.0858],\n",
      "        [-2.1941, -0.1523, -1.5392,  2.6879, -1.8710],\n",
      "        [-1.9049, -0.6713, -1.2629,  1.2351, -0.1407]])\n",
      "tensor([[-2.2553, -0.2562, -1.2137,  2.5597, -1.8725],\n",
      "        [-1.2564, -0.3512, -1.1305,  1.8912, -1.3457],\n",
      "        [-1.6220,  0.4323, -0.9653,  1.7945, -1.4426],\n",
      "        [-2.1012,  1.3255, -0.4283,  1.7023, -2.4930],\n",
      "        [-2.9344, -0.1981, -0.1967,  1.4000, -0.5088]])\n",
      "tensor([[-2.2918, -0.7417,  0.6881, -1.6951,  1.3469],\n",
      "        [-2.2242, -1.2374,  1.1795, -0.7101,  0.5145],\n",
      "        [-2.6349,  0.7058,  0.1436, -0.4175,  0.2802],\n",
      "        [-2.2776, -1.6205,  0.3685, -1.4849,  1.6653],\n",
      "        [-0.4204, -0.5822,  0.3739, -0.4914,  0.4145]])\n",
      "tensor([[-1.2059, -1.8553,  0.1340, -1.7108,  1.3978],\n",
      "        [-2.0879, -1.6646,  0.3521, -1.7115,  1.6529],\n",
      "        [-0.8812, -0.8465,  0.5638, -0.7901,  0.5817],\n",
      "        [ 0.3609, -0.0243, -0.1387, -0.8761, -0.2432],\n",
      "        [-1.8327,  1.5837, -0.8676, -0.5719,  0.1186]])\n",
      " [===============================>...] | Loss: 0.485 | Acc: 88.000% (44/50)     10/10 \n",
      "val_loss:  tensor(0.4846) accuracy:  tensor(88)\n",
      "Saving..\n",
      "\n",
      "Epoch: 6\n",
      " [==================================>] | Loss: 8.967 | Acc: 73.000% (735/1003)  101/101 \n",
      "tensor([[ 2.4389, -1.7081, -1.1957, -0.3201, -1.2719],\n",
      "        [ 3.2773, -2.0485, -2.0017, -0.2236, -1.8383],\n",
      "        [ 5.3897, -2.6779, -2.7075, -1.1461, -2.5981],\n",
      "        [ 1.7610, -0.7724, -1.6805,  0.5080, -1.6538],\n",
      "        [ 3.2336, -1.8078, -1.3493, -0.8920, -1.4230]])\n",
      "tensor([[ 1.4270, -0.6928, -1.6819,  0.9357, -1.9528], Acc: 100.000% (5/5)      1/10 \n",
      "        [ 2.3971, -1.1612, -1.2631, -0.2575, -1.5161],\n",
      "        [ 1.1686, -1.4949, -0.1058, -0.7864, -0.4053],\n",
      "        [ 3.2891, -1.3721, -1.3543, -0.9624, -1.6259],\n",
      "        [ 3.2439, -1.7601, -1.5103, -0.6716, -1.7259]])\n",
      "tensor([[-0.4097,  1.9776, -1.1985,  0.2347, -1.5616],\n",
      "        [-2.2050,  0.2574, -0.1570,  1.1869, -0.8326],\n",
      "        [-1.6964, -0.4117,  0.2964, -0.4561,  0.4222],\n",
      "        [-2.0624,  2.1589, -1.4108,  0.8932, -1.3029],\n",
      "        [-2.8721,  1.9723, -0.9850,  0.8308, -1.2105]])\n",
      "tensor([[-1.6510,  2.0936, -0.6363,  0.5354, -1.5476],\n",
      "        [-2.3906,  2.6004, -0.4607,  0.1955, -1.6138],\n",
      "        [-0.3487,  1.8238, -0.8731, -0.2110, -1.3128],\n",
      "        [-1.6512,  1.4083, -0.3659, -0.8012, -0.1179],\n",
      "        [-2.2194,  1.5258, -0.6608,  0.6788, -0.9658]])\n",
      "tensor([[-2.8320, -1.7349,  2.7388, -1.1350, -0.3387],\n",
      "        [-2.1980, -1.3292,  2.2020, -0.9821, -0.0236],\n",
      "        [-0.6043, -0.9691,  1.2020, -0.6294, -0.5534],\n",
      "        [-2.7975, -1.0822,  2.1303, -1.1372,  0.3326],\n",
      "        [-2.1438, -1.7929,  2.2631, -1.3841,  0.2059]])\n",
      "tensor([[-2.6341, -0.9493,  3.0104, -1.3288, -0.5857],\n",
      "        [-2.4299, -1.1932,  2.4965, -0.4900, -0.8697],\n",
      "        [-2.2585, -0.4466,  1.7853, -1.1161,  0.0931],\n",
      "        [-3.1904, -1.6496,  1.6698, -2.0871,  1.4522],\n",
      "        [-2.0161, -0.9322,  2.4904, -0.9449, -0.3621]])\n",
      "tensor([[-2.3657,  1.1967, -0.4414,  0.8678, -0.9602], Acc: 93.000% (28/30)     6/10 \n",
      "        [-1.5429, -0.4985, -0.8087,  1.6377, -0.9659],\n",
      "        [-1.4412,  1.4432, -1.0299,  1.1097, -1.3899],\n",
      "        [-1.8188,  0.0737, -1.8018,  2.7538, -2.1036],\n",
      "        [-1.6503, -0.5770, -1.4129,  1.5407, -0.4865]])\n",
      "tensor([[-2.1756,  0.0829, -1.6571,  2.6853, -2.0298],\n",
      "        [-1.4408, -0.0096, -1.5830,  2.1457, -1.5544],\n",
      "        [-1.5336,  0.8892, -1.3967,  1.9445, -1.8104],\n",
      "        [-2.6079,  0.9902, -0.9115,  2.6918, -2.9918],\n",
      "        [-2.8029,  0.3508, -0.7255,  1.8337, -0.9380]])\n",
      "tensor([[-2.7817, -1.2171,  1.1494, -1.8049,  1.4655],\n",
      "        [-2.8815, -1.3704,  0.5369, -0.1826,  0.7869],\n",
      "        [-2.8584,  0.2431,  0.0620, -0.3507,  0.5703],\n",
      "        [-2.9094, -1.7630,  0.3696, -1.3207,  1.8869],\n",
      "        [-0.8855, -0.5338,  0.5714, -0.3972,  0.3848]])\n",
      "tensor([[-1.9657, -2.0722,  0.1196, -1.8189,  1.8959],\n",
      "        [-1.9383, -1.9961,  0.3401, -1.5667,  1.6541],\n",
      "        [-1.0518, -1.2542,  0.4286, -0.9978,  0.9233],\n",
      "        [-0.1964, -0.1926, -0.0056, -0.9753,  0.2193],\n",
      "        [-2.1070,  1.5982, -0.5526, -0.7524,  0.1412]])\n",
      " [===============================>...] | Loss: 0.447 | Acc: 88.000% (44/50)     10/10 \n",
      "val_loss:  tensor(0.4472) accuracy:  tensor(88)\n",
      "\n",
      "Epoch: 7\n",
      " [==================================>] | Loss: 8.951 | Acc: 72.000% (723/1003)  101/101 \n",
      "tensor([[ 2.7865, -1.8683, -1.3605, -0.3344, -1.7130],\n",
      "        [ 2.7518, -1.5728, -1.8779,  0.0986, -2.0666],\n",
      "        [ 4.6796, -2.2548, -2.2074, -1.0459, -2.5452],\n",
      "        [ 2.1969, -0.6363, -1.3754, -0.0389, -1.7369],\n",
      "        [ 2.9237, -1.3774, -1.0870, -0.9273, -1.5026]])\n",
      "tensor([[ 1.9645, -1.1729, -2.0423,  0.8985, -2.2899], Acc: 100.000% (5/5)      1/10 \n",
      "        [ 2.3083, -0.9727, -0.9486, -0.5609, -1.5191],\n",
      "        [ 0.2746, -1.6970,  0.2611, -1.2431,  0.2102],\n",
      "        [ 2.8132, -0.9752, -0.8310, -1.1793, -1.5138],\n",
      "        [ 2.7375, -1.3276, -1.2309, -0.5820, -1.6470]])\n",
      "tensor([[-0.1623,  1.6645, -1.2179, -0.0769, -1.4813],\n",
      "        [-2.3731,  0.3462, -0.2096,  0.9728, -0.7236],\n",
      "        [-2.2334, -0.6539,  0.7478, -0.1824,  0.1020],\n",
      "        [-2.5223,  2.1852, -1.6272,  0.9435, -1.1452],\n",
      "        [-3.4078,  2.2501, -1.2428,  0.8080, -1.1713]])\n",
      "tensor([[-1.7516,  1.5183,  0.0381,  0.2032, -1.2765],\n",
      "        [-2.9112,  2.9841, -0.5721, -0.0547, -1.5262],\n",
      "        [-1.2130,  2.3138, -0.8951, -0.2573, -1.2506],\n",
      "        [-1.7652,  1.6193, -0.2461, -0.8624, -0.2382],\n",
      "        [-2.4351,  1.9216, -0.9186,  0.3689, -0.7921]])\n",
      "tensor([[-3.0861, -1.9050,  2.6087, -1.2717, -0.1233],\n",
      "        [-1.9556, -0.8649,  2.0966, -1.2075, -0.2338],\n",
      "        [-0.7224, -0.8330,  1.2406, -0.7497, -0.5438],\n",
      "        [-3.0221, -1.0074,  2.4435, -1.7410,  0.3138],\n",
      "        [-2.4429, -1.7361,  2.5298, -1.8593,  0.1892]])\n",
      "tensor([[-3.0113, -0.7961,  2.9193, -1.7219, -0.3502],\n",
      "        [-2.4388, -0.9675,  2.6016, -0.8930, -0.8271],\n",
      "        [-2.1302, -0.2360,  1.5067, -1.2768,  0.1822],\n",
      "        [-2.7157, -1.4450,  1.1416, -2.0934,  1.4673],\n",
      "        [-2.0928, -0.7473,  2.0875, -1.0620, -0.1470]])\n",
      "tensor([[-2.2895,  1.1632, -0.6065,  0.7259, -0.8266], Acc: 90.000% (27/30)     6/10 \n",
      "        [-1.1325, -0.5623, -0.5687,  1.2649, -0.8792],\n",
      "        [-1.7397,  1.3993, -0.8457,  1.4691, -1.9422],\n",
      "        [-2.1282, -0.1853, -2.3818,  3.0244, -2.2070],\n",
      "        [-1.5376, -0.4683, -1.6544,  1.5460, -0.5484]])\n",
      "tensor([[-2.4246, -0.1141, -2.1833,  3.0059, -2.2656],\n",
      "        [-0.8247, -0.3882, -2.3644,  2.2794, -1.9106],\n",
      "        [-1.2606,  0.4576, -1.3289,  1.7232, -1.7213],\n",
      "        [-2.4928,  0.6341, -0.7455,  2.3598, -2.7765],\n",
      "        [-2.9560,  0.1025, -1.3759,  1.5847, -0.3655]])\n",
      "tensor([[-2.9874, -1.2515,  1.0260, -2.0386,  1.6756],\n",
      "        [-2.9630, -1.5936,  0.9782, -1.0000,  1.0810],\n",
      "        [-2.5833,  0.8566,  0.4016, -0.7059,  0.1916],\n",
      "        [-2.7138, -1.9349,  0.2140, -1.6025,  2.0117],\n",
      "        [-0.6203, -0.7153,  0.2677, -0.7708,  0.5938]])\n",
      "tensor([[-2.1391, -2.2437,  0.0750, -2.1265,  2.1429],\n",
      "        [-2.9252, -2.2825,  0.4343, -2.1556,  2.2654],\n",
      "        [-1.6895, -1.2803,  0.3536, -1.2733,  1.3379],\n",
      "        [-1.2471,  0.1376, -0.1824, -1.2168,  0.6876],\n",
      "        [-2.6570,  0.9298, -0.3931, -1.2330,  0.8943]])\n",
      " [===============================>...] | Loss: 0.420 | Acc: 88.000% (44/50)     10/10 \n",
      "val_loss:  tensor(0.4199) accuracy:  tensor(88)\n",
      "\n",
      "Epoch: 8\n",
      " [==================================>] | Loss: 8.982 | Acc: 72.000% (727/1003)  101/101 \n",
      "tensor([[ 2.3834, -1.9142, -0.8311, -0.4793, -1.4882],\n",
      "        [ 3.4488, -1.7708, -2.0889, -0.0576, -2.4236],\n",
      "        [ 5.2818, -2.6447, -2.7333, -0.8480, -2.9783],\n",
      "        [ 2.5694, -1.1973, -1.3719, -0.1498, -1.9180],\n",
      "        [ 3.1113, -1.8765, -1.0736, -0.9937, -1.5821]])\n",
      "tensor([[ 2.1966, -0.9133, -2.2874,  1.0266, -2.6481], Acc: 100.000% (5/5)      1/10 \n",
      "        [ 2.5686, -1.2817, -1.0126, -0.5857, -1.6885],\n",
      "        [ 0.7064, -1.7191,  0.3468, -1.5665, -0.0065],\n",
      "        [ 3.3978, -1.3571, -1.2927, -1.0526, -1.9786],\n",
      "        [ 3.0377, -1.7528, -1.2394, -0.7148, -1.7949]])\n",
      "tensor([[ 0.8713,  1.2229, -1.9272,  0.4913, -2.2202],\n",
      "        [-2.8099, -0.0828,  0.6131,  0.9620, -1.0261],\n",
      "        [-1.7769, -0.2498,  0.5807, -0.3787,  0.0549],\n",
      "        [-1.1778,  2.0175, -1.5627,  0.9279, -1.6764],\n",
      "        [-2.5514,  2.0234, -0.7358,  0.6971, -1.4358]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.6636,  1.4304, -0.0173,  0.2838, -1.3275],\n",
      "        [-2.6533,  2.1032, -0.2465, -0.2075, -0.9989],\n",
      "        [ 0.1311,  1.4740, -1.1917,  0.0276, -1.4840],\n",
      "        [-1.8185,  0.6285,  0.0873, -1.0335,  0.3372],\n",
      "        [-2.1453,  1.8978, -0.9268,  0.4488, -1.0301]])\n",
      "tensor([[-3.1219, -1.5713,  3.0088, -1.7271, -0.3490],\n",
      "        [-1.9664, -0.9783,  2.3085, -1.1819, -0.6709],\n",
      "        [-0.9009, -0.5501,  1.4422, -0.7187, -0.7662],\n",
      "        [-3.1578, -0.9837,  2.9243, -1.5182, -0.4847],\n",
      "        [-2.6687, -1.7335,  3.1148, -1.7537, -0.4639]])\n",
      "tensor([[-3.6736, -0.7960,  3.4047, -1.7354, -0.6317],\n",
      "        [-2.8318, -0.5763,  2.8490, -0.9049, -1.1389],\n",
      "        [-2.4057, -0.3242,  1.9227, -1.4985, -0.1081],\n",
      "        [-2.6842, -1.5684,  1.8682, -2.4757,  0.9490],\n",
      "        [-2.4072, -0.5913,  2.5415, -0.8058, -1.1814]])\n",
      "tensor([[-2.2226,  0.8387, -0.3103,  0.9580, -1.3381], Acc: 93.000% (28/30)     6/10 \n",
      "        [-1.0389, -0.4829, -0.3058,  0.8679, -0.6594],\n",
      "        [-1.1151,  1.3741, -1.0797,  1.5644, -2.4023],\n",
      "        [-1.3001, -0.3333, -1.8453,  2.5283, -1.9922],\n",
      "        [-0.7379, -0.7788, -1.3957,  1.9563, -1.5479]])\n",
      "tensor([[-1.7788, -0.4042, -1.5988,  2.7904, -2.4092],\n",
      "        [-0.6406, -0.4523, -1.7129,  2.0573, -1.9438],\n",
      "        [-0.8071,  0.4357, -1.6567,  2.0378, -2.2512],\n",
      "        [-2.5470,  0.7829,  0.0129,  1.9411, -2.7494],\n",
      "        [-3.1760, -0.4175, -0.7344,  1.6696, -0.5587]])\n",
      "tensor([[-2.8546, -1.7638,  1.6220, -2.3135,  1.3345],\n",
      "        [-3.0575, -1.1991,  1.0669, -0.6391,  0.7128],\n",
      "        [-2.7494,  0.6618,  0.1391, -0.1116, -0.0325],\n",
      "        [-2.3636, -1.9482,  0.5348, -1.4228,  1.5647],\n",
      "        [-0.4167, -0.6885,  0.2783, -0.7911,  0.2929]])\n",
      "tensor([[-1.6294, -2.8480,  0.3157, -2.3432,  1.9044],\n",
      "        [-1.9441, -2.0564,  0.9180, -1.9150,  1.3768],\n",
      "        [-1.6287, -1.2555,  0.3384, -1.2287,  1.2488],\n",
      "        [-0.6895, -0.7696, -0.0448, -1.5281,  0.7964],\n",
      "        [-2.4499,  0.9641, -0.3360, -1.0950,  0.5875]])\n",
      " [===============================>...] | Loss: 0.452 | Acc: 88.000% (44/50)     10/10 \n",
      "val_loss:  tensor(0.4517) accuracy:  tensor(88)\n",
      "\n",
      "Epoch: 9\n",
      " [==================================>] | Loss: 8.913 | Acc: 75.000% (762/1003)  101/101 \n",
      "tensor([[ 1.7520, -1.5619, -1.2568,  0.0982, -1.3108],\n",
      "        [ 3.0661, -1.2815, -2.4132,  0.3759, -2.5690],\n",
      "        [ 5.6079, -2.8543, -3.2166, -0.8258, -3.2785],\n",
      "        [ 2.2816, -0.8918, -1.4197,  0.0348, -1.9695],\n",
      "        [ 2.8455, -1.7140, -1.2334, -0.8342, -1.4364]])\n",
      "tensor([[ 1.3210, -0.5633, -2.5207,  1.6840, -2.9623], Acc: 100.000% (5/5)      1/10 \n",
      "        [ 2.6745, -1.1581, -1.3340, -0.4384, -1.9030],\n",
      "        [ 0.8361, -0.9123, -0.3890, -1.0199, -0.1499],\n",
      "        [ 3.5728, -1.4677, -1.5279, -1.0759, -2.1502],\n",
      "        [ 3.0469, -1.7065, -1.4886, -0.5328, -2.0367]])\n",
      "tensor([[ 0.2068,  1.3222, -2.0270,  0.5638, -2.0270],\n",
      "        [-2.8895,  0.5152, -0.2360,  1.4512, -1.3111],\n",
      "        [-2.4965,  0.1687,  0.0201, -0.4061,  0.3665],\n",
      "        [-2.5469,  2.5950, -2.0283,  1.2086, -1.6085],\n",
      "        [-3.0166,  2.5833, -1.1360,  0.5564, -1.3968]])\n",
      "tensor([[-2.3938,  2.0103, -0.2938,  0.4442, -1.5946],\n",
      "        [-3.0934,  2.9184, -0.7136,  0.2244, -1.5874],\n",
      "        [-0.8094,  2.1246, -1.3855, -0.0416, -1.3739],\n",
      "        [-2.6594,  1.4980, -0.6024, -1.2319,  0.4051],\n",
      "        [-2.8198,  2.0118, -1.0038,  0.6055, -1.0607]])\n",
      "tensor([[-3.1296, -1.2554,  2.2828, -1.3192,  0.1629],\n",
      "        [-2.3918, -0.4405,  1.9216, -0.7043, -0.4848],\n",
      "        [-1.1667, -0.2217,  1.2066, -0.5658, -0.5924],\n",
      "        [-3.7238, -0.4254,  2.5825, -1.6062, -0.1482],\n",
      "        [-2.8046, -1.1514,  2.6722, -1.7490, -0.0943]])\n",
      "tensor([[-4.1076,  0.0403,  3.1836, -1.5555, -0.8951],\n",
      "        [-3.0095,  0.0385,  2.4597, -0.4508, -1.1030],\n",
      "        [-2.8586,  0.2010,  1.4701, -0.8200, -0.0704],\n",
      "        [-3.3715, -1.4101,  1.2384, -2.4205,  1.7212],\n",
      "        [-2.9595, -0.2932,  2.4766, -0.3861, -1.2382]])\n",
      "tensor([[-2.9623,  1.0222, -0.5045,  1.4098, -1.6048], Acc: 86.000% (26/30)     6/10 \n",
      "        [-0.9465, -0.0634, -0.8448,  1.3118, -1.3009],\n",
      "        [-1.6928,  1.8950, -1.2045,  1.3505, -2.4435],\n",
      "        [-1.6281, -0.0065, -2.2941,  3.0809, -2.8412],\n",
      "        [-1.3234, -0.2502, -1.6377,  1.8903, -1.2850]])\n",
      "tensor([[-1.9053,  0.1790, -1.9119,  2.7683, -2.6336],\n",
      "        [-1.0399, -0.1382, -2.0528,  2.3390, -2.3378],\n",
      "        [-1.6615,  0.2603, -1.4194,  2.1429, -2.1424],\n",
      "        [-2.9211,  1.4054, -0.6112,  2.4079, -3.3623],\n",
      "        [-3.2921,  0.0573, -1.0774,  1.8647, -0.7851]])\n",
      "tensor([[-4.0325, -0.7082,  1.0486, -2.1804,  1.9539],\n",
      "        [-3.0423, -0.4006,  0.6066, -0.5447,  0.6741],\n",
      "        [-3.9294,  0.9754,  0.0092, -0.4162,  0.2405],\n",
      "        [-3.3354, -1.3181,  0.1206, -1.3564,  2.0121],\n",
      "        [-0.5370, -0.3678,  0.0744, -0.6776,  0.2368]])\n",
      "tensor([[-2.6376, -2.1535, -0.4067, -1.9647,  2.4697],\n",
      "        [-2.7015, -1.8454,  0.4777, -1.9057,  1.8816],\n",
      "        [-2.3165, -0.7882,  0.1004, -0.6681,  1.1415],\n",
      "        [-0.8322,  0.0689, -0.4579, -1.4292,  0.6197],\n",
      "        [-3.6396,  1.0070, -0.6463, -1.2909,  1.1297]])\n",
      " [===============================>...] | Loss: 0.413 | Acc: 88.000% (44/50)     10/10 \n",
      "val_loss:  tensor(0.4129) accuracy:  tensor(88)\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(layers_to_finetune, lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2, verbose=True)   #### dynamic LR scheduler\n",
    "for epoch in range(0, 10):\n",
    "    train(epoch)\n",
    "    test_loss = test(epoch)\n",
    "    scheduler.step(test_loss)\n",
    "    \n",
    "train_loss_file.close()\n",
    "val_loss_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "T6NZo31qn5UO",
    "outputId": "a080a79e-c40d-42f1-823e-0555c4fe46f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nupbZKbiGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x150f2eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_curves(cf.data_dir+experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "n2wiePvSn5UV"
   },
   "outputs": [],
   "source": [
    "## After training we load the model that performed the best on validation data (avoid picking overfitted model)\n",
    "classifier = torch.load(cf.data_dir+'checkpoint/checkpoint_inception_ckpt.t7')['net'].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "EXpwn_Rnn5Ub"
   },
   "outputs": [],
   "source": [
    "def eval():\n",
    "    inception.eval()\n",
    "    \n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        datasets.ImageFolder(valdir, transforms.Compose([\n",
    "            transforms.Resize([299,299]),\n",
    "            #transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])),\n",
    "        batch_size=1, shuffle=False,\n",
    "        num_workers=0, pin_memory=False)\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    conf_mat = np.zeros((num_classes, num_classes))\n",
    "    total_ = np.zeros((num_classes))\n",
    "    wrong_predictions = []\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = Variable(inputs, volatile=True), Variable(targets)\n",
    "        outputs = inception(inputs)\n",
    "        size_ = outputs.size()\n",
    "        outputs_ = outputs.view(size_[0], num_classes)\n",
    "        _, predicted = torch.max(outputs_.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets.data).cpu().sum()\n",
    "        prediction = predicted.cpu().numpy()[0]\n",
    "        targets = targets.data.cpu().numpy()[0]\n",
    "        total_[targets] +=1\n",
    "        conf_mat[predicted, targets] +=1\n",
    "        \n",
    "        if prediction != targets:\n",
    "            wrong_predictions += [[inputs, prediction, targets]]\n",
    "        \n",
    "    for k in range(num_classes):\n",
    "        conf_mat[:,k] /= total_[k]\n",
    "    return conf_mat, 100.*correct/total, wrong_predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "BBo2PB9dn5Uk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vgopired\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: tensor(88) %\n"
     ]
    }
   ],
   "source": [
    "conf, acc, wrong_predictions = eval()\n",
    "print ('Accuracy:', acc, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zqlZgVaIn5Um"
   },
   "source": [
    "Whoa!! :o Fine-tuning improved the accuracy by more than 15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "w2EZW2fen5Un",
    "outputId": "dabf3841-45a5-40ea-bb9b-1adb76bdfa28"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14dd0e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(conf, cmap='jet', vmin=0, vmax = 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "pmEqc9RNn5U2",
    "outputId": "962055bf-557b-4723-bc94-a5138a292321"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baba_ramdev confused with khali\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1be25128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for w in wrong_predictions[::10]:\n",
    "    print (classes[w[2]], 'confused with', classes[w[1]])\n",
    "    plt.imshow(w[0][0][0].data.cpu().numpy(), cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RfkxV5VTn5U8"
   },
   "source": [
    "# Now let's try fine-tuning both the FC layers (full model and Aux model) in the network\n",
    "## This will ensure that Loss computed is much more accurate during training for Aux model\n",
    "### Use the below model to refine Inception V3 - This is accurate than the above fine tuning of only one FC layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception = models.inception_v3(pretrained=True,transform_input=True)\n",
    "#print(inception) - To check the layers of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Two ways to get the weights - \n",
    "\n",
    "#print(inception._modules['fc'].weight)\n",
    "#print(inception._modules['Mixed_7c'].branch_pool.conv.weight)\n",
    "\n",
    "### To print weights and grad's\n",
    "#param = list(inception.parameters())\n",
    "#print(param[-3].data)\n",
    "#print(param[-1].grad.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Define 2 classifiers to replace the Fully connected layers of Inception V3 model - one for actual model and other for Aux model\n",
    "classifier_Aux = nn.Sequential(nn.Linear(768, 192), nn.BatchNorm1d(192), nn.ReLU(),\n",
    "                           nn.Linear(192, 48), nn.BatchNorm1d(48), nn.ReLU(),\n",
    "                           nn.Linear(48, num_classes))\n",
    "classifier = nn.Sequential(nn.Linear(2048, 512), nn.BatchNorm1d(512), nn.ReLU(),\n",
    "                           nn.Linear(512, 32), nn.BatchNorm1d(32), nn.ReLU(),\n",
    "                           nn.Linear(32, num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replace the FC layers\n",
    "inception.AuxLogits.fc = classifier_Aux\n",
    "inception.fc = classifier\n",
    "if use_cuda:\n",
    "    inception.cuda()\n",
    "#print(inception.AuxLogits)\n",
    "#print(inception) # Print the re-defined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "yftZP6vxn5U_"
   },
   "outputs": [],
   "source": [
    "## Freeze all parameters/weights first - this will ensure that loss.backward() (BP) doesn't calculate the gradients\n",
    "for param in inception.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "I8Cudjhkn5VE"
   },
   "outputs": [],
   "source": [
    "## Set the requires_grad to True to only the layers for which we want BP to caclulate gradients\n",
    "for param in inception.AuxLogits.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in inception.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "## Define the layers for which to update the gradients by optimizer\n",
    "layers_to_finetune = [{'params': inception.AuxLogits.fc.parameters()}, \n",
    "                      {'params': inception.fc.parameters()}]\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment this to check which layer parametres/weights will be updated\n",
    "#for param in inception.parameters():\n",
    "    #print(param.requires_grad)  ## Make sure that only required layers are Back propgated with gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "gRA83dH-n5VH"
   },
   "outputs": [],
   "source": [
    "experiment = 'inception_finetune_all_IIC/'\n",
    "train_loss_file = open(cf.data_dir+experiment+\"train_loss.txt\", \"w+\")\n",
    "val_loss_file = open(cf.data_dir+experiment+\"val_loss.txt\", \"w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = 0\n",
    "optimizer = optim.Adam(layers_to_finetune, lr=0.001)  ## Set optimizer to update only te layers we want to update weights\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2, verbose=True)   #### dynamic LR scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "5oDNNHzvn5VJ",
    "outputId": "2ea3ca35-7ad0-4b44-f75b-7b4b77e1b4b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      " [>..................................] | Loss: 3.343 | Acc: 20.000% (2/10)      1/101 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vgopired\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:35: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [==================================>] | Loss: 2.591 | Acc: 48.000% (487/1003)  101/101 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vgopired\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9317, -0.1433, -0.1202, -0.1178, -0.2580],\n",
      "        [ 0.8281, -0.1876, -0.1792,  0.0402, -0.2138],\n",
      "        [ 1.8895, -0.4661, -0.7000, -0.1897, -0.8398],\n",
      "        [ 0.8026, -0.1385, -0.4144, -0.0228, -0.4769],\n",
      "        [ 1.0898, -0.3131, -0.3904, -0.3773, -0.4077]])\n",
      " [>..................................] | Loss: 0.725 | Acc: 100.000% (5/5)      \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 1/10 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vgopired\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7664,  0.0954, -0.2029, -0.0228, -0.3317],\n",
      "        [ 0.9900, -0.2082, -0.0551, -0.1624, -0.3717],\n",
      "        [ 0.8251, -0.3124,  0.0900, -0.3405, -0.2017],\n",
      "        [ 1.0151, -0.1330, -0.3505, -0.2192, -0.3471],\n",
      "        [ 1.4272, -0.2444, -0.4145, -0.1813, -0.6044]])\n",
      "tensor([[ 0.7878,  0.2776, -0.5651,  0.2539, -0.6673],\n",
      "        [-0.3634,  0.4206,  0.2598,  0.4097, -0.1941],\n",
      "        [ 0.1455, -0.0013,  0.1467,  0.1137,  0.0805],\n",
      "        [ 0.1841,  0.8193, -0.4048,  1.3087, -0.6301],\n",
      "        [-0.4901,  0.5761,  0.2194,  0.7840, -0.4428]])\n",
      "tensor([[-0.1810,  0.7919,  0.1580,  0.0753,  0.4726],\n",
      "        [ 0.0302,  1.0029, -0.2341,  0.6762, -0.7193],\n",
      "        [ 0.4048,  0.5397, -0.2984, -0.0478, -0.2612],\n",
      "        [-0.1902,  0.5498,  0.2393,  0.0221,  0.4293],\n",
      "        [ 0.0277,  1.1506, -0.2534,  0.7052, -0.3634]])\n",
      "tensor([[-1.0439, -0.7050,  1.4888, -0.2389, -0.0499],\n",
      "        [-0.8993, -0.3238,  1.3053, -0.3701,  0.6827],\n",
      "        [-0.4792, -0.2400,  0.9491, -0.1751, -0.2843],\n",
      "        [-0.8248, -0.3199,  1.2669, -0.2786,  0.2394],\n",
      "        [-0.9655, -0.4795,  1.8286, -0.3276,  0.9206]])\n",
      "tensor([[-1.2135, -0.9513,  2.3445, -0.7501, -0.7586],\n",
      "        [-0.9101, -0.5713,  1.4196, -0.1615, -0.1898],\n",
      "        [-0.8354, -0.1584,  1.2276, -0.1656,  0.1144],\n",
      "        [-1.0513, -0.0749,  1.3759, -0.3742,  1.4968],\n",
      "        [-1.0336, -0.4354,  1.7068, -0.3999,  0.2472]])\n",
      "tensor([[-0.2225,  0.8656,  0.0424,  0.7302, -0.3591], Acc: 83.000% (25/30)     6/10 \n",
      "        [-0.0552,  0.5005, -0.0624,  1.1859, -0.3092],\n",
      "        [ 0.1871,  0.9855, -0.4260,  1.0988, -0.6652],\n",
      "        [ 0.0831,  0.4497, -0.1664,  0.9672, -0.5059],\n",
      "        [ 0.0422,  0.3020,  0.0162,  0.8893, -0.3048]])\n",
      "tensor([[ 0.0491,  0.7354, -0.3757,  1.9641, -0.8674],\n",
      "        [-0.0763,  0.5296, -0.1275,  1.5287, -0.5097],\n",
      "        [-0.0156,  0.7106, -0.0847,  0.9508, -0.1879],\n",
      "        [-0.3222,  0.5731, -0.0021,  0.9190, -0.5946],\n",
      "        [-0.2422,  0.1961,  0.1011,  0.7497, -0.4076]])\n",
      "tensor([[-1.0538, -0.1253,  1.5473, -0.3395,  1.8744],\n",
      "        [-0.3245, -0.0711,  0.5487, -0.1046,  0.1156],\n",
      "        [-0.3769,  0.7038,  0.3416,  0.2489,  0.3590],\n",
      "        [-1.0329,  0.1001,  1.2188, -0.1533,  1.7729],\n",
      "        [ 0.0012,  0.0962,  0.3447, -0.0848,  0.2168]])\n",
      "tensor([[-0.3213, -0.3874,  1.0087, -0.4921,  1.2633],\n",
      "        [-0.7744,  0.1261,  0.8878, -0.2242,  1.4197],\n",
      "        [-0.3435, -0.1544,  0.9690, -0.2252,  0.6561],\n",
      "        [ 0.4143, -0.3066,  0.3747, -0.3432, -0.0936],\n",
      "        [-0.2052,  1.0572,  0.1361,  0.3189,  0.4988]])\n",
      " [===============================>...] | Loss: 0.947 | Acc: 76.000% (38/50)     10/10 \n",
      "val_loss:  tensor(0.9475) accuracy:  tensor(76)\n",
      "Saving..\n",
      "\n",
      "Epoch: 1\n",
      " [==================================>] | Loss: 1.908 | Acc: 63.000% (637/1003)  101/101 \n",
      "tensor([[ 1.7598, -0.6625, -0.5986, -0.1997, -0.6950],\n",
      "        [ 2.0370, -0.8056, -0.7296, -0.1779, -0.8632],\n",
      "        [ 3.3453, -1.4412, -1.2711, -0.3717, -1.5622],\n",
      "        [ 2.3494, -0.8117, -1.1481, -0.0897, -1.2878],\n",
      "        [ 1.7443, -0.7717, -0.6589, -0.5005, -0.6848]])\n",
      "tensor([[ 1.4370, -0.2555, -0.7143,  0.0886, -0.8765], Acc: 100.000% (5/5)      1/10 \n",
      "        [ 1.7909, -0.6413, -0.4695, -0.1314, -0.9068],\n",
      "        [ 1.3677, -0.6006, -0.1985, -0.3413, -0.4917],\n",
      "        [ 2.0566, -0.8629, -0.7251, -0.4640, -0.9010],\n",
      "        [ 2.3526, -0.9166, -0.8295, -0.2333, -1.0989]])\n",
      "tensor([[ 0.4569,  0.5568, -0.9920,  1.0917, -1.1596],\n",
      "        [-0.8835,  0.2578,  0.5176,  0.5297, -0.3288],\n",
      "        [ 0.0710,  0.0233,  0.0713,  0.0268, -0.0872],\n",
      "        [-0.3535,  0.8675, -0.5405,  1.5406, -0.6046],\n",
      "        [-0.6710,  0.9072, -0.2695,  1.3180, -0.6026]])\n",
      "tensor([[-0.0417,  1.0904, -0.3740,  0.0384, -0.5005],\n",
      "        [-0.3509,  1.2398, -0.5370,  0.7615, -1.1464],\n",
      "        [ 0.4926,  1.0091, -0.8057, -0.0597, -0.9024],\n",
      "        [-0.3418,  0.8693, -0.0203, -0.0428,  0.0509],\n",
      "        [-0.3865,  1.5569, -0.9145,  1.4136, -1.2846]])\n",
      "tensor([[-1.5249, -0.7686,  2.0241, -0.4365,  0.3570],\n",
      "        [-1.2669, -0.7926,  1.8368, -0.5254,  0.0745],\n",
      "        [-0.5677, -0.5026,  1.2074, -0.3773, -0.5510],\n",
      "        [-1.5906, -0.7999,  2.2603, -0.7010,  0.3145],\n",
      "        [-0.9631, -0.4076,  1.5851, -0.6224,  1.0262]])\n",
      "tensor([[-1.5047, -0.8360,  2.6052, -0.9415, -1.1201],\n",
      "        [-1.5668, -0.8328,  2.0819, -0.3967, -0.5498],\n",
      "        [-1.2166, -0.2216,  1.5551, -0.2919, -0.5352],\n",
      "        [-1.6087, -0.2345,  1.6468, -0.8322,  1.9600],\n",
      "        [-1.2829, -0.6991,  2.0114, -0.5999, -0.1969]])\n",
      "tensor([[-0.7987,  0.9643, -0.4148,  1.6392, -1.1646], Acc: 80.000% (24/30)     6/10 \n",
      "        [-0.2627,  0.5856, -0.3089,  1.4186, -0.3790],\n",
      "        [-0.3061,  1.2078, -0.7768,  1.5992, -0.9666],\n",
      "        [-0.5734,  0.4701, -0.2929,  2.0241, -0.8472],\n",
      "        [-0.4266,  0.4186, -0.3358,  1.9665, -0.4215]])\n",
      "tensor([[-0.7564,  0.7069, -0.5050,  2.7303, -0.8641],\n",
      "        [-0.6088,  0.6189, -0.4947,  2.4323, -0.8119],\n",
      "        [-0.2711,  0.9810, -0.5916,  1.3884, -0.8162],\n",
      "        [-0.2594,  0.9569, -0.5831,  1.1027, -1.5073],\n",
      "        [-0.7557,  0.2405, -0.1162,  1.7243, -0.9697]])\n",
      "tensor([[-1.4959, -0.1905,  1.4053, -0.5399,  2.1747],\n",
      "        [-0.8241, -0.1386,  0.8586, -0.0073,  0.4267],\n",
      "        [-0.5774,  0.8427,  0.1837,  0.1302,  0.0106],\n",
      "        [-1.4880, -0.0310,  1.1141, -0.3875,  2.1178],\n",
      "        [-0.2624,  0.0644,  0.5466, -0.1337,  0.5735]])\n",
      "tensor([[-0.8532, -0.5257,  1.0402, -0.7048,  1.7492],\n",
      "        [-1.2810, -0.0609,  1.0616, -0.3679,  1.9821],\n",
      "        [-0.1211, -0.3117,  0.6994, -0.3639,  0.3520],\n",
      "        [ 0.3435, -0.3123,  0.2819, -0.3629,  0.2142],\n",
      "        [-0.5177,  1.4351, -0.1760,  0.1078,  0.2066]])\n",
      " [===============================>...] | Loss: 0.687 | Acc: 78.000% (39/50)     10/10 \n",
      "val_loss:  tensor(0.6868) accuracy:  tensor(78)\n",
      "Saving..\n",
      "\n",
      "Epoch: 2\n",
      " [==================================>] | Loss: 1.657 | Acc: 66.000% (663/1003)  101/101 \n",
      "tensor([[ 1.6708, -0.6654, -0.6009, -0.1425, -0.6202],\n",
      "        [ 2.4755, -0.9873, -0.8518, -0.2416, -1.1071],\n",
      "        [ 3.8071, -1.5585, -1.3056, -0.7764, -1.9007],\n",
      "        [ 1.8114, -0.5950, -0.7289, -0.1108, -0.9067],\n",
      "        [ 2.0755, -0.9977, -0.6926, -0.7251, -0.8654]])\n",
      "tensor([[ 1.3244, -0.3782, -0.5377,  0.1064, -0.7297], Acc: 100.000% (5/5)      1/10 \n",
      "        [ 1.8153, -0.6862, -0.4921, -0.2942, -0.8167],\n",
      "        [ 0.5825, -0.6355,  0.4297, -0.6639,  0.1087],\n",
      "        [ 2.1470, -0.7630, -0.5743, -0.7468, -1.1079],\n",
      "        [ 2.5027, -0.9905, -0.7874, -0.4300, -1.1907]])\n",
      "tensor([[ 0.2604,  0.8316, -0.9674,  0.9162, -1.0794],\n",
      "        [-1.4536,  0.1693,  0.8986,  0.2621,  0.4976],\n",
      "        [-0.7314, -0.0897,  0.6269,  0.2669, -0.4559],\n",
      "        [-0.7482,  1.4951, -0.7655,  1.3661, -0.4633],\n",
      "        [-1.3519,  1.4668,  0.0346,  0.7570, -0.6885]])\n",
      "tensor([[-1.1598,  1.5497,  0.1954,  0.1104, -0.3370],\n",
      "        [-0.9850,  2.1142, -0.3830,  0.3958, -1.1810],\n",
      "        [-0.0387,  1.3164, -0.4389, -0.2671, -0.7702],\n",
      "        [-1.0501,  1.5736,  0.1126, -0.1347,  0.1121],\n",
      "        [-1.3079,  1.9122, -0.4259,  0.9653, -1.0878]])\n",
      "tensor([[-1.8268, -0.9987,  2.0599, -0.5737,  0.7331],\n",
      "        [-1.9791, -0.9702,  2.1371, -0.4815,  0.5154],\n",
      "        [-0.8585, -0.6762,  1.3338, -0.2627, -0.2915],\n",
      "        [-2.0964, -0.8361,  2.3029, -0.7480,  0.4944],\n",
      "        [-1.4947, -0.7758,  1.9148, -0.9206,  1.1380]])\n",
      "tensor([[-2.1147, -1.0233,  2.8388, -0.9766, -0.6011],\n",
      "        [-2.2503, -1.1977,  2.4629, -0.3758, -0.1504],\n",
      "        [-1.5393, -0.4231,  1.8425, -0.5248,  0.2222],\n",
      "        [-2.4852, -0.6806,  2.1895, -1.2756,  2.6520],\n",
      "        [-2.2146, -0.9275,  2.4564, -0.6780,  0.3832]])\n",
      "tensor([[-1.2780,  1.1036, -0.1782,  1.3035, -0.7412], Acc: 86.000% (26/30)     6/10 \n",
      "        [-0.6854,  0.3340, -0.0455,  1.2164, -0.0477],\n",
      "        [-1.0670,  1.6385, -0.6407,  1.5091, -1.3249],\n",
      "        [-0.9564,  0.4826, -0.3143,  1.9916, -0.8699],\n",
      "        [-0.9543,  0.5984, -0.3993,  2.1873, -0.6668]])\n",
      "tensor([[-1.0456,  0.8995, -0.6336,  2.6003, -1.1723],\n",
      "        [-0.7969,  0.9869, -0.8089,  2.6095, -0.8502],\n",
      "        [-0.8592,  0.9735, -0.4748,  1.6950, -0.6416],\n",
      "        [-1.4234,  0.7983, -0.3122,  2.1946, -1.8358],\n",
      "        [-1.2023,  0.5168, -0.0302,  1.4800, -0.8763]])\n",
      "tensor([[-2.1034, -0.1234,  1.4303, -0.8515,  2.6911],\n",
      "        [-1.3042, -0.4260,  0.9822,  0.0066,  0.8819],\n",
      "        [-1.1604,  0.6848,  0.6091, -0.0827,  0.5164],\n",
      "        [-2.0987, -0.1820,  1.0414, -0.4913,  2.7369],\n",
      "        [-0.7701,  0.0962,  0.6240, -0.2361,  0.8227]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.7249, -0.2743,  0.9642, -0.8589,  2.5411],\n",
      "        [-2.2306, -0.0689,  1.0114, -0.7027,  2.9024],\n",
      "        [-0.9121, -0.1745,  0.7932, -0.4339,  1.1846],\n",
      "        [-0.9353, -0.1620,  0.9539, -0.1978,  0.6723],\n",
      "        [-1.2177,  2.0409, -0.1589,  0.1470, -0.0502]])\n",
      " [===============================>...] | Loss: 0.591 | Acc: 82.000% (41/50)     10/10 \n",
      "val_loss:  tensor(0.5912) accuracy:  tensor(82)\n",
      "Saving..\n",
      "\n",
      "Epoch: 3\n",
      " [==================================>] | Loss: 1.467 | Acc: 69.000% (694/1003)  101/101 \n",
      "tensor([[ 1.5638, -0.6611, -0.7063,  0.2968, -0.9638],\n",
      "        [ 3.1874, -1.4321, -1.3200,  0.0287, -1.6988],\n",
      "        [ 4.3322, -1.9789, -1.6889, -0.4104, -2.2772],\n",
      "        [ 1.7705, -0.6492, -1.2403,  0.7200, -1.2509],\n",
      "        [ 2.2431, -1.1955, -0.6679, -0.5450, -0.9873]])\n",
      "tensor([[ 1.6271, -0.5093, -0.7469,  0.2328, -0.9236], Acc: 100.000% (5/5)      1/10 \n",
      "        [ 2.0279, -0.8072, -0.5620, -0.2811, -0.9943],\n",
      "        [ 0.5333, -0.7867,  0.3221, -0.7117,  0.1991],\n",
      "        [ 2.3830, -0.8684, -0.7116, -0.4975, -1.3318],\n",
      "        [ 2.7166, -1.2338, -0.8988, -0.3546, -1.3498]])\n",
      "tensor([[-0.3240,  1.1000, -1.0716,  1.4827, -1.0751],\n",
      "        [-1.5634,  0.0027,  0.7807,  0.6252,  0.2383],\n",
      "        [-0.8837, -0.1802,  0.8322,  0.0780, -0.1684],\n",
      "        [-0.7534,  1.4558, -0.8337,  1.3441, -0.7511],\n",
      "        [-1.6710,  1.9337, -0.3256,  1.1191, -0.6310]])\n",
      "tensor([[-0.9775,  1.8370, -0.2979,  0.1201, -0.7211],\n",
      "        [-1.2121,  2.5549, -0.6883,  0.5530, -1.4618],\n",
      "        [-0.6837,  2.0712, -0.5906, -0.1370, -1.0332],\n",
      "        [-1.6712,  2.1969, -0.0499, -0.0910,  0.3327],\n",
      "        [-1.1926,  1.9020, -0.5986,  0.6991, -0.6883]])\n",
      "tensor([[-2.4611, -1.3103,  2.4658, -0.7482,  0.9651],\n",
      "        [-1.6444, -1.1341,  1.9516, -0.6390,  0.5000],\n",
      "        [-1.3634, -0.6776,  1.6411, -0.3620, -0.0059],\n",
      "        [-2.3508, -0.8470,  2.3538, -0.7960,  0.5352],\n",
      "        [-1.7184, -0.6353,  1.6811, -0.9984,  1.7993]])\n",
      "tensor([[-2.6448, -0.7464,  3.1424, -1.2021, -0.7237],\n",
      "        [-2.1919, -1.0197,  2.6444, -0.6716, -0.5358],\n",
      "        [-1.7915, -0.5307,  1.9111, -0.4332, -0.0680],\n",
      "        [-2.1180, -0.7011,  1.8902, -1.2751,  2.0073],\n",
      "        [-2.0690, -0.9843,  2.2811, -0.5714,  0.1917]])\n",
      "tensor([[-1.0295,  0.9224, -0.5549,  1.7507, -0.7255], Acc: 83.000% (25/30)     6/10 \n",
      "        [-0.4616,  0.0802, -0.2578,  1.5461, -0.2274],\n",
      "        [-0.8869,  1.6501, -1.0360,  1.5688, -1.3351],\n",
      "        [-0.6761,  0.3217, -0.5341,  2.2381, -1.1555],\n",
      "        [-0.9401,  0.0712, -0.3700,  2.4984, -0.4541]])\n",
      "tensor([[-0.9570,  0.6174, -0.7721,  2.9713, -1.5929],\n",
      "        [-0.7026,  0.5776, -0.9489,  2.8711, -1.2899],\n",
      "        [-0.6160,  0.5810, -0.4780,  1.5608, -0.5314],\n",
      "        [-0.9396,  0.5002, -0.4500,  2.0621, -1.4331],\n",
      "        [-1.4116,  0.4513, -0.3569,  2.3847, -1.1279]])\n",
      "tensor([[-2.5927,  0.1808,  1.3512, -0.7961,  2.7927],\n",
      "        [-1.6981, -0.3642,  1.2108, -0.0683,  0.7239],\n",
      "        [-1.5877,  1.4749,  0.1153,  0.1571,  0.7352],\n",
      "        [-2.3726, -0.4384,  0.9202, -0.4730,  2.9543],\n",
      "        [-1.0723,  0.2189,  0.5620, -0.2030,  1.1410]])\n",
      "tensor([[-2.1415, -0.6915,  1.1392, -1.0016,  2.9539],\n",
      "        [-2.6384, -0.4291,  1.1430, -0.7900,  3.2284],\n",
      "        [-1.0735, -0.2864,  0.7179, -0.3523,  1.2371],\n",
      "        [-0.6428,  0.0529,  0.2229, -0.0686,  1.0247],\n",
      "        [-1.5557,  2.1117, -0.2996,  0.0752,  0.6406]])\n",
      " [===============================>...] | Loss: 0.520 | Acc: 82.000% (41/50)     10/10 \n",
      "val_loss:  tensor(0.5197) accuracy:  tensor(82)\n",
      "\n",
      "Epoch: 4\n",
      " [==================================>] | Loss: 1.478 | Acc: 66.000% (662/1003)  101/101 \n",
      "tensor([[ 2.1325, -0.9323, -1.0557,  0.3870, -1.1825],\n",
      "        [ 3.5013, -1.4342, -2.0705,  0.8160, -2.0768],\n",
      "        [ 5.3190, -2.3465, -2.4278, -0.1040, -2.9443],\n",
      "        [ 3.5263, -1.3175, -2.1308,  0.6661, -2.2162],\n",
      "        [ 3.2760, -1.5480, -1.3151, -0.3236, -1.6454]])\n",
      "tensor([[ 1.6800, -0.3274, -1.3675,  1.1208, -1.4509], Acc: 100.000% (5/5)      1/10 \n",
      "        [ 3.0149, -1.1660, -1.2516,  0.0389, -1.7206],\n",
      "        [ 1.6299, -1.1049, -0.2043, -0.7021, -0.5846],\n",
      "        [ 3.4779, -1.1839, -1.5418, -0.2152, -2.2261],\n",
      "        [ 3.6580, -1.3845, -1.7658,  0.1504, -2.1361]])\n",
      "tensor([[-0.0327,  1.7105, -2.0448,  1.9097, -2.2219],\n",
      "        [-1.6352,  0.2970,  0.0484,  1.8885, -0.7167],\n",
      "        [-0.1833,  0.1682,  0.0719,  0.4578, -1.0012],\n",
      "        [-1.0466,  1.9165, -1.4822,  2.0422, -1.4186],\n",
      "        [-1.9615,  2.0734, -0.3577,  1.1564, -0.7991]])\n",
      "tensor([[-0.6409,  1.7518, -1.0140,  0.7417, -1.4699],\n",
      "        [-1.2340,  3.0570, -1.1722,  0.6515, -1.8351],\n",
      "        [-0.3710,  2.7021, -1.5207,  0.1058, -1.8038],\n",
      "        [-1.8126,  2.7339, -0.1701, -0.3126, -0.3259],\n",
      "        [-1.2828,  2.4129, -1.1067,  1.0672, -1.7392]])\n",
      "tensor([[-1.3458, -1.4790,  1.9437, -0.8457,  0.8613],\n",
      "        [-1.1986, -1.4885,  2.1325, -0.9157, -0.3255],\n",
      "        [-0.0909, -1.0641,  1.2263, -0.6532, -0.8076],\n",
      "        [-1.6354, -0.4462,  2.0329, -0.7214, -0.4106],\n",
      "        [-0.4497, -1.1784,  1.4971, -1.2912,  0.5744]])\n",
      "tensor([[-1.9989, -0.0786,  2.4555, -1.1241, -1.1915],\n",
      "        [-1.4853, -1.2354,  2.3787, -0.7183, -0.7527],\n",
      "        [-1.4508, -0.7980,  2.0902, -0.7306, -0.4520],\n",
      "        [-1.7277, -0.9256,  2.0432, -1.7843,  1.7203],\n",
      "        [-1.9414, -1.0578,  2.6755, -0.7985, -0.9340]])\n",
      "tensor([[-1.5674,  1.1703, -0.7289,  2.2303, -1.6116], Acc: 86.000% (26/30)     6/10 \n",
      "        [-0.2710,  0.1354, -0.8259,  2.2281, -1.0269],\n",
      "        [-0.5148,  1.5555, -1.6820,  2.2186, -1.9705],\n",
      "        [-0.2794,  0.2003, -1.1601,  2.6458, -1.5633],\n",
      "        [-1.1122, -0.2543, -0.5815,  3.0431, -0.7568]])\n",
      "tensor([[-1.1028,  0.3139, -1.0360,  3.5620, -2.0518],\n",
      "        [-1.0329,  0.2429, -1.1924,  3.6569, -1.8382],\n",
      "        [-0.6431,  0.7763, -1.0680,  2.2783, -1.5997],\n",
      "        [-1.5614,  0.6224, -0.8698,  3.2999, -2.5206],\n",
      "        [-1.5192,  0.2015, -0.3017,  2.3115, -1.2426]])\n",
      "tensor([[-1.8343,  0.1155,  1.0247, -1.0947,  2.1987],\n",
      "        [-1.5332, -0.1513,  0.2455,  1.2176,  0.1639],\n",
      "        [-1.8521,  2.3367, -0.0767,  0.3053, -0.5733],\n",
      "        [-0.9996, -0.5983,  0.3064, -0.3371,  1.8722],\n",
      "        [-0.0533, -0.1676,  0.2355, -0.3839,  0.3078]])\n",
      "tensor([[-0.8184, -1.0651,  0.4029, -1.2726,  2.0996],\n",
      "        [-1.4230, -0.6741,  0.7450, -0.6539,  2.1825],\n",
      "        [-0.5522, -0.3713,  0.3678, -0.1846,  0.7642],\n",
      "        [ 0.3313,  0.0187, -0.3507,  0.0781,  0.0168],\n",
      "        [-1.8703,  2.7962, -0.5328,  0.0771, -0.1602]])\n",
      " [===============================>...] | Loss: 0.533 | Acc: 84.000% (42/50)     10/10 \n",
      "val_loss:  tensor(0.5333) accuracy:  tensor(84)\n",
      "Saving..\n",
      "\n",
      "Epoch: 5\n",
      " [==================================>] | Loss: 1.199 | Acc: 70.000% (710/1003)  101/101 \n",
      "tensor([[ 2.2700, -1.2636, -0.6564, -0.3934, -1.1841],\n",
      "        [ 4.0741, -1.8684, -1.5474, -0.3086, -2.2191],\n",
      "        [ 5.5324, -2.6851, -1.8711, -1.2877, -2.9029],\n",
      "        [ 2.9856, -1.3946, -1.0596, -0.2269, -1.6553],\n",
      "        [ 2.5751, -1.5539, -0.5065, -1.2359, -1.0506]])\n",
      "tensor([[ 1.6781, -0.3852, -1.0456,  0.2544, -1.1481], Acc: 100.000% (5/5)      1/10 \n",
      "        [ 2.6595, -1.2818, -0.7272, -0.6874, -1.3093],\n",
      "        [ 1.4049, -1.0975,  0.0218, -1.1103, -0.4695],\n",
      "        [ 3.2113, -1.3428, -0.8801, -0.9482, -1.7594],\n",
      "        [ 3.4903, -1.4456, -1.2932, -0.6893, -1.9724]])\n",
      "tensor([[-0.2744,  1.6364, -1.5064,  1.2892, -1.6430],\n",
      "        [-1.4994, -0.0205,  0.3050,  1.3060, -0.0389],\n",
      "        [-0.6755, -0.3430,  1.0869, -0.3456, -0.6189],\n",
      "        [-1.2894,  1.8572, -1.0725,  1.4902, -0.4355],\n",
      "        [-1.6678,  1.6947, -0.1698,  0.7476, -0.3332]])\n",
      "tensor([[-0.9531,  1.4116, -0.2489,  0.1605, -0.4550],\n",
      "        [-0.8369,  2.6575, -1.1621,  0.4194, -1.5568],\n",
      "        [ 0.3512,  0.9375, -0.5853, -0.6610, -1.0955],\n",
      "        [-1.7640,  1.8597,  0.4766, -0.6524,  0.2784],\n",
      "        [-1.1641,  1.7458, -0.5804,  0.6199, -0.7953]])\n",
      "tensor([[-1.7252, -1.4269,  2.3330, -1.2655,  0.9156],\n",
      "        [-1.8611, -1.2913,  2.2242, -0.7908,  0.1513],\n",
      "        [-0.6383, -1.0411,  1.6132, -0.9203, -0.4038],\n",
      "        [-2.1745, -0.7111,  2.5357, -1.0243, -0.1420],\n",
      "        [-1.0170, -1.1473,  2.0058, -1.5515,  0.4992]])\n",
      "tensor([[-2.4085, -0.3274,  2.9658, -1.4573, -0.7248],\n",
      "        [-1.9604, -1.2760,  2.7416, -1.1461, -0.2520],\n",
      "        [-1.7034, -0.7323,  1.9832, -0.8967,  0.3042],\n",
      "        [-1.8281, -0.9243,  1.8030, -1.7775,  2.0596],\n",
      "        [-2.1031, -0.9597,  2.2465, -0.5083, -0.2053]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.2772,  0.7166, -0.6395,  1.9181, -0.5964], Acc: 90.000% (27/30)     6/10 \n",
      "        [-0.9192,  0.1545, -0.5143,  1.8341,  0.0299],\n",
      "        [-0.5735,  1.3605, -1.4213,  1.9840, -1.6715],\n",
      "        [ 0.0404,  0.0778, -1.0625,  1.9265, -1.3018],\n",
      "        [-1.2976, -0.3747, -0.3269,  2.7648, -0.6404]])\n",
      "tensor([[-1.0546,  0.7192, -1.1252,  3.0817, -2.0389],\n",
      "        [-1.2293,  0.3574, -0.8434,  3.0089, -1.4542],\n",
      "        [-0.9035,  0.5057, -0.4820,  1.7178, -0.8371],\n",
      "        [-1.9462,  0.7692, -0.2841,  2.5027, -2.1158],\n",
      "        [-1.3786,  0.1006, -0.1476,  1.8490, -0.8220]])\n",
      "tensor([[-2.3896,  0.2824,  1.0219, -1.3121,  2.8904],\n",
      "        [-1.5839,  0.0145,  1.0877, -0.4144,  0.7268],\n",
      "        [-1.6218,  1.6682,  0.3821, -0.4735,  0.5602],\n",
      "        [-1.8318, -0.6179,  0.5853, -0.4554,  2.4997],\n",
      "        [-0.4435, -0.2345,  0.5938, -0.7076,  0.6343]])\n",
      "tensor([[-1.3660, -0.8982,  0.4056, -1.4435,  2.6828],\n",
      "        [-1.6309, -0.8203,  0.7993, -0.9893,  2.5372],\n",
      "        [-0.8464, -0.4152,  0.3265, -0.2794,  1.2357],\n",
      "        [ 0.7472, -0.2051, -0.6360, -0.1705, -0.0774],\n",
      "        [-1.6354,  1.7076,  0.0205, -0.2575,  0.7705]])\n",
      " [===============================>...] | Loss: 0.482 | Acc: 86.000% (43/50)     10/10 \n",
      "val_loss:  tensor(0.4823) accuracy:  tensor(86)\n",
      "Saving..\n",
      "\n",
      "Epoch: 6\n",
      " [==================================>] | Loss: 1.172 | Acc: 71.000% (718/1003)  101/101 \n",
      "tensor([[ 2.0218, -1.0909, -1.0980,  0.0018, -0.7282],\n",
      "        [ 3.4562, -1.6032, -1.8194,  0.3732, -1.8595],\n",
      "        [ 5.2483, -2.6894, -2.1751, -0.9213, -2.1543],\n",
      "        [ 2.4376, -1.1277, -1.4512,  0.4248, -1.2087],\n",
      "        [ 2.7098, -1.5438, -0.6983, -1.3359, -0.9686]])\n",
      "tensor([[ 1.6913, -0.2011, -1.5099,  0.5081, -1.4641], Acc: 100.000% (5/5)      1/10 \n",
      "        [ 2.4999, -1.0228, -0.8994, -0.6196, -1.2786],\n",
      "        [ 1.5263, -1.2004,  0.0954, -1.2505, -0.4448],\n",
      "        [ 3.0203, -0.9691, -1.0631, -0.8456, -1.8694],\n",
      "        [ 3.5652, -1.3672, -1.5867, -0.7201, -2.0208]])\n",
      "tensor([[-0.2620,  2.3670, -2.1489,  1.0872, -2.1807],\n",
      "        [-1.8807,  0.3574,  0.4306,  0.9770, -0.1203],\n",
      "        [-1.2314,  0.4305,  0.6641,  0.1689, -0.6094],\n",
      "        [-2.0039,  2.7609, -1.2290,  1.0576, -0.6663],\n",
      "        [-2.1628,  2.7699, -0.3424,  0.4732, -1.0794]])\n",
      "tensor([[-1.5495,  2.4758, -0.8572,  0.3778, -1.0799],\n",
      "        [-1.7376,  3.9473, -1.5905,  0.3647, -2.3786],\n",
      "        [-0.4781,  2.4075, -1.0801, -0.5771, -1.8631],\n",
      "        [-1.7543,  2.4569,  0.1077, -0.5798, -0.6222],\n",
      "        [-1.6280,  2.5854, -1.0929,  0.7382, -1.5297]])\n",
      "tensor([[-2.3448, -1.4192,  2.6683, -1.3585,  0.8492],\n",
      "        [-1.8577, -1.0773,  2.0968, -0.9024,  0.4483],\n",
      "        [-0.7575, -0.8097,  1.3918, -0.6760, -0.0996],\n",
      "        [-2.5849, -0.7253,  2.8146, -1.1741, -0.1637],\n",
      "        [-1.5215, -0.7541,  1.9720, -1.5074,  1.0396]])\n",
      "tensor([[-2.4558, -0.1164,  2.9833, -1.6146, -1.1355],\n",
      "        [-2.6589, -1.2628,  2.9612, -1.0645, -0.2680],\n",
      "        [-2.0554, -0.6586,  2.2659, -1.0161,  0.1108],\n",
      "        [-2.4917, -0.4370,  2.0568, -1.9359,  2.0939],\n",
      "        [-2.2356, -0.6488,  2.4094, -0.9261, -0.2857]])\n",
      "tensor([[-1.7550,  1.8459, -0.7326,  1.3265, -1.5257], Acc: 90.000% (27/30)     6/10 \n",
      "        [-1.3342,  0.0164, -0.1874,  1.8609, -0.0952],\n",
      "        [-1.3351,  2.5964, -1.6701,  1.4547, -1.9039],\n",
      "        [-0.8123,  0.3900, -1.0520,  2.0072, -0.7237],\n",
      "        [-1.0372, -0.0764, -0.4294,  2.3633, -0.7405]])\n",
      "tensor([[-1.3005,  1.1492, -1.2482,  2.7558, -2.0425],\n",
      "        [-1.3175,  0.6741, -0.9147,  2.6752, -1.5303],\n",
      "        [-1.2581,  1.5504, -1.2921,  1.8388, -1.1913],\n",
      "        [-2.1202,  1.1747, -0.5837,  2.7156, -2.7140],\n",
      "        [-1.7275,  0.1708,  0.0975,  1.5964, -0.6452]])\n",
      "tensor([[-3.3084,  0.6969,  1.2247, -1.4966,  3.2016],\n",
      "        [-2.7735, -0.2895,  1.4012, -0.2060,  1.2285],\n",
      "        [-2.3232,  2.4519, -0.0407, -0.2611,  0.5114],\n",
      "        [-2.8886, -0.1989,  0.9343, -0.7940,  3.2980],\n",
      "        [-0.3909, -0.1602,  0.2710, -0.6289,  0.8613]])\n",
      "tensor([[-1.9194, -0.8783,  0.4744, -1.6025,  3.3072],\n",
      "        [-2.8449, -0.2883,  1.1557, -1.2487,  3.3403],\n",
      "        [-1.4129, -0.3961,  0.7511, -0.4417,  1.3523],\n",
      "        [ 0.0770, -0.0357, -0.3865,  0.0374,  0.4288],\n",
      "        [-2.0764,  2.2621, -0.2165, -0.3802,  0.7652]])\n",
      " [===============================>...] | Loss: 0.442 | Acc: 84.000% (42/50)     10/10 \n",
      "val_loss:  tensor(0.4422) accuracy:  tensor(84)\n",
      "\n",
      "Epoch: 7\n",
      " [==================================>] | Loss: 1.067 | Acc: 71.000% (721/1003)  101/101 \n",
      "tensor([[ 2.9788, -1.5282, -1.2367, -0.2395, -1.3893],\n",
      "        [ 4.0581, -1.7845, -1.9244,  0.1485, -2.3212],\n",
      "        [ 5.7856, -2.9211, -1.8713, -1.3058, -2.7510],\n",
      "        [ 3.2276, -1.5923, -1.6921,  0.5623, -1.8119],\n",
      "        [ 2.8892, -1.9608, -0.3615, -1.7222, -0.9845]])\n",
      "tensor([[ 1.9974, -0.6694, -1.6967,  1.0863, -1.5320], Acc: 100.000% (5/5)      1/10 \n",
      "        [ 3.3766, -1.2927, -1.1942, -0.7084, -1.9990],\n",
      "        [ 2.2758, -1.7270,  0.0146, -1.4306, -0.7540],\n",
      "        [ 4.0269, -1.5739, -1.3214, -0.8518, -2.3052],\n",
      "        [ 3.8093, -1.5969, -1.3488, -0.7562, -2.1457]])\n",
      "tensor([[ 0.0271,  1.3185, -2.0331,  1.7368, -2.1245],\n",
      "        [-1.8611, -0.1391,  0.4456,  1.2867, -0.3017],\n",
      "        [-0.5099,  0.4445,  0.0840,  0.4220, -0.9954],\n",
      "        [-1.8903,  1.9325, -1.0655,  1.6153, -0.8385],\n",
      "        [-1.9963,  2.3142, -0.4252,  0.9071, -1.2166]])\n",
      "tensor([[-1.1626,  1.8719, -0.5827,  0.3294, -1.2228],\n",
      "        [-1.4946,  2.7425, -0.9696,  0.5894, -2.1359],\n",
      "        [ 0.0983,  1.6498, -0.9470, -0.3526, -1.7227],\n",
      "        [-1.8462,  2.2447,  0.5074, -0.8548, -0.2994],\n",
      "        [-1.2401,  1.6972, -0.9980,  1.1783, -1.3863]])\n",
      "tensor([[-1.9976, -1.6744,  2.8636, -1.6963,  0.5494],\n",
      "        [-1.6817, -1.2466,  2.3844, -1.5655,  0.2273],\n",
      "        [-0.7701, -1.1246,  1.6552, -0.9948, -0.0783],\n",
      "        [-2.1669, -0.8796,  2.9264, -1.3441, -0.2235],\n",
      "        [-1.3039, -1.0888,  2.1199, -1.7192,  0.9422]])\n",
      "tensor([[-2.5982, -0.3642,  3.6045, -2.0027, -0.9508],\n",
      "        [-2.3249, -1.0102,  2.8381, -1.1363, -0.4819],\n",
      "        [-2.0459, -1.0150,  2.6960, -1.4525, -0.1177],\n",
      "        [-2.3680, -1.0647,  2.5064, -2.4513,  1.8839],\n",
      "        [-2.2292, -0.6936,  2.2697, -0.7086, -0.0256]])\n",
      "tensor([[-1.2347,  1.2272, -1.0103,  1.7493, -1.7124], Acc: 93.000% (28/30)     6/10 \n",
      "        [-0.5977, -0.1759, -0.6436,  1.9349, -0.4972],\n",
      "        [-0.7336,  1.5301, -1.8228,  2.2550, -2.3483],\n",
      "        [-0.8268, -0.2002, -0.8999,  2.6626, -1.1763],\n",
      "        [-1.1769, -0.5171, -0.8968,  3.5229, -1.0035]])\n",
      "tensor([[-1.2743,  0.6489, -1.3198,  3.3594, -2.5507],\n",
      "        [-1.3539, -0.0124, -0.9952,  3.5119, -2.1431],\n",
      "        [-0.9574,  0.4889, -1.0471,  2.5238, -1.4903],\n",
      "        [-1.7116,  1.0422, -1.2229,  3.2936, -3.1253],\n",
      "        [-2.1933, -0.6390,  0.0480,  2.9586, -1.0715]])\n",
      "tensor([[-2.0520, -0.6956,  1.4938, -1.9556,  2.5732],\n",
      "        [-2.4936, -1.1768,  1.6505, -0.3058,  1.5839],\n",
      "        [-2.2480,  1.8924, -0.1607,  0.5780,  0.4253],\n",
      "        [-2.1327, -0.8800,  0.8387, -0.9343,  2.8193],\n",
      "        [-0.7378, -0.7277,  0.4721, -0.3938,  1.2023]])\n",
      "tensor([[-1.5602, -1.5856,  0.7629, -1.9224,  2.9945],\n",
      "        [-1.7484, -0.9403,  0.6709, -1.0067,  2.6792],\n",
      "        [-0.0532, -1.1310,  0.3416, -0.7415,  0.9520],\n",
      "        [ 0.6498, -0.6534, -0.4989, -0.1921,  0.3729],\n",
      "        [-1.7951,  1.6102, -0.2572, -0.0251,  1.0758]])\n",
      " [===============================>...] | Loss: 0.389 | Acc: 88.000% (44/50)     10/10 \n",
      "val_loss:  tensor(0.3886) accuracy:  tensor(88)\n",
      "Saving..\n",
      "\n",
      "Epoch: 8\n",
      " [==================================>] | Loss: 1.098 | Acc: 70.000% (707/1003)  101/101 \n",
      "tensor([[ 1.9843, -1.2865, -0.6733, -0.3885, -0.8835],\n",
      "        [ 3.3814, -0.9257, -2.4864,  0.7466, -2.4754],\n",
      "        [ 4.9485, -1.9091, -2.2841, -0.6619, -2.7713],\n",
      "        [ 2.0289, -0.4400, -1.7609,  0.7755, -1.7444],\n",
      "        [ 2.6474, -1.4026, -0.6452, -1.1747, -1.1785]])\n",
      "tensor([[ 1.5959, -0.2279, -1.6498,  0.7749, -1.4760], Acc: 100.000% (5/5)      1/10 \n",
      "        [ 2.4078, -0.6541, -1.0773, -0.4787, -1.5845],\n",
      "        [ 0.5875, -1.0553,  0.0527, -0.5158,  0.3544],\n",
      "        [ 3.1034, -0.8233, -1.2635, -0.8916, -2.0620],\n",
      "        [ 2.8381, -0.6886, -1.4410, -0.7279, -1.9831]])\n",
      "tensor([[-0.3861,  2.0880, -1.9978,  1.2382, -2.1497],\n",
      "        [-1.6473,  1.1817, -0.5155,  1.6483, -1.2315],\n",
      "        [-0.7725,  0.6894, -0.0189,  0.4815, -0.9705],\n",
      "        [-2.5887,  2.6587, -0.9078,  1.3247, -0.8174],\n",
      "        [-2.3341,  2.6332, -0.5550,  0.8672, -0.9391]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.7991,  2.1745, -0.4421,  0.3550, -0.9966],\n",
      "        [-1.6210,  3.2078, -1.1100,  0.1667, -1.7246],\n",
      "        [-0.8051,  2.4917, -0.9241, -0.6067, -1.1472],\n",
      "        [-2.4006,  2.5848,  0.1668, -0.6576,  0.3489],\n",
      "        [-1.9228,  1.9521, -0.5309,  0.8227, -0.8928]])\n",
      "tensor([[-2.3307, -1.6560,  2.8039, -1.7720,  1.0622],\n",
      "        [-1.6060, -1.4156,  2.4110, -1.3710, -0.1009],\n",
      "        [-1.1471, -0.7424,  1.5666, -0.7536, -0.0222],\n",
      "        [-2.1187, -0.8358,  2.6839, -1.4464,  0.1163],\n",
      "        [-1.0446, -0.9474,  1.9109, -1.7921,  0.8413]])\n",
      "tensor([[-2.1810, -0.3000,  3.1729, -1.9714, -0.7159],\n",
      "        [-2.3216, -1.0345,  2.6479, -0.9403, -0.4917],\n",
      "        [-2.1552, -0.4817,  2.0214, -0.8294,  0.2472],\n",
      "        [-2.4712, -0.7007,  1.8165, -1.9051,  2.1095],\n",
      "        [-2.7636, -0.8775,  2.6429, -0.8234, -0.0913]])\n",
      "tensor([[-1.6226,  1.1920, -0.6337,  1.6941, -1.7632], Acc: 93.000% (28/30)     6/10 \n",
      "        [-0.8965,  0.0121, -0.4685,  1.9399, -0.8077],\n",
      "        [-1.1248,  2.0258, -1.5571,  1.7075, -2.5087],\n",
      "        [-1.6322,  0.3622, -1.0512,  2.9602, -1.4969],\n",
      "        [-0.6474, -0.3263, -0.7412,  2.6413, -1.4630]])\n",
      "tensor([[-1.9053,  1.0789, -0.9429,  3.0010, -2.6150],\n",
      "        [-1.2191,  0.6041, -0.8927,  2.6537, -2.6358],\n",
      "        [-1.7632,  1.4017, -0.7363,  1.6326, -1.4185],\n",
      "        [-1.4157,  1.2674, -1.0552,  2.3030, -3.2171],\n",
      "        [-2.3620, -0.2331,  0.3648,  2.0535, -0.7153]])\n",
      "tensor([[-3.0814,  0.3687,  1.3849, -1.4746,  2.5291],\n",
      "        [-3.2128, -0.3810,  1.5837, -0.1381,  1.3543],\n",
      "        [-2.6328,  1.8731,  0.4416, -0.2235,  0.8456],\n",
      "        [-2.4999, -0.5347,  0.7607, -0.3782,  2.4518],\n",
      "        [-1.2578, -0.2064,  0.6221, -0.6063,  1.2785]])\n",
      "tensor([[-1.9434, -1.0834,  0.6513, -1.4012,  2.9964],\n",
      "        [-2.1519, -0.9896,  0.9014, -1.2586,  2.8647],\n",
      "        [-1.4606, -0.7002,  0.5594, -0.4363,  1.5979],\n",
      "        [-0.7091,  0.0069,  0.0641, -0.1376,  0.8767],\n",
      "        [-2.3274,  2.1354, -0.2236, -0.0833,  0.8918]])\n",
      " [===============================>...] | Loss: 0.406 | Acc: 88.000% (44/50)     10/10 \n",
      "val_loss:  tensor(0.4058) accuracy:  tensor(88)\n",
      "\n",
      "Epoch: 9\n",
      " [==================================>] | Loss: 1.065 | Acc: 69.000% (696/1003)  101/101 \n",
      "tensor([[ 1.9205, -1.2857, -1.0432,  0.0634, -0.7566],\n",
      "        [ 3.4347, -1.5145, -2.1657,  0.8223, -2.0962],\n",
      "        [ 4.5379, -1.9368, -2.1584, -0.3025, -2.5933],\n",
      "        [ 2.2828, -0.9734, -1.6170,  0.7576, -1.3991],\n",
      "        [ 2.5852, -1.6469, -0.6910, -0.8665, -1.0257]])\n",
      "tensor([[ 1.6484,  0.0201, -1.8171,  0.8751, -1.8361], Acc: 100.000% (5/5)      1/10 \n",
      "        [ 2.4863, -0.8139, -1.2321,  0.0244, -1.5936],\n",
      "        [ 0.3113, -1.2123,  0.8184, -1.3375,  0.2925],\n",
      "        [ 3.2026, -1.1408, -1.0890, -0.7726, -1.9880],\n",
      "        [ 2.6885, -0.8333, -1.3176, -0.3280, -1.8046]])\n",
      "tensor([[-0.3869,  2.3889, -1.9285,  0.7506, -2.0285],\n",
      "        [-2.4744,  0.3466,  0.7943,  0.8240, -0.2977],\n",
      "        [-1.1592,  0.6153,  0.3073, -0.1727,  0.0540],\n",
      "        [-2.1297,  2.3976, -0.9277,  0.9806, -0.8524],\n",
      "        [-2.2600,  2.2487, -0.1024,  0.4349, -0.9334]])\n",
      "tensor([[-1.8026,  1.9861,  0.0033, -0.2685, -0.5607],\n",
      "        [-1.7607,  3.0092, -0.8330,  0.0701, -1.5811],\n",
      "        [-0.9263,  2.6268, -0.7835, -0.7922, -1.2547],\n",
      "        [-2.4439,  2.3001,  0.3206, -0.9150,  0.9678],\n",
      "        [-1.9000,  2.2772, -0.4904,  0.1264, -0.6506]])\n",
      "tensor([[-2.5967, -1.8918,  2.9140, -1.3408,  0.9540],\n",
      "        [-1.8414, -1.5916,  2.6569, -1.5971,  0.2979],\n",
      "        [-1.5617, -1.0424,  1.8659, -0.6858,  0.1447],\n",
      "        [-2.5435, -1.3329,  2.9378, -1.4689,  0.6328],\n",
      "        [-1.2754, -1.9603,  2.3572, -1.8654,  1.2144]])\n",
      "tensor([[-2.4280, -0.5422,  3.3917, -1.8324, -1.0623],\n",
      "        [-2.6008, -1.3736,  2.6597, -0.6889, -0.1469],\n",
      "        [-2.6246, -0.5216,  2.2416, -0.8001,  0.3622],\n",
      "        [-3.0471, -0.4738,  2.1177, -2.1561,  2.5709],\n",
      "        [-3.0627, -0.9186,  3.1795, -1.3293, -0.0660]])\n",
      "tensor([[-1.9643,  1.0932, -0.2815,  1.4640, -1.5684], Acc: 90.000% (27/30)     6/10 \n",
      "        [-1.0228, -0.4807, -0.3691,  2.1660, -0.1943],\n",
      "        [-0.9708,  1.0776, -1.1876,  2.0651, -1.8925],\n",
      "        [-0.8646,  0.2167, -1.3081,  2.6351, -1.4278],\n",
      "        [-0.8526, -0.8203, -0.7892,  3.3240, -1.5989]])\n",
      "tensor([[-1.6329,  0.8474, -1.2598,  3.2935, -2.5661],\n",
      "        [-1.5829,  0.3332, -1.0052,  3.4245, -2.7857],\n",
      "        [-1.3386,  0.9667, -1.0340,  2.1912, -1.8917],\n",
      "        [-2.0180,  0.6285, -0.1881,  2.4549, -2.8929],\n",
      "        [-2.5403, -0.1856,  0.4452,  2.1402, -1.2196]])\n",
      "tensor([[-3.3335, -0.5582,  1.8459, -2.1310,  3.4554],\n",
      "        [-2.9721, -0.7662,  1.4777, -0.8395,  2.6158],\n",
      "        [-3.1460,  1.6976,  0.7647, -0.2233,  0.8927],\n",
      "        [-2.6567, -1.2927,  0.9199, -0.5528,  3.0344],\n",
      "        [-0.8916, -0.3237,  0.6511, -0.7154,  1.0084]])\n",
      "tensor([[-2.0367, -1.9244,  0.9836, -1.7708,  3.4615],\n",
      "        [-2.1764, -1.5596,  0.8395, -1.0018,  3.1282],\n",
      "        [-1.5909, -0.9596,  0.7130, -0.6892,  1.9758],\n",
      "        [-0.8409, -0.7489,  0.7300, -0.4834,  1.0105],\n",
      "        [-2.4974,  1.8200,  0.0227, -0.4288,  1.4264]])\n",
      " [===============================>...] | Loss: 0.359 | Acc: 90.000% (45/50)     10/10 \n",
      "val_loss:  tensor(0.3590) accuracy:  tensor(90)\n",
      "Saving..\n",
      "\n",
      "Epoch: 10\n",
      " [==================================>] | Loss: 0.945 | Acc: 75.000% (758/1003)  101/101 \n",
      "tensor([[ 3.1489, -1.5105, -1.4585, -0.4240, -1.4413],\n",
      "        [ 4.1943, -1.6617, -2.5056,  0.4327, -2.4977],\n",
      "        [ 5.4124, -2.3922, -2.5383, -0.7569, -2.8383],\n",
      "        [ 3.3815, -1.2444, -2.3469,  0.7305, -2.1019],\n",
      "        [ 3.4362, -1.9883, -1.0341, -1.1908, -1.3147]])\n",
      "tensor([[ 2.4796, -0.2588, -2.6933,  1.2024, -2.4783], Acc: 100.000% (5/5)      1/10 \n",
      "        [ 3.1605, -0.9666, -1.5861, -0.0827, -2.2866],\n",
      "        [ 1.6925, -1.2833,  0.0512, -1.3244, -0.6060],\n",
      "        [ 4.5245, -1.7206, -1.8945, -0.9331, -2.6659],\n",
      "        [ 3.6598, -1.2038, -1.7889, -0.6459, -2.3621]])\n",
      "tensor([[ 0.4304,  2.0923, -2.7143,  1.4098, -2.9712],\n",
      "        [-2.0900,  0.7794,  0.0740,  1.5888, -1.2535],\n",
      "        [-0.3332,  0.1987,  0.1763,  0.3646, -1.1843],\n",
      "        [-2.2121,  2.7209, -1.4963,  1.6359, -1.3541],\n",
      "        [-1.4548,  2.3743, -1.1794,  1.1551, -1.9219]])\n",
      "tensor([[-1.3888,  1.4892, -0.4240,  0.7679, -1.4211],\n",
      "        [-1.3951,  3.1353, -1.5546,  0.7296, -2.3949],\n",
      "        [ 0.2978,  2.2944, -1.9535, -0.1139, -2.5938],\n",
      "        [-1.5691,  2.3919, -0.2053, -0.8184, -0.5540],\n",
      "        [-1.0162,  2.3183, -1.7699,  0.9955, -1.7522]])\n",
      "tensor([[-2.1038, -1.8527,  3.3740, -1.8597, -0.0897],\n",
      "        [-1.7204, -1.5121,  2.8081, -1.8154, -0.1494],\n",
      "        [-1.2868, -0.9882,  2.1248, -0.9143, -0.7667],\n",
      "        [-2.5584, -1.3993,  3.5321, -1.7113, -0.4160],\n",
      "        [-1.4373, -1.8388,  2.7723, -1.5709, -0.0131]])\n",
      "tensor([[-2.6101, -0.4905,  3.4552, -1.7839, -1.5832],\n",
      "        [-2.2641, -1.7657,  3.0886, -0.9657, -1.1000],\n",
      "        [-2.5207, -0.6693,  2.5796, -1.1047, -0.2505],\n",
      "        [-2.9975, -0.5175,  2.4530, -2.8010,  2.3462],\n",
      "        [-3.1583, -0.7909,  3.4135, -1.5206, -0.6615]])\n",
      "tensor([[-1.1100,  1.2104, -1.3033,  1.9830, -1.8835], Acc: 93.000% (28/30)     6/10 \n",
      "        [-0.3751, -0.3734, -0.9157,  2.6182, -1.3245],\n",
      "        [-0.6002,  1.0694, -1.7984,  2.9285, -2.5392],\n",
      "        [-0.1705,  0.3635, -1.7226,  2.6138, -1.9936],\n",
      "        [ 0.2437, -0.4398, -1.8496,  3.3795, -2.0434]])\n",
      "tensor([[-1.6733,  0.7927, -1.5821,  4.1170, -3.4034],\n",
      "        [-1.4680,  0.6124, -1.6070,  3.8681, -3.0994],\n",
      "        [-1.4645,  1.2224, -1.5230,  2.8733, -2.5275],\n",
      "        [-1.4299,  0.8603, -1.0672,  2.9223, -3.6229],\n",
      "        [-1.8739,  0.1310, -0.4792,  2.6821, -1.5800]])\n",
      "tensor([[-3.0154, -0.1468,  1.7823, -2.0477,  2.6205],\n",
      "        [-1.8902, -1.2000,  1.3971, -0.3209,  0.9945],\n",
      "        [-3.0762,  2.0951,  0.2906,  0.1834,  0.1567],\n",
      "        [-1.2178, -1.4863,  0.5488, -0.5389,  1.9821],\n",
      "        [ 0.0494, -0.1563,  0.2075, -0.7927, -0.0145]])\n",
      "tensor([[-1.4361, -1.5964,  0.9988, -1.9940,  2.6941],\n",
      "        [-1.5040, -1.7997,  0.7574, -1.0181,  2.5297],\n",
      "        [-0.8831, -0.9400,  0.6920, -0.7901,  1.1947],\n",
      "        [ 0.4159, -0.4218,  0.2313, -0.6882, -0.3616],\n",
      "        [-1.9610,  1.5875, -0.2748,  0.0470,  0.6793]])\n",
      " [===============================>...] | Loss: 0.386 | Acc: 86.000% (43/50)     10/10 \n",
      "val_loss:  tensor(0.3856) accuracy:  tensor(86)\n",
      "\n",
      "Epoch: 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [==================================>] | Loss: 0.924 | Acc: 76.000% (764/1003)  101/101 \n",
      "tensor([[ 3.1315, -1.8850, -1.2327, -0.6983, -1.2044],\n",
      "        [ 4.1798, -1.9034, -1.8849, -0.2499, -2.2224],\n",
      "        [ 5.6582, -2.8123, -2.1608, -1.3251, -2.7790],\n",
      "        [ 2.6695, -1.2517, -1.5374,  0.3106, -1.3587],\n",
      "        [ 3.3365, -2.3122, -0.5754, -1.9338, -1.0432]])\n",
      "tensor([[ 2.6763, -0.8157, -1.8865,  0.0325, -1.6474], Acc: 100.000% (5/5)      1/10 \n",
      "        [ 2.9422, -1.3690, -1.1059, -0.4919, -1.5412],\n",
      "        [ 1.7904, -1.7979,  0.2749, -1.5802, -0.2761],\n",
      "        [ 4.6580, -2.0492, -1.5234, -1.4860, -2.4628],\n",
      "        [ 3.8770, -1.7405, -1.4934, -1.3071, -2.0045]])\n",
      "tensor([[ 0.3913,  1.5894, -2.2006,  0.5049, -1.8274],\n",
      "        [-3.1024, -0.3616,  0.8849,  1.4516,  0.0764],\n",
      "        [-1.1386,  0.5288,  0.7037, -0.6465, -0.1990],\n",
      "        [-2.4020,  2.5203, -1.3239,  1.1220, -0.1665],\n",
      "        [-2.4031,  2.2829, -0.3308,  0.8447, -1.3072]])\n",
      "tensor([[-1.4598,  1.8237, -0.3915,  0.1856, -0.9474],\n",
      "        [-2.0484,  3.2996, -1.1959,  0.3358, -1.8623],\n",
      "        [-0.5041,  2.1677, -0.8690, -1.0693, -1.6960],\n",
      "        [-2.2190,  2.2845,  0.4082, -1.4436,  0.0043],\n",
      "        [-1.5946,  2.0139, -1.0000,  0.7557, -1.1168]])\n",
      "tensor([[-2.8608, -1.9513,  3.3252, -1.9208,  0.9135],\n",
      "        [-2.7903, -1.7443,  3.4179, -2.1569,  0.5661],\n",
      "        [-1.5591, -1.0559,  2.2027, -1.0688, -0.3661],\n",
      "        [-3.2623, -1.1768,  3.6086, -2.3658,  0.9809],\n",
      "        [-1.8150, -2.0140,  2.9271, -1.8784,  0.5510]])\n",
      "tensor([[-3.2224, -0.6087,  4.1629, -2.5174, -0.8619],\n",
      "        [-3.0506, -2.1164,  3.3207, -0.9037, -0.5016],\n",
      "        [-3.0809, -0.8900,  2.9042, -1.4724,  0.3918],\n",
      "        [-3.4399, -1.0582,  2.6777, -2.8005,  2.6683],\n",
      "        [-3.5724, -1.0984,  3.4989, -1.5725,  0.0112]])\n",
      "tensor([[-2.4310,  1.1563, -0.6926,  2.3024, -1.6019], Acc: 93.000% (28/30)     6/10 \n",
      "        [-0.8604, -0.5486, -0.4756,  2.3207, -0.7469],\n",
      "        [-1.1694,  0.8390, -0.9455,  2.3419, -2.0260],\n",
      "        [-1.0650,  0.0723, -1.0390,  2.2764, -1.0759],\n",
      "        [-1.0422, -0.5742, -1.1871,  3.4659, -1.5504]])\n",
      "tensor([[-1.8462,  0.6870, -1.1811,  3.6657, -3.0684],\n",
      "        [-2.2284,  0.5297, -1.3759,  4.0793, -2.7019],\n",
      "        [-1.5235,  1.1537, -1.3632,  2.5451, -1.6145],\n",
      "        [-2.5229,  0.4181,  0.4658,  2.0717, -2.6104],\n",
      "        [-2.4047,  0.2495, -0.0991,  2.0099, -0.6746]])\n",
      "tensor([[-3.8342, -0.4065,  1.8581, -2.2074,  3.5450],\n",
      "        [-2.7097, -0.9287,  1.5385, -0.9836,  2.0608],\n",
      "        [-3.2990,  1.4270,  0.7673, -0.3571,  1.3521],\n",
      "        [-2.5651, -1.7104,  1.1099, -0.6763,  2.8003],\n",
      "        [-0.4013, -0.6472,  0.5200, -1.2048,  0.9627]])\n",
      "tensor([[-2.0279, -1.8386,  1.4122, -2.2908,  3.0810],\n",
      "        [-2.3199, -1.8214,  1.0434, -1.2764,  3.1765],\n",
      "        [-1.1870, -1.0129,  0.8752, -0.9997,  1.4300],\n",
      "        [-0.7759, -0.1466,  0.5952, -0.8360,  0.8196],\n",
      "        [-2.3466,  0.6039,  0.0495, -0.3070,  2.3305]])\n",
      " [===============================>...] | Loss: 0.303 | Acc: 94.000% (47/50)     10/10 \n",
      "val_loss:  tensor(0.3034) accuracy:  tensor(94)\n",
      "Saving..\n",
      "\n",
      "Epoch: 12\n",
      " [==================================>] | Loss: 0.952 | Acc: 75.000% (754/1003)  101/101 \n",
      "tensor([[ 2.1216, -1.6518, -0.7812, -0.5028, -0.6165],\n",
      "        [ 3.9900, -1.4533, -2.4509,  0.3079, -2.7002],\n",
      "        [ 5.3981, -2.4821, -2.3048, -1.0256, -2.9189],\n",
      "        [ 1.8958, -0.7872, -1.6119,  0.6264, -1.1842],\n",
      "        [ 2.7532, -1.8355, -0.7881, -1.4776, -0.8837]])\n",
      "tensor([[ 2.3600, -0.5147, -2.1523,  0.3520, -1.7747], Acc: 100.000% (5/5)      1/10 \n",
      "        [ 3.1030, -1.0071, -1.4206, -0.3847, -2.1323],\n",
      "        [ 1.2142, -1.6274,  0.7133, -1.8220, -0.3077],\n",
      "        [ 4.8252, -1.8103, -2.0004, -1.2983, -3.0090],\n",
      "        [ 3.8963, -1.2240, -1.8029, -1.1725, -2.6644]])\n",
      "tensor([[ 0.6482,  1.7901, -2.6518,  0.5688, -2.5434],\n",
      "        [-2.4167,  0.6891,  0.1041,  1.5003, -0.6179],\n",
      "        [-1.7418,  0.5422,  0.8011, -0.6733,  0.1845],\n",
      "        [-2.2548,  2.6100, -1.5695,  1.0779, -0.4703],\n",
      "        [-2.5076,  2.8268, -0.9196,  0.7179, -1.1222]])\n",
      "tensor([[-1.8216,  1.8401, -0.1922, -0.2389, -0.4231],\n",
      "        [-1.8320,  3.6745, -1.3988,  0.0692, -2.6082],\n",
      "        [ 0.5398,  1.4395, -1.4668, -0.8492, -2.0922],\n",
      "        [-1.7356,  1.8638, -0.0792, -1.1794, -0.0496],\n",
      "        [-1.6609,  2.3050, -1.5009,  1.0577, -1.1751]])\n",
      "tensor([[-2.6522, -1.6643,  3.3136, -1.8985,  0.4537],\n",
      "        [-3.2295, -1.3006,  3.2905, -1.3842, -0.2008],\n",
      "        [-1.9096, -0.6956,  2.1930, -0.9150, -0.4661],\n",
      "        [-3.2253, -0.2560,  3.2693, -1.9754,  0.2932],\n",
      "        [-1.3218, -1.5960,  2.5119, -1.8687,  0.3496]])\n",
      "tensor([[-2.8492, -0.0012,  3.3521, -1.9252, -1.3533],\n",
      "        [-3.2419, -1.4999,  3.0734, -0.6192, -0.6706],\n",
      "        [-2.7643, -0.4573,  2.5508, -1.3157, -0.0625],\n",
      "        [-3.8977, -0.7060,  3.0859, -2.7272,  1.8501],\n",
      "        [-3.1070, -0.3541,  2.9447, -1.2627, -0.5612]])\n",
      "tensor([[-2.3594,  1.7334, -1.0421,  2.0618, -1.3449], Acc: 93.000% (28/30)     6/10 \n",
      "        [-1.2969, -0.2397, -0.4635,  2.3343, -0.6193],\n",
      "        [-1.7605,  1.7558, -1.2463,  2.1239, -2.0859],\n",
      "        [-1.5799,  0.9265, -1.2648,  2.5149, -1.6282],\n",
      "        [-1.2848,  0.6081, -1.8687,  3.0494, -1.2336]])\n",
      "tensor([[-1.8568,  1.1024, -1.1785,  3.1479, -3.0171],\n",
      "        [-2.1289,  0.7942, -1.3751,  3.6796, -2.6498],\n",
      "        [-2.0582,  1.0277, -1.1566,  2.7925, -1.0777],\n",
      "        [-1.6920,  0.8479, -0.5728,  2.2492, -1.9407],\n",
      "        [-2.4653,  0.8453, -0.2471,  1.9046, -1.0510]])\n",
      "tensor([[-3.3596, -0.5494,  1.6767, -2.0078,  2.8184],\n",
      "        [-2.9599, -1.1062,  1.6375,  0.0885,  1.0014],\n",
      "        [-3.4771,  1.9300,  0.6946, -0.5043,  0.8389],\n",
      "        [-2.1068, -1.9539,  1.0749, -0.5982,  2.2454],\n",
      "        [-0.8826, -0.2745,  0.9351, -1.3569,  0.6777]])\n",
      "tensor([[-2.0922, -1.7279,  0.8130, -1.7252,  3.1075],\n",
      "        [-2.3122, -1.9608,  1.2175, -1.3147,  2.8570],\n",
      "        [-1.1278, -0.7348,  0.5394, -0.7489,  1.2279],\n",
      "        [-0.7499,  0.0813,  0.4352, -0.8708,  0.4904],\n",
      "        [-2.7384,  0.9267, -0.0803, -0.4555,  2.1956]])\n",
      " [===============================>...] | Loss: 0.353 | Acc: 90.000% (45/50)     10/10 \n",
      "val_loss:  tensor(0.3526) accuracy:  tensor(90)\n",
      "\n",
      "Epoch: 13\n",
      " [==================================>] | Loss: 0.858 | Acc: 77.000% (776/1003)  101/101 \n",
      "tensor([[ 2.6919, -1.8284, -0.5768, -0.9957, -0.9566],\n",
      "        [ 3.8496, -1.3883, -2.0954, -0.0343, -2.5379],\n",
      "        [ 5.5430, -2.7896, -1.7288, -1.6354, -2.6543],\n",
      "        [ 2.3859, -0.4869, -1.8810,  0.2726, -1.8927],\n",
      "        [ 2.8683, -2.0573, -0.1466, -2.1535, -0.8738]])\n",
      "tensor([[ 2.8875, -0.8641, -1.8146,  0.0884, -2.0269], Acc: 100.000% (5/5)      1/10 \n",
      "        [ 2.9605, -1.2374, -0.5454, -1.0436, -1.9122],\n",
      "        [ 1.0433, -1.2592,  1.0670, -2.3098, -0.5977],\n",
      "        [ 4.3351, -1.6278, -1.3269, -1.6362, -2.5959],\n",
      "        [ 3.5305, -1.3663, -1.1653, -1.3517, -2.0490]])\n",
      "tensor([[-0.3229,  2.3271, -2.1457,  0.6955, -2.1896],\n",
      "        [-3.5694,  0.6465,  0.7704,  1.4026, -0.5107],\n",
      "        [-1.3836,  0.7716,  0.5985, -0.6201, -0.3262],\n",
      "        [-3.4621,  3.2085, -1.9515,  1.7782, -0.3243],\n",
      "        [-2.8520,  2.2532, -0.2412,  0.8892, -1.3354]])\n",
      "tensor([[-1.5965,  2.3782, -0.7834, -0.2041, -1.3832],\n",
      "        [-1.7924,  2.9743, -0.8876,  0.1525, -2.4626],\n",
      "        [-0.1390,  2.1906, -1.3551, -0.8750, -2.4205],\n",
      "        [-1.2308,  1.7473, -0.3294, -1.1534, -0.6643],\n",
      "        [-1.5123,  1.9639, -0.9187,  0.8374, -2.0522]])\n",
      "tensor([[-3.4639, -1.0958,  3.4660, -1.5722, -0.0024],\n",
      "        [-3.1528, -0.8622,  3.4764, -1.8394, -0.4869],\n",
      "        [-2.1314, -0.5224,  2.4395, -1.2766, -0.4065],\n",
      "        [-3.9542, -0.4305,  3.6247, -1.6906, -0.1456],\n",
      "        [-1.4006, -0.5366,  2.0045, -1.6946,  0.3020]])\n",
      "tensor([[-3.7778,  0.1312,  3.7112, -1.8543, -1.4075],\n",
      "        [-3.3790, -1.4128,  3.5257, -1.1556, -0.9481],\n",
      "        [-3.8030, -0.4936,  3.3474, -1.3425, -0.6250],\n",
      "        [-3.5474, -0.6510,  2.9844, -2.8913,  1.6195],\n",
      "        [-3.6066, -0.6030,  3.4547, -1.3907, -0.8112]])\n",
      "tensor([[-2.6627,  1.2483, -0.2602,  1.9929, -2.1347], Acc: 93.000% (28/30)     6/10 \n",
      "        [-1.1357, -0.0197, -0.4484,  2.0421, -0.6249],\n",
      "        [-2.0171,  1.6638, -1.0704,  2.3043, -2.4120],\n",
      "        [-2.3616,  0.6960, -0.9696,  2.8925, -1.2068],\n",
      "        [-1.4801,  0.1263, -1.3920,  3.1600, -1.0055]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.3776,  1.0704, -1.0140,  3.3904, -2.9550],\n",
      "        [-2.6721,  0.6866, -1.2455,  3.8841, -2.1455],\n",
      "        [-1.8890,  1.3754, -1.3793,  2.4102, -1.4765],\n",
      "        [-1.7125,  0.7284, -0.1741,  1.8292, -2.2100],\n",
      "        [-2.6288,  0.4994, -0.2712,  2.4320, -1.5474]])\n",
      "tensor([[-4.5126,  0.9770,  1.5680, -1.8464,  2.9010],\n",
      "        [-3.1699, -0.8016,  1.9637, -0.3576,  0.7464],\n",
      "        [-4.0055,  1.9497,  0.7219, -0.2270,  0.7568],\n",
      "        [-2.0974, -1.2584,  0.6759, -0.8440,  2.6375],\n",
      "        [-0.8354, -0.1962,  0.4388, -1.0373,  0.8502]])\n",
      "tensor([[-2.1732, -1.0046,  0.4937, -1.7438,  2.7826],\n",
      "        [-2.4889, -1.4714,  0.9800, -1.3615,  2.9490],\n",
      "        [-1.7452, -0.1117,  0.8878, -0.6485,  0.9436],\n",
      "        [-1.4220,  0.8760,  0.2453, -0.6076,  0.2741],\n",
      "        [-2.4992,  1.3797, -0.4678, -0.4064,  1.4785]])\n",
      " [===============================>...] | Loss: 0.350 | Acc: 90.000% (45/50)     10/10 \n",
      "val_loss:  tensor(0.3501) accuracy:  tensor(90)\n",
      "\n",
      "Epoch: 14\n",
      " [==================================>] | Loss: 0.887 | Acc: 74.000% (747/1003)  101/101 \n",
      "tensor([[ 1.4036, -1.5246, -1.0077, -0.0280,  0.1003],\n",
      "        [ 3.3206, -1.2886, -2.2303,  0.3658, -1.8706],\n",
      "        [ 4.6351, -2.1513, -2.4728, -1.0873, -2.0093],\n",
      "        [ 1.3091, -0.5415, -1.3875,  0.8542, -1.0809],\n",
      "        [ 2.0654, -1.8437, -0.4649, -1.9712, -0.0223]])\n",
      "tensor([[ 1.9402, -0.3768, -2.4629,  0.6847, -1.4805], Acc: 100.000% (5/5)      1/10 \n",
      "        [ 3.4148, -1.1774, -1.2308, -1.0549, -2.0575],\n",
      "        [ 1.3259, -1.6900,  0.3565, -1.6665, -0.0162],\n",
      "        [ 3.4973, -0.9584, -1.4641, -1.2205, -2.2776],\n",
      "        [ 3.6697, -1.2929, -1.6178, -1.3691, -2.1171]])\n",
      "tensor([[-0.0286,  1.6648, -1.4900,  0.5021, -2.0462],\n",
      "        [-3.5496,  0.9746,  0.6053,  1.5073, -0.7479],\n",
      "        [-1.5820,  0.7872,  0.9876, -0.9749, -0.3109],\n",
      "        [-3.3970,  3.0996, -2.0099,  2.1254, -0.6503],\n",
      "        [-3.2411,  2.3763, -0.1601,  0.9505, -0.9540]])\n",
      "tensor([[-2.4462,  2.5212, -0.4402,  0.1611, -1.1778],\n",
      "        [-2.6049,  3.0335, -0.0037, -0.0656, -2.3661],\n",
      "        [ 0.1362,  1.3739, -0.8030, -0.7473, -1.8403],\n",
      "        [-2.2889,  2.3972,  0.1267, -1.3816, -0.5739],\n",
      "        [-2.8636,  2.5295, -0.5074,  0.6586, -1.1452]])\n",
      "tensor([[-2.6513, -1.3284,  3.3254, -2.3202,  0.2355],\n",
      "        [-2.8626, -0.8290,  3.4171, -2.0083, -0.4750],\n",
      "        [-2.0753, -0.2804,  2.3538, -1.2893, -0.3987],\n",
      "        [-4.2337, -0.4790,  3.4884, -1.7375,  0.4666],\n",
      "        [-1.6193, -0.7915,  2.3052, -2.1131,  0.5934]])\n",
      "tensor([[-3.4445,  0.2753,  3.8517, -2.3648, -1.5287],\n",
      "        [-2.9290, -1.0185,  3.4739, -1.4229, -1.2489],\n",
      "        [-3.5846, -0.5060,  3.2470, -1.3173, -0.6106],\n",
      "        [-4.3418, -0.3495,  3.2474, -2.8262,  1.6916],\n",
      "        [-3.7287, -0.3036,  3.7832, -1.7075, -1.1351]])\n",
      "tensor([[-3.1932,  1.3846, -0.2501,  2.0411, -1.4297], Acc: 93.000% (28/30)     6/10 \n",
      "        [-1.4919, -0.0530, -0.5892,  2.1444, -0.0563],\n",
      "        [-2.5973,  2.2811, -1.0955,  2.0309, -1.9939],\n",
      "        [-1.8532,  0.6160, -1.1134,  2.5616, -0.9615],\n",
      "        [-1.9771,  0.1449, -1.1880,  2.9360, -0.1661]])\n",
      "tensor([[-2.0591,  0.8721, -1.0275,  3.1120, -2.3464],\n",
      "        [-2.4053,  0.2762, -0.9743,  3.5904, -2.1354],\n",
      "        [-1.9143,  1.1197, -1.2045,  2.3760, -1.4107],\n",
      "        [-1.4385,  0.7087, -0.5319,  2.2086, -2.3293],\n",
      "        [-2.8143,  0.4570, -0.5740,  2.6535, -0.7685]])\n",
      "tensor([[-5.1132,  0.9043,  1.6889, -2.2317,  3.4036],\n",
      "        [-3.3303, -0.2344,  1.3324,  0.0730,  1.1365],\n",
      "        [-4.4705,  2.2168,  0.8169, -0.1515,  0.5834],\n",
      "        [-2.9480, -1.1650,  1.0142, -0.8936,  2.9180],\n",
      "        [-1.4073, -0.2389,  0.6009, -0.8726,  1.2092]])\n",
      "tensor([[-2.5624, -1.2852,  0.5244, -1.9626,  3.3181],\n",
      "        [-2.9896, -1.6839,  1.3106, -0.9254,  2.6268],\n",
      "        [-1.5769, -0.4426,  0.8586, -0.9169,  1.2366],\n",
      "        [-1.4535,  0.4748,  0.3678, -0.9392,  0.7895],\n",
      "        [-3.8981,  2.1790, -0.6551,  0.5211,  1.4858]])\n",
      " [===============================>...] | Loss: 0.365 | Acc: 88.000% (44/50)     10/10 \n",
      "val_loss:  tensor(0.3650) accuracy:  tensor(88)\n",
      "Epoch    14: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch    14: reducing learning rate of group 1 to 5.0000e-04.\n",
      "\n",
      "Epoch: 15\n",
      " [==================================>] | Loss: 0.896 | Acc: 75.000% (762/1003)  101/101 \n",
      "tensor([[ 2.1098, -1.7709, -1.3182,  0.0016, -0.3767],\n",
      "        [ 3.6732, -1.5498, -2.2967,  0.5812, -2.3935],\n",
      "        [ 5.6912, -2.7259, -2.7378, -1.0954, -2.7370],\n",
      "        [ 2.1563, -0.9239, -1.8529,  0.9201, -1.6496],\n",
      "        [ 2.7504, -1.7735, -1.0931, -1.6749, -0.7097]])\n",
      "tensor([[ 2.5263, -0.4296, -2.9532,  1.0373, -2.2954], Acc: 100.000% (5/5)      1/10 \n",
      "        [ 3.2857, -1.2455, -1.0894, -0.8791, -2.1350],\n",
      "        [ 1.8094, -1.8770,  0.4019, -2.1186, -0.3292],\n",
      "        [ 4.2974, -1.2309, -1.9193, -1.2435, -2.9306],\n",
      "        [ 4.0351, -1.4134, -2.0516, -1.2504, -2.4781]])\n",
      "tensor([[ 0.3131,  1.6969, -2.1468,  0.5742, -2.4719],\n",
      "        [-2.8015,  0.6068,  0.0775,  1.8929, -0.7142],\n",
      "        [-1.2512,  0.3012,  0.9101, -0.5545, -0.3475],\n",
      "        [-2.7278,  2.5714, -2.1095,  2.1762, -0.8827],\n",
      "        [-2.7336,  2.2443, -0.4217,  0.8330, -0.7215]])\n",
      "tensor([[-1.5199,  2.3505, -1.0132,  0.2780, -1.8987],\n",
      "        [-1.9236,  3.1163, -0.9625,  0.1854, -2.6693],\n",
      "        [ 0.2732,  1.8304, -1.3435, -0.8401, -2.5609],\n",
      "        [-1.4766,  2.0966, -0.0320, -1.3740, -1.1923],\n",
      "        [-1.8161,  2.2391, -1.1710,  0.9997, -2.0462]])\n",
      "tensor([[-2.4431, -1.7972,  2.8866, -1.7362,  0.4426],\n",
      "        [-2.7454, -1.3022,  3.1801, -1.5882, -0.3470],\n",
      "        [-1.9090, -0.5813,  2.2346, -1.0986, -0.4774],\n",
      "        [-4.0045, -0.7819,  3.5576, -1.6923,  0.0933],\n",
      "        [-1.7961, -0.9119,  2.2589, -1.8467,  0.5336]])\n",
      "tensor([[-2.2805, -0.3686,  3.2120, -2.1050, -1.3934],\n",
      "        [-3.0445, -1.2685,  3.2763, -1.0752, -1.0384],\n",
      "        [-3.0034, -0.8087,  2.8288, -1.1566, -0.2426],\n",
      "        [-3.7147, -0.8601,  2.6684, -2.8835,  2.2482],\n",
      "        [-3.1512, -0.8573,  3.1806, -1.2555, -0.6607]])\n",
      "tensor([[-2.7234,  1.1900, -0.5578,  2.3290, -1.7417], Acc: 93.000% (28/30)     6/10 \n",
      "        [-1.2332, -0.2884, -0.5540,  2.3898, -0.6578],\n",
      "        [-2.1221,  1.9161, -1.2947,  2.3883, -2.3492],\n",
      "        [-1.6546,  0.0951, -1.0833,  3.0323, -1.5941],\n",
      "        [-1.4392, -0.2724, -1.0741,  3.2224, -1.3688]])\n",
      "tensor([[-2.0619,  0.6418, -1.1024,  3.6646, -3.1818],\n",
      "        [-2.1892,  0.0645, -1.1079,  3.9440, -2.6759],\n",
      "        [-1.4699,  0.6133, -1.3188,  2.8385, -1.8879],\n",
      "        [-1.7077,  0.6587, -0.4390,  2.4565, -2.7107],\n",
      "        [-3.1711,  0.3819, -0.7934,  3.4132, -1.3662]])\n",
      "tensor([[-3.8043, -0.1490,  1.7136, -2.1041,  2.7673],\n",
      "        [-2.5701, -1.0356,  1.5848, -0.0828,  0.5964],\n",
      "        [-3.9479,  1.2624,  0.7142,  0.5183,  0.3155],\n",
      "        [-1.9487, -1.9872,  0.9789, -0.9837,  2.3964],\n",
      "        [-0.6744, -0.5488,  0.4628, -0.9022,  0.7959]])\n",
      "tensor([[-1.7364, -1.9634,  0.7973, -2.4651,  2.9007],\n",
      "        [-2.6439, -2.4550,  1.3508, -0.5558,  2.2767],\n",
      "        [-0.9507, -0.9932,  0.9600, -0.8320,  0.7044],\n",
      "        [-0.1671,  0.3434, -0.5451, -0.7229, -0.1083],\n",
      "        [-2.4708,  1.9781, -0.8566,  0.2827,  0.1569]])\n",
      " [===============================>...] | Loss: 0.399 | Acc: 86.000% (43/50)     10/10 \n",
      "val_loss:  tensor(0.3989) accuracy:  tensor(86)\n",
      "\n",
      "Epoch: 16\n",
      " [==================================>] | Loss: 0.770 | Acc: 76.000% (763/1003)  101/101 \n",
      "tensor([[ 1.6233, -1.4529, -1.2469,  0.3554, -0.3676],\n",
      "        [ 3.2978, -0.9701, -2.5945,  0.8873, -2.6080],\n",
      "        [ 5.0123, -2.0772, -2.7499, -0.5987, -2.6667],\n",
      "        [ 1.8154, -0.7133, -1.9027,  1.0842, -1.5161],\n",
      "        [ 2.6177, -1.5688, -0.9397, -1.6117, -0.7400]])\n",
      "tensor([[ 1.9162, -0.3006, -2.8209,  1.4457, -2.0563], Acc: 100.000% (5/5)      1/10 \n",
      "        [ 2.8476, -0.7608, -1.0779, -0.4928, -2.3403],\n",
      "        [ 1.3928, -1.6189,  0.0487, -1.0848, -0.0122],\n",
      "        [ 3.8494, -0.9305, -1.7818, -1.1073, -2.7418],\n",
      "        [ 3.6880, -1.2762, -1.6337, -0.9904, -2.2502]])\n",
      "tensor([[ 0.0516,  1.7076, -1.8301,  0.7961, -2.4509],\n",
      "        [-3.1663,  0.6568,  0.6899,  1.2132, -0.5849],\n",
      "        [-1.6120,  0.5479,  1.1614, -0.9096, -0.3275],\n",
      "        [-3.1173,  2.8656, -2.1279,  2.2838, -0.8594],\n",
      "        [-2.9142,  2.5498, -0.3793,  0.8889, -1.4809]])\n",
      "tensor([[-1.9244,  2.2527, -0.3762,  0.2172, -1.8949],\n",
      "        [-2.6953,  3.4238, -0.3914, -0.1280, -2.4474],\n",
      "        [-0.3966,  2.4282, -1.3099, -0.4823, -2.9220],\n",
      "        [-1.9949,  2.2748,  0.2705, -1.4002, -1.0541],\n",
      "        [-1.9743,  2.1849, -0.7020,  0.6422, -1.8960]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.0699, -1.6927,  3.1616, -1.8234,  0.5526],\n",
      "        [-3.3401, -1.1380,  3.4770, -1.9793, -0.0557],\n",
      "        [-2.4349, -0.4176,  2.6352, -1.4918, -0.4392],\n",
      "        [-4.2320, -0.4934,  3.2970, -1.8725,  0.8284],\n",
      "        [-2.0248, -0.9206,  2.4468, -2.1177,  0.6381]])\n",
      "tensor([[-2.8976, -0.3360,  3.5428, -2.2464, -1.2057],\n",
      "        [-3.2930, -1.1632,  3.6014, -1.4536, -1.1782],\n",
      "        [-3.2644, -0.5233,  3.0614, -1.6107, -0.2592],\n",
      "        [-4.4187, -0.2742,  3.1769, -3.1571,  1.9808],\n",
      "        [-4.1644, -0.7118,  3.7603, -1.7158, -0.5181]])\n",
      "tensor([[-2.3345,  1.4478, -0.4535,  1.7786, -2.1399], Acc: 93.000% (28/30)     6/10 \n",
      "        [-1.0884, -0.0320, -0.4765,  1.8073, -0.5391],\n",
      "        [-2.3242,  2.3015, -1.1557,  1.8382, -2.2042],\n",
      "        [-1.8509,  0.6108, -1.3533,  3.0449, -1.7135],\n",
      "        [-1.5285,  0.3335, -1.3377,  2.9742, -1.3210]])\n",
      "tensor([[-2.1715,  1.1042, -1.3648,  3.5253, -3.1716],\n",
      "        [-2.0159,  0.3238, -1.1517,  3.5187, -2.5180],\n",
      "        [-1.4462,  0.4656, -1.1022,  2.7791, -2.0470],\n",
      "        [-1.8951,  1.0089, -0.5678,  2.4223, -3.0648],\n",
      "        [-3.0440,  0.6418, -1.0656,  3.3141, -1.2245]])\n",
      "tensor([[-4.2951,  0.0236,  2.1630, -2.3579,  2.6474],\n",
      "        [-3.9510,  0.0186,  1.5984, -0.1367,  0.9287],\n",
      "        [-3.9590,  1.4729,  1.1375, -0.4219,  0.4774],\n",
      "        [-2.9089, -1.7104,  1.2891, -0.9154,  2.6160],\n",
      "        [-1.5610, -0.6091,  1.0193, -0.8260,  0.9760]])\n",
      "tensor([[-1.8244, -1.9956,  1.1319, -2.5227,  2.8093],\n",
      "        [-3.1341, -2.0702,  1.5589, -1.3097,  2.7941],\n",
      "        [-1.9593, -0.6499,  1.4317, -0.9888,  0.9317],\n",
      "        [-1.0649,  0.1807,  0.0448, -0.5998,  0.5761],\n",
      "        [-3.2848,  2.1406, -0.2893, -0.0905,  0.7771]])\n",
      " [===============================>...] | Loss: 0.400 | Acc: 84.000% (42/50)     10/10 \n",
      "val_loss:  tensor(0.3999) accuracy:  tensor(84)\n",
      "\n",
      "Epoch: 17\n",
      " [==================================>] | Loss: 0.714 | Acc: 77.000% (774/1003)  101/101 \n",
      "tensor([[ 1.7820, -1.7692, -1.1806,  0.4625, -0.3107],\n",
      "        [ 3.7804, -1.3489, -2.5735,  0.7555, -2.3706],\n",
      "        [ 5.1810, -2.4689, -2.4855, -1.0151, -2.1330],\n",
      "        [ 2.1821, -0.9199, -1.9247,  0.9415, -1.3390],\n",
      "        [ 3.4256, -2.2372, -0.6969, -2.0835, -0.9617]])\n",
      "tensor([[ 2.5086, -0.8678, -2.6198,  0.9878, -1.4921], Acc: 100.000% (5/5)      1/10 \n",
      "        [ 2.7614, -1.0880, -0.7244, -0.5063, -1.9568],\n",
      "        [ 1.6060, -1.9889,  0.4111, -1.9948,  0.1395],\n",
      "        [ 3.8587, -1.2450, -1.2943, -1.3819, -2.2927],\n",
      "        [ 3.4999, -1.4879, -1.2033, -1.3844, -1.6342]])\n",
      "tensor([[-0.7967,  2.1340, -1.7314,  0.8928, -2.0076],\n",
      "        [-3.3769,  0.2693,  1.0825,  0.9943, -0.3407],\n",
      "        [-1.9197,  0.3774,  1.4249, -1.0850, -0.1268],\n",
      "        [-3.3209,  2.9106, -1.6564,  1.7502, -0.5264],\n",
      "        [-3.4311,  2.8459, -0.1763,  0.6165, -1.3434]])\n",
      "tensor([[-2.3870,  2.0685,  0.2804, -0.2216, -1.4063],\n",
      "        [-3.1044,  3.3154,  0.0079, -0.3790, -1.9709],\n",
      "        [-1.4552,  3.1188, -0.9226, -0.8539, -2.7292],\n",
      "        [-2.1288,  2.2408,  0.2570, -1.3915, -0.8528],\n",
      "        [-1.8164,  1.9466, -0.7562,  0.7781, -1.8624]])\n",
      "tensor([[-2.8848, -2.0727,  3.2295, -1.9933,  0.6074],\n",
      "        [-3.1175, -1.2752,  3.3419, -1.8689, -0.1451],\n",
      "        [-2.2813, -0.7730,  2.4987, -1.3275, -0.3160],\n",
      "        [-4.2561, -0.4950,  3.2863, -1.9804,  0.8960],\n",
      "        [-1.9866, -1.0165,  2.3231, -2.3210,  0.9854]])\n",
      "tensor([[-3.0364, -0.4014,  3.5471, -2.2120, -1.0966],\n",
      "        [-2.9430, -1.7077,  3.5742, -1.5695, -0.9506],\n",
      "        [-3.1061, -0.7478,  3.0093, -1.6191, -0.1054],\n",
      "        [-3.5500, -0.8179,  2.5738, -3.1347,  2.3015],\n",
      "        [-3.9432, -1.2882,  3.4381, -1.1734, -0.3829]])\n",
      "tensor([[-2.3003,  0.9397, -0.5526,  2.1382, -1.6596], Acc: 93.000% (28/30)     6/10 \n",
      "        [-1.2307, -0.5401, -0.2179,  2.0021, -0.4280],\n",
      "        [-2.1963,  2.1195, -1.0866,  1.9089, -2.2653],\n",
      "        [-1.7828,  0.0437, -1.1024,  3.1044, -1.5208],\n",
      "        [-1.2637, -0.3902, -1.0587,  3.1672, -1.4165]])\n",
      "tensor([[-2.0908,  0.8214, -1.0798,  3.1854, -2.6403],\n",
      "        [-1.9962, -0.1076, -0.9149,  3.4100, -2.1542],\n",
      "        [-2.0756,  0.1160, -0.6329,  2.8408, -1.4567],\n",
      "        [-2.0727,  0.2874,  0.1399,  2.2514, -2.7260],\n",
      "        [-3.1512,  0.1871, -0.7014,  3.1305, -0.9331]])\n",
      "tensor([[-3.3198, -0.6736,  1.7362, -2.1957,  2.5801],\n",
      "        [-3.1887, -0.9625,  1.7453, -0.4156,  1.2288],\n",
      "        [-4.3403,  2.0835,  1.2763, -0.7704,  0.0265],\n",
      "        [-2.1663, -1.6880,  0.9597, -0.9983,  2.3801],\n",
      "        [-1.0627, -0.8979,  0.4158, -0.6843,  1.3567]])\n",
      "tensor([[-1.5493, -1.9743,  0.6508, -2.1871,  2.7909],\n",
      "        [-2.0179, -2.2998,  0.8372, -1.3906,  2.7580],\n",
      "        [-1.7853, -0.6943,  1.0147, -0.6208,  1.0543],\n",
      "        [-0.9930, -0.1660, -0.0816, -0.5236,  0.8818],\n",
      "        [-2.9551,  1.4496, -0.1840, -0.1881,  1.0571]])\n",
      " [===============================>...] | Loss: 0.364 | Acc: 88.000% (44/50)     10/10 \n",
      "val_loss:  tensor(0.3641) accuracy:  tensor(88)\n",
      "Epoch    17: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch    17: reducing learning rate of group 1 to 2.5000e-04.\n",
      "\n",
      "Epoch: 18\n",
      " [==================================>] | Loss: 0.709 | Acc: 78.000% (788/1003)  101/101 \n",
      "tensor([[ 2.3364, -1.7229, -1.6411,  0.1620, -0.4286],\n",
      "        [ 4.6673, -1.6146, -3.2082,  0.5897, -2.8517],\n",
      "        [ 5.8759, -2.4281, -3.2555, -0.7143, -2.8828],\n",
      "        [ 2.7450, -0.9771, -2.2438,  0.7261, -1.6755],\n",
      "        [ 3.8015, -2.2170, -1.1603, -2.1634, -1.1681]])\n",
      "tensor([[ 3.4241, -0.6283, -3.2579,  0.5029, -2.4338], Acc: 100.000% (5/5)      1/10 \n",
      "        [ 3.3832, -1.1269, -1.2500, -0.5995, -2.4560],\n",
      "        [ 1.8724, -1.7895,  0.2749, -2.0594, -0.2611],\n",
      "        [ 4.4834, -1.3137, -1.8070, -1.3662, -2.8695],\n",
      "        [ 4.0382, -1.3994, -1.9425, -1.0940, -2.2924]])\n",
      "tensor([[ 0.1172,  2.0650, -2.3741,  0.6453, -2.3891],\n",
      "        [-3.5969,  0.6042,  0.7009,  1.4174, -0.4756],\n",
      "        [-1.2582,  0.6545,  0.7107, -1.1403, -0.1723],\n",
      "        [-3.0807,  3.2991, -2.3773,  1.9473, -0.8569],\n",
      "        [-3.2103,  2.9983, -0.5147,  0.6555, -1.1461]])\n",
      "tensor([[-3.0431,  2.6952, -0.1070, -0.5151, -0.4500],\n",
      "        [-2.8068,  3.8425, -0.7052, -0.1850, -2.3119],\n",
      "        [-0.5486,  2.7667, -1.6117, -0.7354, -2.5903],\n",
      "        [-1.9827,  2.2632,  0.1704, -1.4895, -0.7610],\n",
      "        [-2.1503,  2.7806, -1.5699,  0.8516, -1.6896]])\n",
      "tensor([[-3.1020, -1.5852,  3.1991, -1.8064,  0.5356],\n",
      "        [-3.0555, -1.2221,  3.2020, -1.7745, -0.0200],\n",
      "        [-2.3700, -0.4855,  2.2619, -0.9630, -0.4736],\n",
      "        [-4.1765, -0.2330,  3.1549, -2.1518,  1.1543],\n",
      "        [-1.8629, -1.1703,  2.4199, -2.3184,  0.9059]])\n",
      "tensor([[-3.2207, -0.0885,  3.5605, -2.2643, -1.1597],\n",
      "        [-3.4263, -1.5183,  3.5506, -1.2048, -1.0525],\n",
      "        [-3.0830, -0.3731,  2.4596, -1.1673,  0.1335],\n",
      "        [-4.0714, -0.3308,  2.4492, -3.0158,  2.6332],\n",
      "        [-3.8407, -0.7862,  3.3957, -1.2450, -0.7520]])\n",
      "tensor([[-2.1548,  1.9538, -1.3993,  1.9363, -1.7051], Acc: 90.000% (27/30)     6/10 \n",
      "        [-0.7178, -0.1842, -0.9460,  2.3944, -1.0698],\n",
      "        [-1.8925,  1.9097, -1.1603,  2.0157, -2.2660],\n",
      "        [-0.8542,  0.7600, -2.0765,  3.1306, -2.5166],\n",
      "        [-1.1045,  0.0250, -1.7447,  3.2951, -1.4610]])\n",
      "tensor([[-1.7656,  1.0818, -1.5046,  3.3411, -3.0127],\n",
      "        [-1.7852,  0.2507, -1.4190,  3.7075, -2.8027],\n",
      "        [-1.8917,  0.7561, -1.4629,  3.0491, -1.9407],\n",
      "        [-1.5899,  0.6024, -0.4966,  2.5023, -3.1135],\n",
      "        [-3.0867,  0.5531, -1.0463,  3.2211, -0.9684]])\n",
      "tensor([[-4.4755,  0.3056,  1.4269, -1.9306,  3.3332],\n",
      "        [-3.8437, -1.1447,  1.5526,  0.6847,  0.8995],\n",
      "        [-4.6766,  2.5739,  0.3006, -0.1033,  0.9085],\n",
      "        [-2.5859, -1.3912,  1.0759, -1.1035,  2.5717],\n",
      "        [-0.9321, -0.4943,  0.0066, -0.5425,  1.2083]])\n",
      "tensor([[-1.7418, -1.9235,  0.6305, -2.5561,  3.0722],\n",
      "        [-2.6074, -1.7045,  0.4459, -1.1481,  3.2480],\n",
      "        [-1.9892, -0.5053,  0.9064, -0.6293,  1.3131],\n",
      "        [-0.5750, -0.0975, -0.3833, -0.7717,  0.8103],\n",
      "        [-3.4858,  2.0909, -0.4289, -0.1078,  1.1105]])\n",
      " [===============================>...] | Loss: 0.326 | Acc: 86.000% (43/50)     10/10 \n",
      "val_loss:  tensor(0.3260) accuracy:  tensor(86)\n",
      "\n",
      "Epoch: 19\n",
      " [==================================>] | Loss: 0.736 | Acc: 78.000% (783/1003)  101/101 \n",
      "tensor([[ 1.7020, -1.3847, -1.5274,  0.2765, -0.1567],\n",
      "        [ 4.0058, -1.4003, -3.2086,  1.0044, -2.4593],\n",
      "        [ 5.6432, -2.7488, -3.0861, -1.1505, -2.1893],\n",
      "        [ 2.4903, -0.9389, -1.9488,  0.4910, -1.3135],\n",
      "        [ 3.5942, -2.3265, -1.0000, -2.4015, -0.9031]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.9918, -0.9436, -2.7520,  0.4770, -1.6686], Acc: 100.000% (5/5)      1/10 \n",
      "        [ 3.2824, -1.0374, -1.0725, -0.9590, -2.1762],\n",
      "        [ 1.4618, -1.7182,  0.5255, -2.2488, -0.0418],\n",
      "        [ 3.5621, -1.0896, -1.1776, -1.4740, -2.1487],\n",
      "        [ 3.5390, -1.2592, -1.5234, -1.2904, -1.9176]])\n",
      "tensor([[-0.9362,  2.4910, -1.7692,  0.4603, -1.8409],\n",
      "        [-4.0259,  0.5726,  1.0733,  1.2179, -0.4032],\n",
      "        [-1.4826,  0.4655,  1.2461, -1.0580, -0.3185],\n",
      "        [-3.1058,  3.0045, -2.0584,  1.7838, -0.4895],\n",
      "        [-3.5783,  2.8864, -0.2370,  0.7967, -1.3366]])\n",
      "tensor([[-2.3205,  2.5964, -0.3813, -0.2379, -1.3866],\n",
      "        [-2.8892,  3.4185, -0.4313, -0.1003, -1.9113],\n",
      "        [-1.1063,  2.8371, -0.9664, -0.9387, -2.4692],\n",
      "        [-2.3090,  2.3449,  0.3503, -1.6948, -0.5298],\n",
      "        [-1.9698,  2.3584, -1.1357,  0.8258, -1.7569]])\n",
      "tensor([[-3.4499, -1.6952,  3.1092, -1.7953,  1.0815],\n",
      "        [-2.4912, -1.4642,  2.8557, -1.8060,  0.2123],\n",
      "        [-2.2062, -0.5442,  2.3428, -1.2636, -0.2349],\n",
      "        [-4.5262, -0.8242,  3.5977, -2.1003,  1.0338],\n",
      "        [-1.9277, -1.1087,  2.4967, -2.7296,  1.1897]])\n",
      "tensor([[-3.2835, -0.4878,  3.8183, -2.3761, -0.8934],\n",
      "        [-3.2837, -1.5306,  3.6562, -1.3664, -1.0545],\n",
      "        [-3.4077, -0.6318,  2.6696, -0.9914,  0.0700],\n",
      "        [-4.0859, -0.4675,  2.5584, -3.1125,  2.6384],\n",
      "        [-3.9917, -0.7869,  3.4331, -1.2311, -0.6670]])\n",
      "tensor([[-2.6797,  1.0691, -0.5653,  2.3036, -1.6965], Acc: 90.000% (27/30)     6/10 \n",
      "        [-1.4006, -0.2243, -0.4950,  2.1460, -0.3505],\n",
      "        [-2.3998,  2.1713, -1.1444,  2.0735, -2.3001],\n",
      "        [-1.9555,  0.4847, -1.4066,  2.9311, -1.3104],\n",
      "        [-1.5402,  0.0846, -1.4371,  3.0615, -0.9486]])\n",
      "tensor([[-2.2800,  0.8346, -1.0237,  3.3814, -3.0482],\n",
      "        [-2.1290,  0.4364, -1.2807,  3.6723, -2.6729],\n",
      "        [-2.0798,  0.6386, -1.4627,  3.2323, -1.6508],\n",
      "        [-2.4633,  0.4259,  0.0184,  2.7443, -3.2507],\n",
      "        [-3.3658,  0.4081, -0.8645,  3.3149, -1.0396]])\n",
      "tensor([[-4.0611, -0.0150,  1.5137, -2.1768,  3.2335],\n",
      "        [-3.6006, -0.2227,  1.3588, -0.1627,  1.2832],\n",
      "        [-4.7254,  2.0646,  1.4571, -0.9762,  0.3796],\n",
      "        [-2.1849, -2.0113,  0.6846, -1.3272,  3.0057],\n",
      "        [-1.0685, -0.5798,  0.3753, -0.7839,  1.2291]])\n",
      "tensor([[-1.4085, -2.4746,  0.4297, -2.5661,  3.1423],\n",
      "        [-2.8447, -2.2133,  0.9338, -1.4207,  3.3826],\n",
      "        [-1.7910, -0.4676,  0.6881, -0.4511,  1.1991],\n",
      "        [-0.5888, -0.4045, -0.0538, -0.8479,  0.9232],\n",
      "        [-3.1868,  1.7987, -0.2440, -0.1252,  0.8838]])\n",
      " [===============================>...] | Loss: 0.331 | Acc: 86.000% (43/50)     10/10 \n",
      "val_loss:  tensor(0.3314) accuracy:  tensor(86)\n",
      "\n",
      "Epoch: 20\n",
      " [==================================>] | Loss: 0.664 | Acc: 78.000% (792/1003)  101/101 \n",
      "tensor([[ 1.9449, -1.7103, -1.5901,  0.4326, -0.3231],\n",
      "        [ 3.6902, -1.3383, -3.2907,  1.3429, -2.3865],\n",
      "        [ 5.2430, -2.4146, -3.0881, -0.5906, -2.2569],\n",
      "        [ 1.7052, -0.9797, -2.1918,  1.4258, -1.1451],\n",
      "        [ 3.6261, -2.2189, -1.3803, -2.1270, -1.0197]])\n",
      "tensor([[ 2.8835, -0.7016, -3.2589,  1.1035, -2.1289], Acc: 100.000% (5/5)      1/10 \n",
      "        [ 3.3056, -1.1009, -1.1652, -0.8564, -2.1788],\n",
      "        [ 2.0717, -2.0770,  0.1212, -2.0173, -0.1421],\n",
      "        [ 3.4767, -0.9862, -1.5203, -1.1645, -2.1666],\n",
      "        [ 3.7037, -1.6032, -1.4440, -1.3477, -1.7189]])\n",
      "tensor([[-0.4786,  2.0155, -1.7785,  0.6740, -2.0990],\n",
      "        [-3.7422,  0.4512,  0.8018,  1.4695, -0.3648],\n",
      "        [-1.4112,  0.3651,  1.1733, -1.0875, -0.2048],\n",
      "        [-2.6806,  2.7938, -2.2234,  1.9424, -0.9371],\n",
      "        [-3.3013,  2.8452, -0.4873,  0.7744, -1.1558]])\n",
      "tensor([[-2.2707,  2.1597, -0.4139,  0.2528, -1.2321],\n",
      "        [-2.3833,  3.2344, -0.8321,  0.0835, -2.1835],\n",
      "        [-0.2657,  2.2667, -1.2546, -0.6482, -2.6305],\n",
      "        [-2.0432,  2.1489,  0.1569, -1.5628, -0.6346],\n",
      "        [-1.7048,  2.2256, -1.3183,  0.7832, -1.7125]])\n",
      "tensor([[-2.8945, -2.0029,  3.0136, -2.2460,  1.1525],\n",
      "        [-2.7229, -1.6126,  3.0076, -1.9532,  0.3874],\n",
      "        [-2.0769, -0.6087,  2.2221, -1.0966, -0.3565],\n",
      "        [-4.3767, -0.9061,  3.2893, -1.8787,  1.1964],\n",
      "        [-1.8894, -1.0415,  2.0069, -2.2690,  1.3667]])\n",
      "tensor([[-2.9627, -0.8266,  3.6889, -2.3511, -0.7840],\n",
      "        [-3.2310, -1.4551,  3.5844, -1.4802, -0.8975],\n",
      "        [-2.9586, -0.8970,  2.6115, -1.2442,  0.1885],\n",
      "        [-3.2551, -1.2846,  2.0945, -3.3549,  2.8644],\n",
      "        [-3.5016, -1.4706,  3.3268, -1.1646, -0.4858]])\n",
      "tensor([[-1.8979,  1.2257, -1.1168,  2.1110, -1.8940], Acc: 90.000% (27/30)     6/10 \n",
      "        [-1.2447, -0.4271, -0.4600,  2.2061, -0.3725],\n",
      "        [-2.1932,  2.2148, -1.3355,  2.0117, -2.2635],\n",
      "        [-1.4490,  0.2933, -1.5034,  3.1862, -2.0453],\n",
      "        [-1.4589, -0.2872, -1.4641,  3.2693, -0.8032]])\n",
      "tensor([[-1.8414,  0.6274, -1.0344,  3.2243, -2.9884],\n",
      "        [-1.7771,  0.1729, -1.2596,  3.5733, -2.7783],\n",
      "        [-1.9024,  0.2844, -1.3692,  3.3328, -1.8037],\n",
      "        [-2.5021,  0.3911, -0.1301,  2.9560, -3.0714],\n",
      "        [-3.2404,  0.1330, -0.8361,  3.5400, -1.4483]])\n",
      "tensor([[-3.2724, -0.7519,  1.4763, -2.5314,  3.0518],\n",
      "        [-3.4145, -0.9160,  1.5476, -0.3910,  1.5655],\n",
      "        [-4.5475,  1.3615,  1.0777, -0.1479,  0.7621],\n",
      "        [-2.2674, -2.2611,  0.5257, -1.4490,  3.3260],\n",
      "        [-0.8513, -0.7533, -0.0364, -0.5579,  1.3334]])\n",
      "tensor([[-1.2494, -3.0001,  0.5147, -3.0157,  3.2185],\n",
      "        [-2.1481, -2.7464,  0.8806, -1.6708,  3.1683],\n",
      "        [-1.5391, -0.6406,  0.6391, -0.7179,  1.3062],\n",
      "        [-0.2892, -0.2842, -0.8226, -0.4863,  0.9005],\n",
      "        [-2.8007,  1.5728, -0.3793, -0.2539,  0.8876]])\n",
      " [===============================>...] | Loss: 0.338 | Acc: 88.000% (44/50)     10/10 \n",
      "val_loss:  tensor(0.3377) accuracy:  tensor(88)\n",
      "Epoch    20: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch    20: reducing learning rate of group 1 to 1.2500e-04.\n",
      "\n",
      "Epoch: 21\n",
      " [==================================>] | Loss: 0.692 | Acc: 79.000% (800/1003)  101/101 \n",
      "tensor([[ 1.6070, -1.6444, -1.2469,  0.4506, -0.2398],\n",
      "        [ 3.9773, -1.4897, -3.3809,  1.3054, -2.4172],\n",
      "        [ 5.1085, -2.3260, -3.2925, -0.2990, -2.1112],\n",
      "        [ 1.4342, -0.9339, -2.0453,  1.6162, -1.1198],\n",
      "        [ 3.5018, -2.1140, -1.0964, -2.0173, -1.1078]])\n",
      "tensor([[ 2.4042, -0.7356, -3.1169,  1.2184, -1.7379], Acc: 80.000% (4/5)       1/10 \n",
      "        [ 3.4552, -1.0047, -1.3759, -0.9178, -2.3821],\n",
      "        [ 1.9758, -1.9593,  0.0862, -1.9169, -0.1670],\n",
      "        [ 3.7367, -0.9851, -1.6787, -1.0639, -2.4733],\n",
      "        [ 3.9097, -1.4674, -1.6172, -1.2415, -2.1419]])\n",
      "tensor([[-0.3071,  1.9554, -1.7294,  0.6247, -2.3008],\n",
      "        [-3.5600,  0.3390,  0.9484,  1.2457, -0.4809],\n",
      "        [-1.1330,  0.0937,  1.1361, -0.8687, -0.3549],\n",
      "        [-2.8138,  2.7436, -1.9508,  1.8664, -0.8682],\n",
      "        [-3.6802,  3.0026, -0.3255,  0.5966, -1.0166]])\n",
      "tensor([[-2.3029,  2.4057, -0.5709,  0.1317, -1.3451],\n",
      "        [-2.6804,  3.2475, -0.5031,  0.0692, -2.0535],\n",
      "        [ 0.1058,  2.0488, -1.5121, -0.5533, -2.7476],\n",
      "        [-1.9852,  2.4921, -0.1793, -1.6027, -0.9807],\n",
      "        [-1.9053,  2.6047, -1.5776,  0.7455, -1.8771]])\n",
      "tensor([[-2.8182, -2.0952,  3.0198, -2.2144,  1.1497],\n",
      "        [-2.4947, -1.7640,  3.2585, -2.1261, -0.0494],\n",
      "        [-1.6423, -0.5029,  2.1408, -1.2923, -0.5442],\n",
      "        [-4.2940, -1.1298,  3.5257, -2.0780,  1.1019],\n",
      "        [-1.5622, -1.3969,  2.2673, -2.5441,  1.0717]])\n",
      "tensor([[-2.7882, -0.7974,  3.8027, -2.5434, -1.1665],\n",
      "        [-3.0190, -1.3902,  3.5715, -1.5030, -1.1607],\n",
      "        [-2.8618, -0.7709,  2.6945, -1.3450, -0.1138],\n",
      "        [-3.6943, -1.3263,  2.7969, -3.4435,  2.6897],\n",
      "        [-3.4707, -1.1335,  3.4393, -1.2694, -1.0504]])\n",
      "tensor([[-2.3619,  1.4720, -1.0878,  2.2457, -1.9757], Acc: 90.000% (27/30)     6/10 \n",
      "        [-1.2914, -0.2682, -0.5215,  2.0955, -0.3125],\n",
      "        [-2.2422,  2.0809, -1.1751,  1.9932, -2.2099],\n",
      "        [-1.4839,  0.4423, -1.5223,  3.0246, -2.0396],\n",
      "        [-1.3850, -0.2993, -1.2883,  3.0422, -0.8923]])\n",
      "tensor([[-1.6375,  0.7875, -1.1026,  2.9225, -2.7491],\n",
      "        [-1.9741, -0.0149, -1.1024,  3.7171, -2.8284],\n",
      "        [-2.0141,  0.2852, -1.4297,  3.2791, -1.3156],\n",
      "        [-2.0090,  0.5341, -0.5320,  2.9010, -3.0036],\n",
      "        [-2.9425, -0.2438, -0.6768,  3.3406, -1.2289]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.8476, -1.3569,  1.5480, -2.4473,  2.9905],\n",
      "        [-2.5755, -1.1730,  1.7422, -0.8831,  1.1848],\n",
      "        [-4.2740,  1.6225,  1.0992, -0.4082,  0.1856],\n",
      "        [-2.1408, -2.2530,  0.9604, -1.6499,  2.8622],\n",
      "        [-0.8139, -0.8533,  0.2489, -0.5161,  1.0846]])\n",
      "tensor([[-1.1907, -3.0456,  0.3419, -2.4636,  3.1746],\n",
      "        [-2.0037, -2.8002,  0.9955, -1.3337,  2.7688],\n",
      "        [-1.2391, -0.7600,  0.6915, -0.5568,  0.9287],\n",
      "        [-0.3299, -0.4326, -0.7236, -0.1785,  0.9272],\n",
      "        [-2.9684,  1.5676, -0.5015, -0.1089,  0.9961]])\n",
      " [===============================>...] | Loss: 0.361 | Acc: 86.000% (43/50)     10/10 \n",
      "val_loss:  tensor(0.3610) accuracy:  tensor(86)\n",
      "\n",
      "Epoch: 22\n",
      " [==================================>] | Loss: 0.699 | Acc: 77.000% (777/1003)  101/101 \n",
      "tensor([[ 1.1914, -1.5567, -1.2247,  0.7612, -0.1021],\n",
      "        [ 3.5826, -1.2982, -3.0302,  1.0686, -2.2833],\n",
      "        [ 4.9541, -2.0277, -3.0625, -0.5082, -2.3566],\n",
      "        [ 1.6502, -0.6807, -1.9950,  1.1056, -1.3190],\n",
      "        [ 3.2961, -2.0102, -1.0881, -1.9294, -0.8935]])\n",
      "tensor([[ 2.6573, -0.3683, -3.1753,  0.8694, -2.2162], Acc: 100.000% (5/5)      1/10 \n",
      "        [ 3.1904, -0.9283, -1.1687, -0.9904, -2.1737],\n",
      "        [ 1.8484, -1.7401,  0.0354, -1.7425, -0.1821],\n",
      "        [ 3.7218, -0.9675, -1.5619, -1.3319, -2.4738],\n",
      "        [ 3.3283, -1.2841, -1.2628, -1.3028, -1.6804]])\n",
      "tensor([[-0.3762,  2.0526, -2.0884,  0.7724, -2.1464],\n",
      "        [-3.6251,  0.7990,  0.2458,  1.7606, -0.0983],\n",
      "        [-1.0753,  0.1925,  1.0388, -1.3016, -0.1373],\n",
      "        [-2.8520,  2.8010, -2.0558,  1.7181, -0.6489],\n",
      "        [-3.5991,  3.0131, -0.4636,  0.6066, -0.7434]])\n",
      "tensor([[-2.4276,  2.7013, -0.4916, -0.2935, -1.3450],\n",
      "        [-2.8623,  3.7028, -0.6071, -0.2509, -2.2033],\n",
      "        [-0.3310,  2.2853, -1.1538, -0.6550, -2.7446],\n",
      "        [-2.2000,  2.7377, -0.0901, -1.7467, -1.0182],\n",
      "        [-2.1829,  2.8704, -1.5133,  0.6178, -1.8973]])\n",
      "tensor([[-2.9265, -1.6155,  3.0519, -2.2222,  1.0463],\n",
      "        [-2.6461, -1.2995,  3.0635, -1.8522, -0.0155],\n",
      "        [-1.9005, -0.2101,  2.2024, -1.3855, -0.5510],\n",
      "        [-4.2069, -0.6180,  3.5310, -2.3340,  0.9705],\n",
      "        [-1.8408, -0.9827,  2.5844, -2.8212,  1.0124]])\n",
      "tensor([[-3.5672, -0.1118,  3.7818, -2.5692, -0.8261],\n",
      "        [-2.7588, -1.3785,  3.4889, -1.5352, -1.1545],\n",
      "        [-2.6526, -0.2440,  2.1886, -1.3234,  0.1976],\n",
      "        [-3.6151, -0.9433,  2.5706, -3.4745,  2.7400],\n",
      "        [-3.4780, -0.6998,  3.4106, -1.4496, -1.0261]])\n",
      "tensor([[-2.5938,  1.8041, -1.4123,  2.2969, -1.6459], Acc: 90.000% (27/30)     6/10 \n",
      "        [-1.6634, -0.3282, -0.4288,  2.2376, -0.2053],\n",
      "        [-2.6450,  2.2821, -1.2976,  2.0471, -1.8778],\n",
      "        [-1.7496,  0.3760, -1.4983,  3.1681, -1.8742],\n",
      "        [-1.4845, -0.1987, -1.2847,  2.8128, -0.6520]])\n",
      "tensor([[-2.1864,  1.0558, -1.3273,  3.2427, -2.4450],\n",
      "        [-1.9580,  0.2937, -1.2225,  3.4203, -2.5799],\n",
      "        [-2.1328,  0.6724, -1.3871,  3.1562, -1.9717],\n",
      "        [-2.2590,  0.8001, -0.6196,  2.9544, -3.2065],\n",
      "        [-3.2460,  0.2186, -0.6598,  3.1927, -1.2780]])\n",
      "tensor([[-3.7109,  0.0110,  1.4334, -2.4866,  3.0342],\n",
      "        [-3.3077, -1.0126,  1.7094, -0.6281,  1.6134],\n",
      "        [-4.3362,  2.4829,  0.4627, -0.3423,  0.5072],\n",
      "        [-2.6322, -2.0211,  0.8307, -1.0615,  3.0869],\n",
      "        [-1.0662, -0.1280,  0.5007, -1.0660,  0.7912]])\n",
      "tensor([[-1.7606, -2.0803,  0.5500, -2.5424,  3.1547],\n",
      "        [-2.2200, -1.9281,  0.5659, -1.3537,  3.0511],\n",
      "        [-1.0746, -0.6559,  0.8004, -1.1993,  0.9456],\n",
      "        [-0.2668, -0.2106, -0.3556, -0.8028,  0.6485],\n",
      "        [-3.0280,  2.1191, -0.5180, -0.5633,  0.7765]])\n",
      " [===============================>...] | Loss: 0.369 | Acc: 86.000% (43/50)     10/10 \n",
      "val_loss:  tensor(0.3686) accuracy:  tensor(86)\n",
      "\n",
      "Epoch: 23\n",
      " [==================================>] | Loss: 0.655 | Acc: 79.000% (799/1003)  101/101 \n",
      "tensor([[ 1.8521, -1.5714, -1.4422,  0.5094, -0.4846],\n",
      "        [ 4.0384, -1.7044, -3.2195,  1.1274, -2.3157],\n",
      "        [ 5.1819, -2.3742, -3.1222, -0.4944, -2.2515],\n",
      "        [ 1.7914, -0.7352, -2.1071,  1.1801, -1.4441],\n",
      "        [ 3.3494, -2.1164, -0.9345, -2.0870, -0.9862]])\n",
      "tensor([[ 2.9687, -0.6507, -3.3237,  1.1175, -2.4433], Acc: 100.000% (5/5)      1/10 \n",
      "        [ 3.5199, -1.0968, -1.3456, -0.8213, -2.5899],\n",
      "        [ 1.9173, -1.8468,  0.1116, -1.9284, -0.2719],\n",
      "        [ 4.0978, -1.2064, -1.6609, -1.3853, -2.6386],\n",
      "        [ 4.1300, -1.6400, -1.7605, -1.3304, -2.2201]])\n",
      "tensor([[ 0.2089,  1.7186, -1.7981,  0.6975, -2.5987],\n",
      "        [-3.6301,  0.2148,  0.6363,  1.9449, -0.6386],\n",
      "        [-1.1320,  0.1087,  1.1725, -1.1855, -0.1981],\n",
      "        [-2.8466,  2.9494, -2.2238,  1.7740, -0.7832],\n",
      "        [-3.2505,  2.6173, -0.3321,  0.6614, -0.8407]])\n",
      "tensor([[-1.8073,  2.1475, -0.4021, -0.0241, -1.6116],\n",
      "        [-2.6128,  3.1973, -0.4286,  0.0302, -2.1083],\n",
      "        [ 0.8161,  1.5727, -1.6518, -0.6400, -2.9391],\n",
      "        [-1.7805,  2.2017, -0.0051, -1.5344, -0.8838],\n",
      "        [-1.8587,  2.6324, -1.5843,  0.6465, -1.8265]])\n",
      "tensor([[-2.9420, -2.0208,  3.2359, -1.9770,  0.7045],\n",
      "        [-2.7817, -1.3204,  3.2999, -1.8589, -0.3342],\n",
      "        [-1.6979, -0.4242,  2.1908, -1.2667, -0.7665],\n",
      "        [-4.1835, -1.3947,  3.9372, -2.0920,  0.4323],\n",
      "        [-1.8245, -1.2173,  2.5839, -2.4266,  0.6886]])\n",
      "tensor([[-3.2286, -0.6016,  3.9061, -2.4431, -1.1492],\n",
      "        [-2.9353, -1.6838,  3.5809, -1.2374, -1.3954],\n",
      "        [-2.8182, -0.7934,  2.7246, -1.2687, -0.1795],\n",
      "        [-3.5192, -1.2187,  2.7466, -3.3750,  2.4437],\n",
      "        [-3.4368, -1.1958,  3.4948, -1.2639, -1.0482]])\n",
      "tensor([[-2.5183,  1.7184, -1.0870,  2.2027, -2.0385], Acc: 93.000% (28/30)     6/10 \n",
      "        [-1.1414, -0.2357, -0.6893,  2.3246, -0.7304],\n",
      "        [-2.2917,  2.1661, -1.2398,  2.0045, -2.1662],\n",
      "        [-1.9202,  0.2214, -1.3857,  3.3767, -1.9376],\n",
      "        [-1.1108, -0.4315, -1.5547,  3.3233, -1.2587]])\n",
      "tensor([[-1.9510,  0.7619, -1.1178,  3.2184, -2.8337],\n",
      "        [-1.9235,  0.2104, -1.2828,  3.7055, -3.0495],\n",
      "        [-1.9660,  0.6314, -1.5101,  3.2479, -2.1066],\n",
      "        [-2.5033,  0.3441, -0.2184,  3.1272, -3.1439],\n",
      "        [-3.1120, -0.0637, -0.6457,  3.4263, -1.6051]])\n",
      "tensor([[-3.5594, -0.4006,  1.4078, -2.3685,  3.1837],\n",
      "        [-3.1772, -0.7268,  1.9098, -1.0285,  1.3233],\n",
      "        [-4.6214,  1.5903,  0.4046,  0.7299,  0.5973],\n",
      "        [-2.4282, -1.9813,  0.8766, -1.2554,  2.9636],\n",
      "        [-0.5663, -0.3665,  0.1027, -0.8033,  0.6976]])\n",
      "tensor([[-1.4901, -2.5312,  0.6512, -2.7385,  3.1038],\n",
      "        [-2.5193, -2.3039,  0.8504, -1.0040,  2.9292],\n",
      "        [-1.2024, -0.4755,  0.6023, -0.5685,  0.8037],\n",
      "        [ 0.0259, -0.2429, -0.7161, -0.5692,  0.5095],\n",
      "        [-3.0336,  1.9291, -0.5616, -0.2117,  0.7937]])\n",
      " [===============================>...] | Loss: 0.368 | Acc: 88.000% (44/50)     10/10 \n",
      "val_loss:  tensor(0.3678) accuracy:  tensor(88)\n",
      "Epoch    23: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch    23: reducing learning rate of group 1 to 6.2500e-05.\n",
      "\n",
      "Epoch: 24\n",
      " [==================================>] | Loss: 0.670 | Acc: 79.000% (797/1003)  101/101 \n",
      "tensor([[ 1.9858, -1.7770, -1.8442,  0.6950, -0.3306],\n",
      "        [ 4.5561, -1.8312, -3.6270,  1.0483, -2.6916],\n",
      "        [ 5.7521, -2.8717, -3.0851, -1.1024, -2.2890],\n",
      "        [ 2.7020, -1.0132, -2.8007,  1.1243, -1.7451],\n",
      "        [ 3.8016, -2.4477, -1.2319, -2.2071, -1.0078]])\n",
      "tensor([[ 3.0794, -0.8359, -3.2390,  0.9366, -2.1424], Acc: 100.000% (5/5)      1/10 \n",
      "        [ 3.9073, -1.3982, -1.5864, -0.9016, -2.3830],\n",
      "        [ 2.1157, -2.0533,  0.0414, -2.2387, -0.2509],\n",
      "        [ 4.6025, -1.5022, -1.8974, -1.5116, -2.8176],\n",
      "        [ 4.2957, -1.8507, -1.7039, -1.3051, -2.1495]])\n",
      "tensor([[-0.1945,  2.0606, -2.0943,  0.9478, -2.4872],\n",
      "        [-3.0967,  0.7458,  0.1606,  1.6909, -0.2045],\n",
      "        [-1.4748,  0.3487,  0.9813, -1.0313,  0.0594],\n",
      "        [-3.1114,  3.2732, -2.7420,  2.3046, -1.0399],\n",
      "        [-3.5433,  2.9159, -0.6493,  0.9755, -0.7966]])\n",
      "tensor([[-2.5997,  2.5186, -0.1384, -0.2944, -1.1345],\n",
      "        [-2.9135,  3.7270, -0.8669,  0.1439, -2.2090],\n",
      "        [ 0.2243,  2.0295, -1.7781, -0.3589, -2.7874],\n",
      "        [-2.1548,  2.3966,  0.1136, -1.5454, -0.6379],\n",
      "        [-2.0516,  2.8808, -1.9492,  0.9286, -1.8688]])\n",
      "tensor([[-2.2549, -1.6762,  2.8449, -2.2910,  0.8794],\n",
      "        [-2.8511, -1.0480,  2.9553, -1.7439,  0.1415],\n",
      "        [-1.6570, -0.3695,  2.0421, -1.2370, -0.4495],\n",
      "        [-4.2606, -0.8236,  3.6644, -2.0984,  0.6706],\n",
      "        [-1.7766, -0.8891,  2.2910, -2.1988,  0.8135]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.0249, -0.2366,  3.5433, -2.2782, -1.2237],\n",
      "        [-3.0343, -1.2823,  3.2291, -0.9810, -1.1759],\n",
      "        [-3.2894, -0.2184,  2.5542, -1.1394, -0.0218],\n",
      "        [-4.1572, -0.4969,  2.6736, -3.3666,  2.7654],\n",
      "        [-3.5699, -0.5356,  2.9888, -0.9347, -0.8239]])\n",
      "tensor([[-2.4897,  1.7119, -1.4344,  2.3409, -1.4937], Acc: 90.000% (27/30)     6/10 \n",
      "        [-1.3519, -0.3183, -0.8044,  2.4635, -0.1182],\n",
      "        [-2.5868,  2.2752, -1.3625,  2.2215, -2.1141],\n",
      "        [-1.2348,  0.3474, -1.5220,  2.8890, -1.8468],\n",
      "        [-1.2526, -0.2397, -1.6081,  3.2541, -1.1574]])\n",
      "tensor([[-1.7563,  1.0131, -1.6069,  3.4253, -2.7935],\n",
      "        [-1.8938,  0.1917, -1.4387,  3.9709, -3.2136],\n",
      "        [-2.4276,  0.6991, -1.4180,  3.4176, -1.8438],\n",
      "        [-2.0708,  0.8449, -0.7341,  2.9046, -3.1681],\n",
      "        [-3.3618,  0.5313, -0.8419,  3.1345, -1.0656]])\n",
      "tensor([[-3.6043, -0.1160,  1.6593, -2.8218,  2.9687],\n",
      "        [-2.6661, -0.7904,  1.2958, -0.4438,  1.4268],\n",
      "        [-4.6602,  2.2404,  0.6122, -0.0194,  0.5344],\n",
      "        [-2.2810, -1.7435,  0.6659, -0.7368,  2.6535],\n",
      "        [-0.5418, -0.5953, -0.2459, -0.4336,  1.0272]])\n",
      "tensor([[-1.2824, -2.2883,  0.4303, -2.6767,  2.9437],\n",
      "        [-2.2764, -2.1892,  0.5357, -1.2360,  3.1341],\n",
      "        [-1.2848, -0.5745,  0.6768, -0.7344,  0.9958],\n",
      "        [-0.3207, -0.1973, -0.4807, -0.6489,  0.6707],\n",
      "        [-3.2759,  2.1938, -0.6643, -0.2832,  0.9398]])\n",
      " [===============================>...] | Loss: 0.337 | Acc: 88.000% (44/50)     10/10 \n",
      "val_loss:  tensor(0.3373) accuracy:  tensor(88)\n",
      "\n",
      "Epoch: 25\n",
      " [==================================>] | Loss: 0.648 | Acc: 80.000% (807/1003)  101/101 \n",
      "tensor([[ 2.0747, -1.6871, -1.2695, -0.0668, -0.3463],\n",
      "        [ 3.6851, -1.5552, -2.9648,  0.9262, -1.9962],\n",
      "        [ 5.2488, -2.5702, -3.0058, -0.8880, -2.0110],\n",
      "        [ 1.4378, -0.7738, -1.9342,  1.4075, -1.3833],\n",
      "        [ 3.4637, -2.3175, -1.0362, -1.9484, -0.8237]])\n",
      "tensor([[ 2.5244, -0.5142, -3.0097,  0.9546, -2.0310], Acc: 100.000% (5/5)      1/10 \n",
      "        [ 3.4276, -1.1552, -1.3237, -0.7717, -2.2528],\n",
      "        [ 1.6195, -1.8814,  0.0190, -1.5532,  0.1315],\n",
      "        [ 3.8061, -1.2926, -1.5681, -1.3972, -2.1163],\n",
      "        [ 3.8526, -1.7235, -1.3419, -1.5899, -1.8194]])\n",
      "tensor([[-0.1413,  1.8163, -1.9460,  1.0648, -2.5228],\n",
      "        [-3.4278,  0.4877,  0.3257,  1.8942, -0.3064],\n",
      "        [-1.3995,  0.2498,  1.1192, -1.1074, -0.0314],\n",
      "        [-2.9887,  2.8536, -2.2159,  2.2666, -1.0844],\n",
      "        [-3.1765,  2.4367, -0.5812,  1.1827, -0.9657]])\n",
      "tensor([[-2.2220,  2.1625, -0.4354,  0.4039, -1.4923],\n",
      "        [-2.5903,  3.2295, -0.5621,  0.1274, -2.2050],\n",
      "        [-0.2115,  2.3828, -1.6425, -0.3605, -2.9111],\n",
      "        [-1.8722,  1.9179,  0.2813, -1.4844, -0.5969],\n",
      "        [-1.9948,  2.7434, -1.6417,  0.7103, -1.8290]])\n",
      "tensor([[-2.5564, -2.0881,  3.1061, -2.0080,  0.5958],\n",
      "        [-2.5447, -1.4778,  3.0390, -1.8653,  0.0232],\n",
      "        [-1.8559, -0.6037,  2.2783, -1.2770, -0.4760],\n",
      "        [-4.0037, -1.0125,  3.4416, -1.9044,  0.7010],\n",
      "        [-1.7534, -1.1154,  2.4147, -2.2678,  0.7257]])\n",
      "tensor([[-2.7090, -0.5781,  3.4813, -2.2715, -1.0692],\n",
      "        [-2.7314, -1.6502,  3.2423, -1.0729, -1.1552],\n",
      "        [-3.0929, -0.4651,  2.4068, -1.2182,  0.3423],\n",
      "        [-3.8165, -0.8746,  2.3052, -2.9521,  2.7980],\n",
      "        [-3.5606, -0.8378,  3.2263, -1.0833, -1.0045]])\n",
      "tensor([[-2.4393,  1.6624, -1.1811,  2.1703, -1.6218], Acc: 90.000% (27/30)     6/10 \n",
      "        [-1.1808, -0.3554, -0.5708,  2.2015, -0.3084],\n",
      "        [-2.5046,  1.9652, -1.0414,  2.0929, -2.0347],\n",
      "        [-1.8496,  0.3328, -1.2703,  2.9659, -1.4214],\n",
      "        [-1.4430, -0.0267, -1.6604,  3.1024, -0.8558]])\n",
      "tensor([[-1.7481,  0.7606, -1.2287,  3.1443, -2.6686],\n",
      "        [-1.9816,  0.1856, -1.1380,  3.5195, -2.7344],\n",
      "        [-2.3464,  0.5957, -1.2068,  3.2501, -1.8117],\n",
      "        [-2.2079,  0.6444, -0.4311,  2.7751, -2.9397],\n",
      "        [-3.2737,  0.2200, -0.6739,  3.1377, -0.9493]])\n",
      "tensor([[-3.0735, -0.8085,  1.4421, -2.1076,  2.8140],\n",
      "        [-3.0869, -0.9297,  1.4536, -0.1604,  1.2740],\n",
      "        [-4.9019,  2.0711,  0.4815,  0.3993,  0.5509],\n",
      "        [-2.3529, -2.0356,  0.9903, -0.9175,  2.6121],\n",
      "        [-0.5499, -0.6878,  0.3301, -0.7896,  0.7829]])\n",
      "tensor([[-1.4201, -2.5349,  0.6603, -2.3912,  2.9947],\n",
      "        [-2.2779, -2.5920,  0.8704, -1.4154,  3.0897],\n",
      "        [-1.5609, -0.5287,  0.6534, -0.4840,  1.0861],\n",
      "        [-0.5742, -0.3124, -0.5581, -0.3039,  1.0502],\n",
      "        [-3.2332,  1.7784, -0.3662,  0.0034,  0.9537]])\n",
      " [===============================>...] | Loss: 0.373 | Acc: 88.000% (44/50)     10/10 \n",
      "val_loss:  tensor(0.3730) accuracy:  tensor(88)\n",
      "\n",
      "Epoch: 26\n",
      " [==================================>] | Loss: 0.626 | Acc: 81.000% (814/1003)  101/101 \n",
      "tensor([[ 1.8302, -1.7094, -2.0261,  0.7589, -0.1975],\n",
      "        [ 3.7958, -1.4322, -3.3024,  1.0781, -2.2786],\n",
      "        [ 5.1643, -2.2001, -3.4032, -0.3325, -2.4432],\n",
      "        [ 2.1256, -0.8924, -2.4462,  1.1801, -1.4862],\n",
      "        [ 3.1256, -2.0080, -1.1540, -1.7130, -0.7684]])\n",
      "tensor([[ 2.6583, -0.7638, -3.1110,  1.1738, -1.8790], Acc: 100.000% (5/5)      1/10 \n",
      "        [ 3.0502, -0.8637, -1.5840, -0.2024, -2.1465],\n",
      "        [ 1.2790, -1.5564,  0.0048, -1.2913,  0.1282],\n",
      "        [ 3.8206, -1.1474, -2.0645, -0.8162, -2.3110],\n",
      "        [ 3.6366, -1.2561, -2.0410, -0.8259, -2.0584]])\n",
      "tensor([[-0.6805,  2.2446, -2.4222,  0.9840, -1.8558],\n",
      "        [-3.0045,  0.5631, -0.3241,  2.2345, -0.0726],\n",
      "        [-1.5046,  0.3374,  0.7900, -1.0803,  0.1638],\n",
      "        [-2.9056,  2.9386, -2.3548,  1.9042, -0.5924],\n",
      "        [-3.2730,  2.6423, -0.4489,  0.7927, -0.7663]])\n",
      "tensor([[-1.8748,  2.2140, -1.0542,  0.5936, -1.5223],\n",
      "        [-2.5660,  3.6678, -1.3113,  0.1470, -2.2665],\n",
      "        [-0.2627,  2.3289, -1.7713, -0.3066, -2.5117],\n",
      "        [-1.8766,  2.1852, -0.1651, -1.3635, -0.6082],\n",
      "        [-2.0501,  2.4888, -1.6695,  1.2020, -1.7984]])\n",
      "tensor([[-2.9489, -1.6062,  2.7078, -1.3390,  0.7871],\n",
      "        [-2.9080, -1.1269,  2.8438, -1.3750, -0.0542],\n",
      "        [-1.9802, -0.6593,  2.0252, -0.7651, -0.4197],\n",
      "        [-4.4183, -0.7700,  3.4960, -1.7966,  0.6406],\n",
      "        [-1.8992, -0.9131,  2.1010, -1.8579,  0.8388]])\n",
      "tensor([[-3.0842, -0.2088,  3.2897, -1.9963, -0.9426],\n",
      "        [-2.7744, -1.3731,  3.0438, -0.9915, -1.0200],\n",
      "        [-3.0621, -0.4362,  2.3040, -1.0038,  0.2656],\n",
      "        [-4.1629, -0.7964,  2.4255, -3.0813,  2.9797],\n",
      "        [-3.6952, -1.0610,  2.9295, -0.6280, -0.5025]])\n",
      "tensor([[-2.6570,  1.3287, -0.9370,  2.3167, -1.3297], Acc: 90.000% (27/30)     6/10 \n",
      "        [-1.5085, -0.4782, -0.5724,  2.3184, -0.0022],\n",
      "        [-2.3977,  1.9682, -1.4125,  2.3352, -1.8502],\n",
      "        [-1.5277,  0.2623, -1.7634,  3.4554, -1.9461],\n",
      "        [-1.5033,  0.0696, -1.8245,  3.1791, -0.8571]])\n",
      "tensor([[-1.8301,  0.9527, -1.4324,  3.1817, -2.4820],\n",
      "        [-2.0098,  0.2014, -1.3755,  3.6729, -2.4469],\n",
      "        [-2.1746,  0.6462, -1.4100,  3.1105, -1.5198],\n",
      "        [-2.1534,  0.5451, -0.5833,  3.0916, -3.2264],\n",
      "        [-3.2942,  0.5149, -0.9510,  3.0662, -0.6801]])\n",
      "tensor([[-4.1992,  0.3153,  1.0438, -1.7455,  3.2381],\n",
      "        [-3.3313, -0.5810,  1.0155,  0.4079,  1.3016],\n",
      "        [-4.5023,  2.4373,  0.3256, -0.0835,  0.7263],\n",
      "        [-2.6914, -1.6320,  0.4949, -0.8615,  3.1415],\n",
      "        [-0.9142, -0.2777,  0.0623, -0.4165,  0.8215]])\n",
      "tensor([[-1.9848, -1.9290,  0.5372, -2.2480,  3.1518],\n",
      "        [-2.6203, -1.9199,  0.4938, -0.9481,  3.1545],\n",
      "        [-2.0361, -0.2725,  0.6094, -0.5900,  1.4566],\n",
      "        [-0.5376, -0.0533, -0.9434, -0.1671,  1.0114],\n",
      "        [-3.2015,  1.7125, -0.6910,  0.1487,  1.1058]])\n",
      " [===============================>...] | Loss: 0.351 | Acc: 90.000% (45/50)     10/10 \n",
      "val_loss:  tensor(0.3512) accuracy:  tensor(90)\n",
      "Epoch    26: reducing learning rate of group 0 to 3.1250e-05.\n",
      "Epoch    26: reducing learning rate of group 1 to 3.1250e-05.\n",
      "\n",
      "Epoch: 27\n",
      " [==================================>] | Loss: 0.618 | Acc: 80.000% (809/1003)  101/101 \n",
      "tensor([[ 1.9376, -1.6595, -1.8268,  0.9156, -0.5358],\n",
      "        [ 4.0847, -1.5537, -3.6262,  1.8447, -2.7832],\n",
      "        [ 5.4668, -2.5184, -3.1692, -0.4507, -2.3888],\n",
      "        [ 2.0217, -1.1475, -2.2501,  1.3455, -1.2572],\n",
      "        [ 3.6072, -2.4099, -0.9835, -2.1071, -0.9128]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.8131, -0.7919, -3.4093,  1.6728, -2.2914], Acc: 100.000% (5/5)      1/10 \n",
      "        [ 3.5346, -0.9629, -1.5909, -0.6470, -2.4691],\n",
      "        [ 1.8385, -1.9076,  0.0852, -1.7021, -0.1381],\n",
      "        [ 4.0914, -1.2138, -1.5373, -1.4147, -2.6000],\n",
      "        [ 3.9249, -1.5825, -1.6328, -1.1332, -1.9904]])\n",
      "tensor([[-0.3253,  2.0295, -1.8797,  0.6302, -2.1383],\n",
      "        [-3.2844,  0.3189,  0.3967,  1.5328,  0.2681],\n",
      "        [-1.3903,  0.3576,  0.9638, -1.3454, -0.0636],\n",
      "        [-3.0399,  3.1017, -2.6202,  1.8741, -0.3945],\n",
      "        [-3.7485,  3.1120, -0.5246,  0.4808, -0.3498]])\n",
      "tensor([[-2.4247,  2.7594, -1.0649,  0.5622, -1.8060],\n",
      "        [-2.5153,  3.3113, -1.0342,  0.1886, -1.8262],\n",
      "        [-1.1108,  3.0509, -1.2812, -0.8756, -2.6746],\n",
      "        [-2.3342,  2.5288, -0.1517, -1.7047, -0.4566],\n",
      "        [-2.1317,  2.4602, -1.5834,  1.1456, -1.6802]])\n",
      "tensor([[-3.3452, -2.0147,  3.1077, -2.3143,  1.7210],\n",
      "        [-3.1663, -1.2204,  3.1772, -1.8741,  0.2730],\n",
      "        [-2.0732, -0.6755,  2.1195, -1.0687, -0.0877],\n",
      "        [-4.9093, -0.7156,  3.6311, -2.3908,  1.5891],\n",
      "        [-2.4054, -0.8340,  2.2326, -2.3071,  1.5114]])\n",
      "tensor([[-3.2696, -0.6608,  3.9977, -2.8232, -0.5895],\n",
      "        [-2.7652, -1.3262,  3.3741, -1.6417, -0.8006],\n",
      "        [-3.5924, -0.4946,  2.5061, -0.9997,  0.4431],\n",
      "        [-4.6003, -0.8412,  2.5436, -3.6439,  3.6475],\n",
      "        [-3.8562, -1.1878,  3.3381, -1.1056, -0.4799]])\n",
      "tensor([[-2.4933,  1.6446, -1.3956,  2.4541, -1.8534], Acc: 90.000% (27/30)     6/10 \n",
      "        [-1.2212, -0.3644, -0.6427,  2.0818,  0.0270],\n",
      "        [-2.3832,  2.3402, -1.6811,  2.2891, -2.1253],\n",
      "        [-1.9947,  0.1936, -1.7379,  3.6860, -1.8392],\n",
      "        [-1.1430, -0.4515, -1.6602,  3.2347, -0.7656]])\n",
      "tensor([[-1.9631,  1.1037, -1.5539,  3.3228, -2.6547],\n",
      "        [-1.7193,  0.2739, -1.5038,  3.5719, -2.6004],\n",
      "        [-1.9409,  0.5357, -1.7994,  3.5427, -1.7662],\n",
      "        [-1.7039,  0.9006, -0.9698,  2.7933, -3.1740],\n",
      "        [-3.2097,  0.2972, -1.0589,  3.2928, -0.9057]])\n",
      "tensor([[-3.9792, -0.4501,  1.3704, -2.5178,  3.6880],\n",
      "        [-3.5172, -0.7453,  1.4528, -1.0774,  2.5121],\n",
      "        [-4.8862,  2.1382,  0.9721, -0.7450,  1.1898],\n",
      "        [-2.9604, -1.9989,  0.7275, -1.2718,  3.5700],\n",
      "        [-0.9393, -0.3830,  0.0048, -0.7484,  1.1901]])\n",
      "tensor([[-2.4749, -2.3756,  0.6531, -2.6889,  3.8840],\n",
      "        [-3.0460, -2.1980,  0.9475, -1.7170,  3.7314],\n",
      "        [-1.4181, -0.8274,  0.6731, -0.8358,  1.3325],\n",
      "        [-0.7492, -0.3061, -0.6215, -0.4763,  1.2902],\n",
      "        [-3.8004,  2.0636, -0.5346, -0.3773,  1.5871]])\n",
      " [===============================>...] | Loss: 0.318 | Acc: 88.000% (44/50)     10/10 \n",
      "val_loss:  tensor(0.3184) accuracy:  tensor(88)\n",
      "\n",
      "Epoch: 28\n",
      " [==================================>] | Loss: 0.652 | Acc: 80.000% (804/1003)  101/101 \n",
      "tensor([[ 1.5281, -1.6404, -1.3247,  0.5908, -0.2205],\n",
      "        [ 3.1565, -1.1143, -2.9247,  1.4206, -2.2769],\n",
      "        [ 4.8392, -2.0300, -2.9817, -0.3614, -2.2686],\n",
      "        [ 1.1807, -0.5933, -1.8771,  1.3235, -1.1487],\n",
      "        [ 2.9507, -1.8690, -0.9762, -1.8675, -0.6878]])\n",
      "tensor([[ 2.3679, -0.3719, -2.9664,  1.2596, -2.1108], Acc: 80.000% (4/5)       1/10 \n",
      "        [ 2.9697, -1.0067, -1.1012, -0.4951, -2.2135],\n",
      "        [ 1.0244, -1.7020,  0.5763, -1.8410,  0.2178],\n",
      "        [ 3.7082, -1.0955, -1.4064, -1.4120, -2.3303],\n",
      "        [ 3.4672, -1.2330, -1.4355, -1.2027, -1.9412]])\n",
      "tensor([[-0.7759,  2.2914, -1.4177,  0.6852, -2.6490],\n",
      "        [-3.2946,  0.1571,  0.4995,  1.7846, -0.3206],\n",
      "        [-1.5823,  0.4862,  1.0520, -1.2233, -0.0957],\n",
      "        [-3.1192,  3.0661, -2.3191,  2.0930, -0.9678],\n",
      "        [-3.4199,  2.6693, -0.3473,  0.6956, -0.7586]])\n",
      "tensor([[-2.3014,  2.4529, -0.4114,  0.1505, -1.7068],\n",
      "        [-2.7660,  3.6347, -0.9552,  0.1463, -2.2900],\n",
      "        [-0.3342,  2.2103, -1.1763, -0.3737, -2.7461],\n",
      "        [-2.1875,  2.3265,  0.1771, -1.6141, -0.6658],\n",
      "        [-2.4400,  2.7896, -1.3642,  0.9407, -1.9189]])\n",
      "tensor([[-3.5093, -1.5565,  3.5010, -2.3300,  0.9315],\n",
      "        [-3.2863, -1.4665,  3.3723, -1.8071,  0.1002],\n",
      "        [-2.2216, -0.4899,  2.3706, -1.2807, -0.3690],\n",
      "        [-4.6365, -1.0894,  3.6909, -1.8142,  0.7118],\n",
      "        [-2.1852, -0.9317,  2.5187, -2.3749,  0.9472]])\n",
      "tensor([[-3.4997, -0.6940,  4.1743, -2.7709, -0.8374],\n",
      "        [-2.9288, -1.5798,  3.6081, -1.4966, -1.1846],\n",
      "        [-3.4392, -0.4719,  2.6413, -1.0794,  0.0428],\n",
      "        [-4.2057, -0.6128,  2.6336, -3.2624,  2.7911],\n",
      "        [-3.5756, -1.0833,  3.3425, -1.1809, -0.8645]])\n",
      "tensor([[-3.1401,  1.6115, -0.6346,  2.3068, -2.0514], Acc: 86.000% (26/30)     6/10 \n",
      "        [-1.5316, -0.3924, -0.4534,  2.2263, -0.2378],\n",
      "        [-2.5640,  2.3928, -1.3054,  1.9477, -2.1689],\n",
      "        [-2.0193,  0.3680, -1.3465,  3.3190, -2.0162],\n",
      "        [-1.5307, -0.0036, -1.4739,  3.0717, -1.0751]])\n",
      "tensor([[-2.1048,  1.0278, -1.4081,  3.4521, -3.1511],\n",
      "        [-2.2133,  0.1431, -1.0107,  3.5303, -2.7069],\n",
      "        [-2.4652,  0.7673, -1.2474,  3.1444, -1.9589],\n",
      "        [-2.2660,  0.7524, -0.5293,  2.9328, -3.4929],\n",
      "        [-3.2777,  0.4402, -0.5926,  2.8720, -1.0492]])\n",
      "tensor([[-4.3767,  0.1547,  1.8814, -2.5846,  3.0193],\n",
      "        [-3.8415, -0.3503,  1.9806, -0.5508,  1.0602],\n",
      "        [-4.8735,  1.9937,  0.5957, -0.0421,  1.1033],\n",
      "        [-3.0941, -1.5358,  1.1915, -1.3658,  3.0215],\n",
      "        [-1.1282, -0.0001,  0.3402, -0.6186,  0.5369]])\n",
      "tensor([[-1.8147, -2.2910,  1.1413, -2.7738,  3.0566],\n",
      "        [-3.2523, -2.2552,  1.5273, -1.9240,  3.4057],\n",
      "        [-1.6347, -0.4694,  0.8511, -0.7932,  1.0516],\n",
      "        [-0.9149, -0.0066, -0.1683, -0.5382,  0.8484],\n",
      "        [-3.8059,  2.2266, -0.2994, -0.1897,  1.1043]])\n",
      " [===============================>...] | Loss: 0.391 | Acc: 84.000% (42/50)     10/10 \n",
      "val_loss:  tensor(0.3914) accuracy:  tensor(84)\n",
      "\n",
      "Epoch: 29\n",
      " [==================================>] | Loss: 0.684 | Acc: 79.000% (794/1003)  101/101 \n",
      "tensor([[ 1.5919, -1.7204, -1.7772,  0.7347, -0.0435],\n",
      "        [ 3.7867, -1.4171, -3.2947,  1.0367, -2.3411],\n",
      "        [ 5.1880, -2.1534, -3.5596, -0.3751, -2.4169],\n",
      "        [ 1.6512, -0.6571, -2.2010,  1.3481, -1.5319],\n",
      "        [ 3.2604, -2.0123, -1.2492, -2.0433, -0.8059]])\n",
      "tensor([[ 2.3188, -0.2855, -3.2552,  1.3110, -2.2734], Acc: 100.000% (5/5)      1/10 \n",
      "        [ 3.4254, -0.9368, -1.6047, -0.7234, -2.4316],\n",
      "        [ 1.7032, -1.5129, -0.3563, -1.1117, -0.1148],\n",
      "        [ 3.7152, -0.8569, -1.9108, -1.2341, -2.5950],\n",
      "        [ 3.9882, -1.3609, -1.9765, -1.0351, -2.3615]])\n",
      "tensor([[-0.2641,  2.2046, -2.5865,  1.4057, -2.8043],\n",
      "        [-3.1043,  0.5893, -0.1415,  2.2149, -0.3698],\n",
      "        [-1.4301,  0.9339,  0.5511, -1.2004, -0.2138],\n",
      "        [-3.1107,  3.3546, -2.7592,  2.2094, -1.1580],\n",
      "        [-3.3111,  2.8330, -0.7063,  0.9784, -1.0655]])\n",
      "tensor([[-2.0253,  2.8486, -1.2990,  0.5524, -2.3586],\n",
      "        [-2.7913,  3.8758, -1.3180,  0.3022, -2.4675],\n",
      "        [ 0.0873,  2.2254, -1.8862, -0.1678, -2.9638],\n",
      "        [-2.1158,  2.2760,  0.0670, -1.5501, -0.5961],\n",
      "        [-2.0399,  2.8131, -1.8614,  0.9942, -1.9978]])\n",
      "tensor([[-2.7792, -1.6192,  2.8761, -1.7538,  0.7741],\n",
      "        [-2.6970, -0.9394,  2.7312, -1.6186,  0.1557],\n",
      "        [-1.6997, -0.1769,  1.8684, -1.0880, -0.6575],\n",
      "        [-4.2398, -0.4897,  3.2992, -1.9382,  0.8308],\n",
      "        [-1.5925, -0.6883,  1.9938, -1.9209,  0.6845]])\n",
      "tensor([[-2.9311, -0.2157,  3.4693, -2.3248, -1.1643],\n",
      "        [-2.7968, -1.3335,  3.1719, -1.1117, -1.0798],\n",
      "        [-3.0891, -0.0156,  2.1732, -1.0156,  0.1016],\n",
      "        [-4.3656, -0.1911,  2.1286, -2.8750,  3.0788],\n",
      "        [-3.4917, -0.6197,  3.1258, -0.9845, -1.1447]])\n",
      "tensor([[-2.6941,  1.7940, -1.3846,  2.4547, -1.8126], Acc: 93.000% (28/30)     6/10 \n",
      "        [-1.2559, -0.1089, -0.8305,  2.2923, -0.3845],\n",
      "        [-2.4871,  2.2627, -1.4127,  2.1796, -2.2669],\n",
      "        [-1.0809,  0.6924, -2.3316,  3.2167, -2.1104],\n",
      "        [-1.3751,  0.1618, -1.9812,  3.2209, -1.2364]])\n",
      "tensor([[-2.2826,  1.1236, -1.5277,  3.6066, -2.8824],\n",
      "        [-2.1960,  0.2068, -1.2596,  3.8724, -2.9369],\n",
      "        [-2.2977,  0.5934, -1.4299,  3.4449, -2.2330],\n",
      "        [-1.9121,  1.0896, -1.0552,  3.0020, -3.6956],\n",
      "        [-3.2245,  0.3838, -0.9800,  3.3602, -1.1826]])\n",
      "tensor([[-3.9319,  0.2015,  1.0791, -2.1536,  3.1981],\n",
      "        [-3.7177, -0.1712,  1.2369, -0.1231,  1.5964],\n",
      "        [-4.7376,  2.5604,  0.1606,  0.1414,  0.6373],\n",
      "        [-2.3380, -1.5275,  0.5312, -1.0994,  2.9576],\n",
      "        [-0.2813, -0.0529, -0.2191, -0.6411,  0.2824]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.6904, -1.9450,  0.2989, -2.2371,  3.1223],\n",
      "        [-2.5627, -1.9374,  0.5769, -1.1023,  3.1974],\n",
      "        [-1.5251, -0.2768,  0.4550, -0.8006,  1.1664],\n",
      "        [-0.5420, -0.2908, -0.4952, -0.6349,  1.1026],\n",
      "        [-3.2892,  2.4188, -0.7674, -0.2602,  0.7439]])\n",
      " [===============================>...] | Loss: 0.376 | Acc: 90.000% (45/50)     10/10 \n",
      "val_loss:  tensor(0.3763) accuracy:  tensor(90)\n",
      "Epoch    29: reducing learning rate of group 0 to 1.5625e-05.\n",
      "Epoch    29: reducing learning rate of group 1 to 1.5625e-05.\n"
     ]
    }
   ],
   "source": [
    "## Run the training \n",
    "for epoch in range(0, 30):\n",
    "    train(epoch)\n",
    "    test_loss = test(epoch)\n",
    "    scheduler.step(test_loss)\n",
    "    \n",
    "train_loss_file.close()\n",
    "val_loss_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "2xXmYbiYn5VQ",
    "outputId": "5c5215c1-f34d-4889-aa77-3753fd21520f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnQqHnYO9+5QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c9a9f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Plot the Loss and Accuracy curves\n",
    "training_curves(cf.data_dir+experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "tDYuNsOzn5VW"
   },
   "outputs": [],
   "source": [
    "## After training we load the model that performed the best on validation data (avoid picking overfitted model)\n",
    "classifier = torch.load(cf.data_dir+'checkpoint/checkpoint_inception_all_ckpt.t7')['net'].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "VSaNFg5bn5VX",
    "outputId": "f01ed9cd-7dbc-4c89-eed7-679f6f024fcd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vgopired\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: tensor(90) %\n"
     ]
    }
   ],
   "source": [
    "conf, acc, wrong_predictions = eval()\n",
    "print ('Accuracy:', acc, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "RTDqw7JHn5Va",
    "outputId": "e054b9c1-bef1-4b3a-d669-6494b5863966"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1836f710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(conf, cmap='jet', vmin=0, vmax = 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "WCesthYvn5Vd",
    "outputId": "9c46bc2c-4697-4b68-d72b-10c53ecf9f53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biswa confused with khali\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c5405f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for w in wrong_predictions[::10]:\n",
    "    print (classes[w[2]], 'confused with', classes[w[1]])\n",
    "    plt.imshow(w[0][0][0].data.cpu().numpy(), cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qlrquk26n5Vv"
   },
   "source": [
    "Relying on pre-trained networks we improved the accuracy by more than 20%!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uyKFDbZkn5Vx"
   },
   "source": [
    "### Different parts of the model can have different LR. While fine-tuning it is common to set the implanted layers to 10 times higher LR than pre-trained layers. This helps the implanted layers learns faster since it is starting from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "lYlOlT1jn5Vy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "Lab11-Experiment2_2.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
